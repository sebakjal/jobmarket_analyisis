{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import google.generativeai as genai\n",
    "from typing import Optional\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "date_posted = 604800  # 86400 -> 1 day, 2592000 -> 1 month, 604800 -> 1 week\n",
    "job_name = 'data engineer'\n",
    "location = 'Chile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('config.json') as f:\n",
    "#     config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_format(job_name):\n",
    "    return job_name.replace(' ', '%20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    r = requests.get(url, headers={\"headers\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"}, timeout=5)\n",
    "\n",
    "    return BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobcards_soup():\n",
    "    formatted_job_name = name_format(job_name)\n",
    "    url = f\"https://linkedin.com/jobs/search?keywords={formatted_job_name}&location={location}&f_TPR=r{date_posted}\"\n",
    "    return get_data(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_jobcards(soup):\n",
    "    # Parsing the job card info (title, company, location, date, job_url) from the beautiful soup object\n",
    "    joblist = []\n",
    "    try:\n",
    "        divs = soup.find_all('div', class_='base-search-card__info')\n",
    "    except:\n",
    "        print(\"Empty page, no jobs found\")\n",
    "        return joblist\n",
    "    for item in divs:\n",
    "        title = item.find('h3').text.strip()\n",
    "        company = item.find('a', class_='hidden-nested-link')\n",
    "        location = item.find('span', class_='job-search-card__location')\n",
    "        parent_div = item.parent\n",
    "        entity_urn = parent_div['data-entity-urn']\n",
    "        job_posting_id = entity_urn.split(':')[-1]\n",
    "        job_url = 'https://www.linkedin.com/jobs/view/'+job_posting_id+'/'\n",
    "\n",
    "        date_tag_new = item.find('time', class_ = 'job-search-card__listdate--new')\n",
    "        date_tag = item.find('time', class_='job-search-card__listdate')\n",
    "        date = date_tag['datetime'] if date_tag else date_tag_new['datetime'] if date_tag_new else ''\n",
    "        job_description = ''\n",
    "        job = {\n",
    "            'title': title,\n",
    "            'company': company.text.strip().replace('\\n', ' ') if company else '',\n",
    "            'location': location.text.strip() if location else '',\n",
    "            'date': date,\n",
    "            'job_url': job_url,\n",
    "            'job_description': job_description,\n",
    "        }\n",
    "        joblist.append(job)\n",
    "\n",
    "    return joblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_info(soup):\n",
    "\n",
    "    job_info = {}\n",
    "    # Get the job description from the job page\n",
    "    desc_div = soup.find('div', class_='description__text description__text--rich')\n",
    "    if desc_div:\n",
    "        # Remove unwanted elements\n",
    "        for element in desc_div.find_all(['span', 'a']):\n",
    "            element.decompose()\n",
    "\n",
    "        # Replace bullet points\n",
    "        for ul in desc_div.find_all('ul'):\n",
    "            for li in ul.find_all('li'):\n",
    "                li.insert(0, '-')\n",
    "\n",
    "        text = desc_div.get_text(separator='\\n').strip()\n",
    "        text = text.replace('\\n\\n', '')\n",
    "        text = text.replace('::marker', '-')\n",
    "        text = text.replace('-\\n', '- ')\n",
    "        text = text.replace('Show less', '').replace('Show more', '')\n",
    "        job_info['job_description'] = text\n",
    "    else:\n",
    "        job_info['job_description'] = \"Could not find Job Description\"\n",
    "    \n",
    "    # Get the job salary from the job page\n",
    "    #TODO\n",
    "\n",
    "    # Get the job contract type from the job page\n",
    "    # Find the main list container (optional, but good practice if multiple lists exist)\n",
    "    criteria_list_ul = soup.find('ul', class_='description__job-criteria-list')\n",
    "\n",
    "\n",
    "    # Check if the main list was found\n",
    "    if criteria_list_ul:\n",
    "        # Find all list items within this specific list\n",
    "        list_items = criteria_list_ul.find_all('li', class_='description__job-criteria-item')\n",
    "\n",
    "        # Iterate through each list item\n",
    "        for item in list_items:\n",
    "            # Find the subheader (h3) for the criterion name\n",
    "            subheader_tag = item.find('h3', class_='description__job-criteria-subheader')\n",
    "            # Find the text span for the criterion value\n",
    "            # Using the more specific class 'description__job-criteria-text--criteria' is slightly safer\n",
    "            value_tag = item.find('span', class_='description__job-criteria-text--criteria')\n",
    "\n",
    "            # Ensure both tags were found before extracting text\n",
    "            if subheader_tag and value_tag:\n",
    "                # Extract text and clean whitespace (strip removes leading/trailing spaces/newlines)\n",
    "                criterion_name = subheader_tag.get_text(strip=True)\n",
    "                criterion_value = value_tag.get_text(strip=True)\n",
    "\n",
    "                # Add the key-value pair to the dictionary\n",
    "                job_info[criterion_name] = criterion_value\n",
    "            else:\n",
    "                # Optional: Print a warning if the structure is unexpected within an item\n",
    "                print(f\"Warning: Skipping item, couldn't find expected h3/span: {item.prettify()}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Could not find the 'ul' with class 'description__job-criteria-list'.\")\n",
    "\n",
    "\n",
    "    return job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"data engineer\",\n",
    "            \"data enginer\",\n",
    "            \"ingeniero de datos\",\n",
    "            \"ingeniero datos\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Obtiene el objeto soup que contiene las jobcards\n",
    "    soup = get_jobcards_soup()\n",
    "\n",
    "    # Devuelve una lista de diccionarios con la informaci√≥n de las jobcards (title, company, location, date, job_url)\n",
    "    joblist = get_list_of_jobcards(soup)\n",
    "    job_description = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Data Engineer Junior',\n",
       "  'company': 'LISIT',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294902/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst I',\n",
       "  'company': 'Principal Chile',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4187514059/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'Xepelin',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205474021/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'BC Tecnolog√≠a',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297472/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': '2Brains',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294882/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'Falabella',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207045620/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'NeuralWorks',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205500303/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos',\n",
       "  'company': 'Devaid',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205299283/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer (GCP & DataFlow & Bigquery)',\n",
       "  'company': 'Option',\n",
       "  'location': 'Santiago Metropolitan Area',\n",
       "  'date': '2025-04-12',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4208792219/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'ICONSTRUYE',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205295718/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos ($1.400.000 l√≠quidos)',\n",
       "  'company': 'Vector',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4203857279/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer Soluciones de Datos',\n",
       "  'company': 'LISIT',\n",
       "  'location': 'Biob√≠o Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294845/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'Seeds',\n",
       "  'location': 'Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4189755534/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Senior Data Engineer Python',\n",
       "  'company': '23people',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294906/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de datos',\n",
       "  'company': 'Ripley Chile',\n",
       "  'location': 'Las Condes, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-08',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204266753/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Graduate 2025 Software Engineer I Backend, Chile',\n",
       "  'company': 'Uber',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205853556/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos/ Dbt',\n",
       "  'company': 'BC Tecnolog√≠a',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205500332/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst',\n",
       "  'company': 'Macal Remates',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205298423/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos Maestros (Proyecto Corporativo)',\n",
       "  'company': 'Agrosuper',\n",
       "  'location': \"Rancagua, O'Higgins Region, Chile\",\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297494/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos',\n",
       "  'company': 'AyCA SpA',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206696535/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer AWS ‚Äì Contrato Indefinido.',\n",
       "  'company': 'BC Tecnolog√≠a',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204878459/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer ‚Äì Proyecto de 6 Meses',\n",
       "  'company': 'BC Tecnolog√≠a',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297473/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer',\n",
       "  'company': 'NeuralWorks',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205295705/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de Datos en GCP',\n",
       "  'company': 'BC Tecnolog√≠a',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294840/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de Datos',\n",
       "  'company': 'MindCo',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205553758/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de Datos',\n",
       "  'company': 'Outlier',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207881229/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Senior Data Engineer',\n",
       "  'company': 'Grupo Falabella',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205321119/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'Mediastream',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206504298/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer AWS',\n",
       "  'company': 'BC Tecnolog√≠a',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294910/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst',\n",
       "  'company': 'LISIT',\n",
       "  'location': 'Los √Ångeles, Biob√≠o Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297449/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer Python',\n",
       "  'company': 'Equifax',\n",
       "  'location': 'Providencia, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4165780801/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer GCP',\n",
       "  'company': 'Soluciones - Data & Analytics Consulting',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206574777/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Senior Data Engineer',\n",
       "  'company': '23people',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207846989/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer AWS',\n",
       "  'company': 'Soluciones - Data & Analytics Consulting',\n",
       "  'location': 'Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207848749/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer Senior',\n",
       "  'company': 'Equifax',\n",
       "  'location': 'Las Condes, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4144902157/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer Semisenior o Senior',\n",
       "  'company': 'LISIT',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297492/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos',\n",
       "  'company': 'Amaris Consulting',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206597362/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de Datos',\n",
       "  'company': 'Outlier',\n",
       "  'location': 'La Serena, Coquimbo Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207883217/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer - GCP Ssr',\n",
       "  'company': 'axity',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204875774/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Gobierno de Datos - Subgerencia de Gobierno de Datos',\n",
       "  'company': 'Consorcio',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-08',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204238135/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer - AWS Ssr',\n",
       "  'company': 'axity',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204874848/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero en Gesti√≥n de Datos',\n",
       "  'company': 'Genesys',\n",
       "  'location': 'Las Condes, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206087107/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer',\n",
       "  'company': 'IGX',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205299322/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Consultor Data Analyst',\n",
       "  'company': 'LISIT',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297448/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer',\n",
       "  'company': 'Banco Falabella',\n",
       "  'location': 'Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205421235/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer Azure',\n",
       "  'company': '',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206654598/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer',\n",
       "  'company': 'ZeroFox',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4203138895/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Backoffice - Analista de datos',\n",
       "  'company': 'Infinity Ingenieria SPA',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204075434/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de datos de Farmacia',\n",
       "  'company': 'IQVIA',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-12',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4208763580/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst Power BI- Bigquery',\n",
       "  'company': 'Soluciones - Data & Analytics Consulting',\n",
       "  'location': 'Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207890015/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst Senior Modelos y Datos Riesgo',\n",
       "  'company': 'Banco Bci',\n",
       "  'location': 'Las Condes, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-08',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4203767105/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Insights Specialist',\n",
       "  'company': 'Nestl√©',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4202697660/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst I - Operations',\n",
       "  'company': 'Signant Health',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4202554692/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer II, Gerencia Tecnolog√≠a',\n",
       "  'company': 'Walmart Chile',\n",
       "  'location': 'Huechuraba, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206684576/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer III, Gerencia Tecnolog√≠a',\n",
       "  'company': 'Walmart Chile',\n",
       "  'location': 'Huechuraba, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206686540/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Salesforce Software Engineer',\n",
       "  'company': 'Banco Falabella',\n",
       "  'location': 'Santiago Metropolitan Area',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4203137306/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista BI',\n",
       "  'company': 'Chubb',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4208212282/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer III',\n",
       "  'company': 'Mindbody',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-13',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4169374324/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Senior Software Engineer, Backend (Remote)',\n",
       "  'company': 'Mindbody',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-12',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4170144703/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Senior Data Engineer',\n",
       "  'company': 'Grupo Falabella',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205465977/',\n",
       "  'job_description': ''}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Getting job description for Data Engineer Junior in LISIT\n",
      "Job description starts with: En Lisit, \n",
      "------------------------------\n",
      "Getting job description for Data Engineer in Xepelin\n",
      "Job description starts with: Somos una \n",
      "------------------------------\n",
      "Getting job description for Data Engineer in BC Tecnolog√≠a\n",
      "Error: Could not find the 'ul' with class 'description__job-criteria-list'.\n",
      "Job description starts with: Could not \n",
      "------------------------------\n",
      "Getting job description for Data Engineer in 2Brains\n",
      "Job description starts with: 2Brains es\n",
      "------------------------------\n",
      "Getting job description for Data Engineer in Falabella\n",
      "Job description starts with: Descripci√≥\n",
      "------------------------------\n",
      "Getting job description for Data Engineer in NeuralWorks\n",
      "Job description starts with: NeuralWork\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos in Devaid\n",
      "Job description starts with: En Devaid>\n",
      "------------------------------\n",
      "Getting job description for Data Engineer (GCP & DataFlow & Bigquery) in Option\n",
      "Job description starts with: ¬øQui√©nes s\n",
      "------------------------------\n",
      "Getting job description for Data Engineer in ICONSTRUYE\n",
      "Job description starts with: En ICONSTR\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos ($1.400.000 l√≠quidos) in Vector\n",
      "Job description starts with: Somos una \n",
      "------------------------------\n",
      "Getting job description for Data Engineer Soluciones de Datos in LISIT\n",
      "Job description starts with: En *Lisit*\n",
      "------------------------------\n",
      "Getting job description for Data Engineer in Seeds\n",
      "Job description starts with: ¬øSos \n",
      "Data\n",
      "------------------------------\n",
      "Getting job description for Senior Data Engineer Python in 23people\n",
      "Job description starts with: √önete a Eq\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos/ Dbt in BC Tecnolog√≠a\n",
      "Job description starts with: En BC Tecn\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos Maestros (Proyecto Corporativo) in Agrosuper\n",
      "Job description starts with: En Agrosup\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos in AyCA SpA\n",
      "Job description starts with: Company De\n",
      "------------------------------\n",
      "Getting job description for Data Engineer AWS ‚Äì Contrato Indefinido. in BC Tecnolog√≠a\n",
      "Job description starts with: Company De\n",
      "------------------------------\n",
      "Getting job description for Data Engineer ‚Äì Proyecto de 6 Meses in BC Tecnolog√≠a\n",
      "Job description starts with: En BC Tecn\n",
      "------------------------------\n",
      "Getting job description for Senior Data Engineer in Grupo Falabella\n",
      "Job description starts with: Somos m√°s \n",
      "------------------------------\n",
      "Getting job description for Data Engineer in Mediastream\n",
      "Job description starts with: Descriptio\n",
      "------------------------------\n",
      "Getting job description for Data Engineer AWS in BC Tecnolog√≠a\n",
      "Job description starts with: En \n",
      "BC Tec\n",
      "------------------------------\n",
      "Getting job description for Data Engineer GCP in Soluciones - Data & Analytics Consulting\n",
      "Job description starts with: ‚úîÔ∏è\n",
      "¬øQui√©ne\n",
      "------------------------------\n",
      "Getting job description for Senior Data Engineer in 23people\n",
      "Job description starts with: ¬°Hola! Est\n",
      "------------------------------\n",
      "Getting job description for Data Engineer AWS in Soluciones - Data & Analytics Consulting\n",
      "Job description starts with: ‚úîÔ∏è\n",
      "¬øQui√©ne\n",
      "------------------------------\n",
      "Getting job description for Data Engineer Senior in Equifax\n",
      "Job description starts with: Como Data \n",
      "------------------------------\n",
      "Getting job description for Data Engineer Semisenior o Senior in LISIT\n",
      "Job description starts with: Lisit es u\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos in Amaris Consulting\n",
      "Job description starts with: Who are we\n",
      "------------------------------\n",
      "Getting job description for Data Engineer - GCP Ssr in axity\n",
      "Job description starts with: Company De\n",
      "------------------------------\n",
      "Getting job description for Data Engineer - AWS Ssr in axity\n",
      "Job description starts with: Company De\n",
      "------------------------------\n",
      "Getting job description for Data Engineer Azure in \n",
      "Job description starts with: Resumen de\n",
      "------------------------------\n",
      "Getting job description for Senior Data Engineer in Grupo Falabella\n",
      "Job description starts with: Descripci√≥\n"
     ]
    }
   ],
   "source": [
    "# A la lista de trabajos se le agrega info extra de cada trabajo\n",
    "for job in joblist:\n",
    "    \n",
    "    # Verifica si el titulo del trabajo contiene alguna de las palabras clave\n",
    "    if any(keyword in job['title'].lower() for keyword in keywords):\n",
    "        \n",
    "        # Agregar descripci√≥n del trabajo, salario, tipo de contrato\n",
    "        try:\n",
    "            print('-' * 30)\n",
    "            print(f'Getting job description for {job[\"title\"]} in {job[\"company\"]}')\n",
    "\n",
    "            time.sleep(random.randint(2, 5))\n",
    "\n",
    "            # Ac√° se busca la descripcion del trabajo\n",
    "            job_info = get_job_info(get_data(job['job_url']))\n",
    "            job.update(job_info)\n",
    "            print('Job description starts with:', job_info['job_description'][:10])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Error getting job description for {job[\"title\"]} in {job[\"company\"]}: {e}')\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert joblist to JSON\n",
    "joblist_json = json.dumps(joblist, indent=4)\n",
    "\n",
    "# Export to JSON file\n",
    "with open('joblist.json', 'w') as json_file:\n",
    "    json_file.write(joblist_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "{'title': 'Data Engineer Junior', 'company': 'LISIT', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294902/', 'job_description': 'En Lisit, nos dedicamos a crear, desarrollar e implementar herramientas y servicios de software que automatizan y optimizan procesos, siempre con un fuerte enfoque en la innovaci√≥n y los desaf√≠os que se presentan. Nuestro objetivo es fomentar la eficacia operativa de nuestros clientes, ayud√°ndoles a alcanzar sus metas de transformaci√≥n mediante un acompa√±amiento consultivo integral. Actualmente, estamos en b√∫squeda de un Data Engineer Junior que se una a nuestro equipo apasionado por la tecnolog√≠a y el aprendizaje continuo.\\n Funciones del Rol\\nComo Data Engineer Junior, Ser√°s Parte Esencial Del Equipo Encargado De Manejar y Optimizar El Flujo De Datos De La Organizaci√≥n. Tus Principales Responsabilidades Incluir√°n\\n- Colaborar en la recopilaci√≥n y procesamiento de datos relacionales y no relacionales.\\n- Trabajar con lenguajes de programaci√≥n, especialmente Python, para crear soluciones de datos efectivas.\\n- Implementar y mantener los procesos de integraci√≥n en ambientes cloud como GCP o Azure.\\n- Realizar consultas y manipulaci√≥n de bases de datos utilizando SQL.\\n- Aprender y adaptarte a nuevas tecnolog√≠as y herramientas en el entorno de la nube.\\n Descripci√≥n del Perfil\\nBuscamos Un Perfil Proactivo, Con Conocimientos Intermedios En Python y Disposici√≥n Para Aprender Sobre Nuevas Tecnolog√≠as. El Candidato Ideal Deber√° Tener\\n- Experiencia b√°sica a intermedia en programaci√≥n Python.\\n- Habilidades en el uso y tratamiento de datos en ambientes tanto relacionales como no relacionales.\\n- Conocimientos fundamentales en tecnolog√≠as de nube, incluyendo GCP o Azure.\\n- Experiencia en el uso del lenguaje SQL.\\n- Bajo es requisito pero se valorar√° el conocimiento en Power BI.\\n Habilidades Deseables\\nSer√≠a excelente contar con conocimientos adicionales en herramientas de visualizaci√≥n de datos como Power BI. Adem√°s, habilidad para trabajar en equipo y una mentalidad orientada al aprendizaje continuo son altamente valoradas.\\n Beneficios de Trabajar con Nosotros\\nEn Lisit, Promovemos Un Ambiente De Trabajo Excepcional\\n- Acceso a oportunidades de desarrollo profesional continuo en tecnolog√≠as emergentes.\\n- Un equipo apasionado por la innovaci√≥n y el aprendizaje, donde tu entusiasmo ser√° bienvenido.        \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst I', 'company': 'Principal Chile', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4187514059/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'Xepelin', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4205474021/', 'job_description': 'Somos una FinTech que busca democratizar los servicios financieros para todo tipo de empresas. Nos apalancamos en la mejor tecnolog√≠a para crear soluciones √°giles, personalizadas y transparentes. Nuestro objetivo es ser la FinTech B2B m√°s grande de Latam y convertirnos en el CFO digital de todas las empresas en la regi√≥n.\\nXepelin nace en Chile en 2019 y, desde entonces, hemos levantado m√°s de USD145 millones en equity y USD300 millones en asset-backed facilities para potenciar el crecimiento en toda la regi√≥n, especialmente en los pa√≠ses donde hoy operamos, Chile y M√©xico. La √∫ltima ronda de equity fue de USD111 millones, record en Chile y una de las m√°s grandes en Am√©rica Latina para una FinTech.\\n¬øPor qu√© trabajar en Xepelin?\\nüí™ Desaf√≠o\\nEstamos sacudiendo una de las industrias m√°s poderosas y competitivas, eliminando fricciones para darle a las Pymes acceso a capital y apalancado en la √∫ltima tecnolog√≠a disponible. Todo esto poniendo siempre a nuestras Pymes en el centro.\\nConstruir un banco digital desde cero es un gran proyecto; el producto es complejo y no se puede romper, existen regulaciones estrictas y tendremos que ser mejores que algunas de las corporaciones m√°s grandes y consolidadas del mundo. Pero superar estos desaf√≠os significa que habremos construido algo duradero.\\nüí• Impacto\\nTrabajar en un equipo de clase mundial y automotivado significa autonom√≠a, amplia experiencia en todos los proyectos y ver que tus contribuciones afectan directamente al producto e impactan a nuestras Pymes.\\nTrabajar√°s con todos nuestros productos, tendr√°s que tomar decisiones fundamentales. El correcto posicionamiento de ellos marcar√° su futuro.\\n‚úîÔ∏è Calidad\\nNuestro posicionamiento de marca y productos es algo diferenciador frente al resto del mercado por lo que invertimos mucho en crear productos de calidad que nuestras Pymes respeten y valoren.\\nNos damos el tiempo para pensar fuera de la caja y volver con propuestas innovadoras. Estamos aqu√≠ para cambiar la industria!\\n¬øQu√© estamos buscando? \\nEn Xepelin estamos buscando personas creativas y visionarias que piensen fuera de la caja para sumarse a nuestro equipo. Si te apasiona resolver desaf√≠os interesantes de alto impacto y quieres ser parte de un entorno din√°mico que est√° transformando la industria financiera, ¬°Esta oportunidad es para ti!\\nEl rol se integrar√° a nuestro equipo de \\nData Platform\\n. Si te motiva el desaf√≠o de construir soluciones innovadoras en un entorno de r√°pido cambio, queremos conocerte.\\nUnete a nosotros, crezcamos juntos!\\nPrincipales responsabilidades...\\n-  Dise√±ar, crear y mantener pipelines de datos\\n-  Mantener y optimizar la infraestructura de datos necesaria para una extracci√≥n precisa, transformaci√≥n y carga de datos de una amplia variedad de fuentes de datos\\n-  Automatizar los flujos de trabajo de datos, como la ingesta de datos, la agregaci√≥n y el procesamiento de ETL o ELT\\n-  Preparar datos sin procesar en almacenes de datos en un conjunto de datos consumibles para fines t√©cnicos y partes interesadas no t√©cnicas\\n-  Crear, mantener e implementar productos de datos para equipos de an√°lisis y ciencia de datos en Plataformas en la nube, preferentemente en GCP, y/o AWS\\n-  Desarrollar sistemas y arquitectura que soporten las diferentes etapas del flujo de Machine Learning\\n¬øQu√© necesitas para brillar?\\n- Conocimientos en alguna Nube, preferentemente GCP o AWS (en ese orden de preferencia)\\n- Conocimientos intermedio/avanzado en Python\\n- Conocimiento intermedio/avanzado de SQL\\n- Experiencia trabajando almacenamiento en la nube como GCS o AWS S3\\n- Experiencia desplegando aplicaciones en ambientes serverless como Cloud Functions o AWS Lambda\\n- Conocimientos administrando y desplegando alg√∫n orquestador, por ejemplo: Dagster, Apache Airflow, Prefect, etc\\n- Excelentes habilidades para trabajar en equipo. Ser humilde y saber colaborar, un Team Player!\\n- Saber escuchar a tus stakeholders y poder traducir eso en requerimientos y ejecutarlos con tu equipo\\n- Trabajo proactivo y responsable\\n- Conocimientos en DBT\\n- Conocimientos y manejo de lenguajes de programaci√≥n y/o frameworks, NodeJS, Golang, por ejemplo\\n- Experiencia en MLOps\\n- No tener miedo a tomar decisiones y liderar proyectos\\n- Foco en impacto e historia consistente entregando resultados para usuarios y el negocio\\n- Capacidad para pensar en grande y desarrollar iniciativas con impacto real y medible\\n- Te sientes c√≥modo cuestionando el status-quo de los servicios financieros, adapt√°ndose r√°pidamente a los cambios, y presentando claramente tus ideas y conceptos para debatirlos en equipo\\nNuestros Beneficios:\\nüå¥ Xepelin Balance\\nVacaciones:\\n 15 d√≠as h√°biles. Por cada a√±o que cumplas en Xepelin, te damos un d√≠a extra de vacaciones.\\nBalance days:\\n 10 d√≠as libres adicionales al a√±o, para disfrutar como quieras.\\nTrabajo h√≠brido y flexibilidad horaria seg√∫n el rol. Trabajamos por objetivos.\\nBeneficios Flexibles: \\nPuntos flexibles en tu moneda local al mes para gastar en lo que quieras.\\nXepelin Fun:\\n Actividades de encuentro financiadas por Xepelin para divertirnos juntos.\\nüöÄ Xepelin Performance & Career\\nPlataformas de capacitaci√≥n:\\n Convenios con las mejores plataformas, como Reforge, Udemy y DataCamp.\\nKit de Bienvenida: \\ntodo lo que necesitas para comenzar tu viaje en Xepelin üòä\\nü§ù Xepelin Cares\\nCobertura de salud:\\n contamos con convenios de salud con proveedores de calidad o reembolsos seg√∫n el pa√≠s donde te encuentres.\\nPost Natal:\\n te damos una semana extra de licencia post natal. ¬°Nos interesa que est√©s con tu familia y seres queridos!\\nMatrimonio plus:\\n Lleva tus planes al siguiente nivel, con una gift card y extendiendo tu permiso legal por matrimonio con dos d√≠as de regalo por Xepelin.        \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Software Development, IT Services and IT Consulting, and Biotechnology Research'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'BC Tecnolog√≠a', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297472/', 'job_description': 'Could not find Job Description'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': '2Brains', 'location': 'Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294882/', 'job_description': '2Brains es una empresa dedicada a construir y desarrollar el Futuro Digital de nuestros clientes, con una visi√≥n excepcional que radica en la integraci√≥n sin√©rgica de estrategia, dise√±o y tecnolog√≠a, un tr√≠ptico poderoso que impulsa el crecimiento de empresas y disruptores tecnol√≥gicos.\\nContamos con un nutrido equipo de m√°s de 200 profesionales, verdaderos art√≠fices de la innovaci√≥n digital. En el coraz√≥n de nuestra labor, destacamos como l√≠deres indiscutibles, canalizando a√±os de experiencia hacia la creaci√≥n de plataformas tecnol√≥gicas adaptables y productos digitales de clase mundial.\\nEn 2Brains, no solo somos consultores, somos arquitectos de experiencias digitales. Aspiramos a ir m√°s all√° de las expectativas, estableciendo nuevos est√°ndares en la industria. Descubre c√≥mo damos vida a la innovaci√≥n, c√≥mo convertimos ideas en resultados tangibles y c√≥mo, junto a nosotros, puedes forjar un futuro digital brillante.\\n El/la Data Engineer de 2Brains \\nSe encarga de participar en el dise√±o y desarrollo de los nuevos modelos de informaci√≥n de gesti√≥n y las mantenciones evolutivas de los existentes. Participar en las iniciativas de Anal√≠tica avanzada del √°rea, apoyando las exploraci√≥n de modelos de informaci√≥n internos y externos (Data Discovery). Obtener datos hist√≥ricos desde m√∫ltiples fuentes de informaci√≥n interna para apoyar las iniciativas de anal√≠tica avanzada del equipo.\\nEl/la Data Engineer de 2Brains debe\\n- Construir y optimizar pipelines de datos para la ingesta, transformaci√≥n y carga eficiente de informaci√≥n.\\n- Manejar infraestructuras en la nube (AWS, GCP, Azure), asegurando escalabilidad y eficiencia en costos.\\n- Automatizar y monitorear procesos mediante herramientas de DevOps como Airflow, Terraform o Kubernetes.\\n- Implementar controles de calidad y gobernanza para garantizar la integridad y disponibilidad de los datos.\\n- Colaborar con equipos de Data Science, Producto y Desarrollo para dise√±ar soluciones alineadas con las necesidades del negocio.\\n Qu√© conocimientos buscamos en/la Data Engineer\\n- Excluyente Experiencia trabajando con tecnolog√≠as de BI\\n- Experiencia en la construcci√≥n/operaci√≥n de sistemas distribuidos de extracci√≥n, ingesti√≥n y procesamiento de grandes conjuntos de datos de gran disponibilidad.\\n- Capacidad demostrable en modelado de datos, desarrollo de ETL y almacenamiento de datos.\\n- Experiencia en el uso de herramientas de informes de inteligencia empresarial (Power BI)\\n- Excluyente conocimiento en consumo de microservicios de APIs Rest\\n- Excluyente conocimiento en Git , Bitbucket, Docker,Jenkins,Webhooks\\n- Programaci√≥n con Python y bases s√≥lidas de ingenier√≠a de software.\\n- Automatizaci√≥n y scripting.\\n- Uso de librer√≠as de Python para manipulaci√≥n y an√°lisis de datos y Apache Spark.\\n- Conocimientos en bases de datos SQL y NoSQL.\\n- Conocimiento en CI/CD, Dataflow\\n- Conocimiento en S3, Redshift y Glue AWS\\n Que competencias buscamos en/la Data Engineer \\n- Empat√≠a\\n- Buena capacidad de comunicaci√≥n.\\n- Colaboraci√≥n y trabajo en equipo.\\n- Proactividad.\\n- Autonom√≠a.\\n- Foco en los objetivos de proyectos.\\n Condiciones\\nTrabajar con un equipo de alto rendimiento, aprendemos y nos desarrollamos juntos\\nAcceso a grandes clientes y proyectos desafiantes\\nAprendizaje y crecimiento permanente, organizamos meetups, capacitaciones y actividades culturales\\nUn entorno de trabajo flexible y din√°mico\\nBeneficios especiales: d√≠a libre para tu cumplea√±os, d√≠as de descanso a convenir.\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'Falabella', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207045620/', 'job_description': 'Descripci√≥n Empresa\\nSomos m√°s de 80 mil personas que cada d√≠a trabajamos por el firme Prop√≥sito - Simplificar y Disfrutar m√°s la Vida. Estamos presentes en 9 pa√≠ses y compuestos por grandes marcas posicionadas de diversas industrias. Falabella Retail, Sodimac, Banco Falabella, Tottus, Mallplaza, Falabella.com, Falabella Inmobiliario. Cada una de √©stas nos hace ser quienes somos, y es entre todos, como Un Solo Equipo, que buscamos diariamente reinventarnos y superar las experiencias de nuestros clientes.\\nSi eres trabajador de Falabella, revisa todos los cursos disponibles en la Academia Falabella, que te ayudar√°n a seguir impulsando tu desarrollo y preparar tu pr√≥xima aventura con nosotros!\\nSOMOS UNA EMPRESA QUE APOYA LA LEY 21015, APOYAMOS LA DIVERSIDAD Y LA INCLUSI√ìN EN TODAS SUS FORMAS, SIN IMPORTAR RELIGI√ìN, RAZA, G√âNERO, SITUACI√ìN DE DISCAPACIDAD, NACIONALIDAD.\\nFunciones Del Cargo\\n¬°Si tienes una mente inquieta y te gusta so√±ar en grande, este llamado es para ti!\\nEn Falabella Retail buscamos a nuestro/a pr√≥ximo/a Data Engineer, con base en Santiago, Chile.\\nSomos Falabella, UN equipo diverso con m√°s de 100 mil colaboradores compuesto por grandes marcas: Falabella Retail, Sodimac, Banco Falabella, Seguros Falabella, Tottus, Mallplaza, Open Plaza y Linio. Hoy tenemos presencia en 7 pa√≠ses de Am√©rica Latina, adem√°s de oficinas en China e India.\\n¬øCu√°l es el principal objetivo del cargo?\\nLiderar la construcci√≥n y mantenci√≥n de estructuras de datos, as√≠ como la arquitectura tecnol√≥gica requerida para el procesamiento de apps.\\n¬øQu√© har√°s en el d√≠a a d√≠a?\\n-  Desarrollo, implementaci√≥n de procesos ETL.\\n-  Levantamiento de requerimientos funcionales y t√©cnicos relacionados con los clientes internos.\\n-  Implementar modelos de datos automatizados para transformar datos de acuerdo a los requisitos del negocio.\\n-  Migraci√≥n de datos desde entornos on-premise a entornos Cloud.\\n-  Trabajar con tecnolog√≠as Google Cloud Platform (Big Query).\\n¬øQu√© necesitas para postular?\\n-  Profesional: Ingenier√≠a Civil en Computaci√≥n, Inform√°tica, Sistemas o carrera af√≠n.\\n-  Conocimiento en SQL (excluyente)\\n-  S√≥lidos conocimientos en Google Cloud Platform (excluyente)\\n-  Conocimiento avanzado en Python (excluyente)\\n-  Conocimiento y experiencia trabajando en GIT (excluyente)\\n-  Disponibilidad para ir a la oficina al menos 2 veces por semana (Las Condes) (excluyente)\\nEn Nuestro Equipo Encontrar√°s\\n-  Espacios para crear e innovar.\\n-  Ser√°s parte de un lugar lleno de oportunidades de desarrollo.\\n-  Tener un trabajo con sentido y donde se promueve la calidad de vida.\\n-  Participar en voluntariados.\\n-  ¬°Pertenecer a una empresa llena de energ√≠a!\\nSi disfrutas nuevos desaf√≠os con alta responsabilidad y exposici√≥n en el epicentro de la transformaci√≥n del retail en Latinoam√©rica, ¬°s√∫mate a trabajar con nosotros!\\nSomos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusi√≥n en todas sus formas, sin importar religi√≥n, raza, g√©nero, situaci√≥n de discapacidad, nacionalidad.\\nRequisitos\\n- Profesional: Ingenier√≠a Civil en Computaci√≥n, Inform√°tica, Sistemas o carrera af√≠n.\\n- Conocimiento en SQL (excluyente)\\n- S√≥lidos conocimientos en Google Cloud Platform (excluyente)\\n- Conocimiento avanzado en Python (excluyente)\\n- Conocimiento y experiencia trabajando en GIT (excluyente)\\n- Disponibilidad para ir a la oficina al menos 2 veces por semana (Las Condes) (excluyente)\\nCondiciones Oferta\\nDescripci√≥n proceso de selecci√≥n:\\nEl proceso de selecci√≥n se realiza a trav√©s de Aira - plataforma de reclutamiento dise√±ado para mejorar tu experiencia de postulaci√≥n.\\nPara Postular Solo Necesitas\\n-  Postular a la oferta\\n-  Revisar tu email\\n-  Ingresar a Aira y contestar las preguntas y/o pruebas solicitadas\\nLuego, si vemos que tu perfil se ajusta a lo que estamos buscando, te contactaremos por email (a trav√©s de Aira) para seguir a la etapa presencial.\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Retail'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'NeuralWorks', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205500303/', 'job_description': 'NeuralWorks es una compa√±√≠a de alto crecimiento fundada hace 3 a√±os. Estamos trabajando a toda m√°quina en cosas que dar√°n que hablar.\\nSomos un equipo donde se unen la creatividad, curiosidad y la pasi√≥n por hacer las cosas bien. Nos arriesgamos a explorar fronteras donde otros no llegan: un modelo predictor basado en monte carlo, una red convolucional para detecci√≥n de caras, un sensor de posici√≥n bluetooth, la recreaci√≥n de un espacio ac√∫stico usando finite impulse response.\\nEstos son solo algunos de los desaf√≠os, donde aprendemos, exploramos y nos complementamos como equipo para lograr cosas impensadas.\\nTrabajamos en proyectos propios y apoyamos a corporaciones en partnerships donde codo a codo combinamos conocimiento con creatividad, donde imaginamos, dise√±amos y creamos productos digitales capaces de cautivar y crear impacto.\\nüëâ Conoce m√°s sobre nosotros\\n Descripci√≥n del trabajo\\nEl equipo de Data y Analytics trabaja en diferentes proyectos que combinan vol√∫menes de datos enormes e IA, como detectar y predecir fallas antes que ocurran, optimizar pricing, personalizar la experiencia del cliente, optimizar uso de combustible, detectar caras y objetos usando visi√≥n por computador.\\nDentro del equipo multidisciplinario con Data Scientist, Translators, DevOps, Data Architect, tu rol ser√° clave en construir y proveer los sistemas e infraestructura que permiten el desarrollo de estos servicios, formando los cimientos sobre los cuales se construyen los modelos que permiten generar impacto, con servicios que deben escalar, con alt√≠sima disponibilidad y tolerantes a fallas, en otras palabras, que funcionen. Adem√°s, mantendr√°s tu mirada en los indicadores de capacidad y performance de los sistemas.\\nEn cualquier proyecto que trabajes, esperamos que tengas un gran esp√≠ritu de colaboraci√≥n, pasi√≥n por la innovaci√≥n y el c√≥digo y una mentalidad de automatizaci√≥n antes que procesos manuales.\\nComo Data Engineer, Tu Trabajo Consistir√° En\\n- Participar activamente durante el ciclo de vida del software, desde inception, dise√±o, deploy, operaci√≥n y mejora.\\n- Apoyar a los equipos de desarrollo en actividades de dise√±o y consultor√≠a, desarrollando software, frameworks y capacity planning.\\n- Desarrollar y mantener arquitecturas de datos, pipelines, templates y est√°ndares.\\n- Conectarse a trav√©s de API a otros sistemas (Python)\\n- Manejar y monitorear el desempe√±o de infraestructura y aplicaciones.\\n- Asegurar la escalabilidad y resiliencia.\\n Calificaciones clave\\n- Estudios de Ingenier√≠a Civil en Computaci√≥n o similar.\\n- Experiencia pr√°ctica de al menos 3 a√±os en entornos de trabajo como Data Engineer, Software Engineer entre otros.\\n- Experiencia con Python. Entendimiento de estructuras de datos con habilidades anal√≠ticas relacionadas con el trabajo con conjuntos de datos no estructurados, conocimiento avanzado de SQL, incluida optimizaci√≥n de consultas.\\n- Pasi√≥n en problem√°ticas de procesamiento de datos.\\n- Experiencia con servidores cloud (GCP, AWS o Azure), especialmente el conjunto de servicios de procesamiento de datos.\\n- Buen manejo de ingl√©s, sobre todo en lectura donde debes ser capaz de leer un paper, art√≠culos o documentaci√≥n de forma constante.\\n- Habilidades de comunicaci√≥n y trabajo colaborativo.\\n¬°En NeuralWorks nos importa la diversidad! Creemos firmemente en la creaci√≥n de un ambiente laboral inclusivo, diverso y equitativo. Reconocemos y celebramos la diversidad en todas sus formas y estamos comprometidos a ofrecer igualdad de oportunidades para todos los candidatos.\\n‚ÄúLos hombres postulan a un cargo cuando cumplen el 60% de las calificaciones, pero las mujeres s√≥lo si cumplen el 100%.‚Äù D. Gaucher , J. Friesen and A. C. Kay, Journal of Personality and Social Psychology, 2011.\\nTe invitamos a postular aunque no cumplas con todos los requisitos.\\n Nice to have\\n- Agilidad para visualizar posibles mejoras, problemas y soluciones en Arquitecturas.\\n- Experiencia en Infrastructure as code, observabilidad y monitoreo.\\n- Experiencia en la construcci√≥n y optimizaci√≥n de data pipelines, colas de mensajes y arquitecturas big data altamente escalables.\\n- Experiencia en procesamiento distribuido utilizando servicios cloud.\\n Beneficios\\n- MacBook Air M2 o similar (con opci√≥n de compra hiper conveniente)\\n- Bono por desempe√±o\\n- Bono de almuerzo mensual y almuerzo de equipo los viernes\\n- Seguro complementario de salud y dental\\n- Horario flexible\\n- Flexibilidad entre oficina y home office\\n- Medio d√≠a libre el d√≠a de tu cumplea√±os\\n- Financiamiento de certificaciones\\n- Inscripci√≥n en Coursera con plan de entrenamiento a medida\\n- Estacionamiento de bicicletas\\n- Vestimenta informal\\n- Programa de referidos\\n- Salida de ‚Äúteambuilding‚Äù mensual        \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos', 'company': 'Devaid', 'location': 'Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205299283/', 'job_description': 'En Devaid> nos apasionan los desaf√≠os tecnol√≥gicos y nuestros clientes lo saben. Por lo anterior, nos plantean problem√°ticas que nos obligan a estar constantemente probando e implementando nuevas tecnolog√≠as.\\nTrabajamos fuertemente en la nube ya que somos Partner Premier de Google Cloud en Chile, por lo que tendr√°s la oportunidad de formarte como un profesional cloud.\\nDependiendo de las necesidades del cliente, ofrece soluciones web, m√≥viles, integraci√≥n de sistemas, entre otros. Esto permite acceder a la herramienta sin importar el dispositivo ni el lugar d√≥nde se encuentra. Permitimos el trabajo colaborativo entre m√∫ltiples usuarios manteniendo una base centralizada de informaci√≥n.\\n Funciones del cargo\\nEsperamos Que Puedas Desempe√±arte En Las Siguientes Actividades\\n- Creaci√≥n de pipelines de carga y transformaci√≥n de datos.\\n- Modelamiento de datos y creaci√≥n de Data Warehouse y Data Lakes.\\n- Integraci√≥n de sistemas.\\n- Creaci√≥n de modelos de machine learning con herramientas low code autoML.\\nVas a participar como ingeniero de datos en equipos de consultores que prestan servicios a empresas importantes en Chile. En estos equipos participan distintos perfiles, tales como desarrolladores de software, arquitectos de datos y data scientists. Los servicios se prestan de forma remota y son prestados por proyecto (no es outsourcing de recursos), por lo que puedes trabajar desde tu casa sin problemas. Diariamente vas a tener reuniones con tu equipo para coordinar actividades y resolver temas complejos que vayan surgiendo.\\n Requerimientos del cargo\\nLos requisitos para un buen desempe√±o de las funciones son:\\n- 1 a√±o de experiencia como Data Engineer. \\n- Programaci√≥n en lenguaje Python, NodeJS o Java (al menos uno de los 3). \\n- Conocimiento de soluciones de Data Warehouse y ETL. \\n- Conocimiento de plataformas de procesamiento de datos como Apache Spark, Dataflow o similares. \\n- Haber trabajado previamente con alguna nube p√∫blica (AWS, Azure o GCP).\\nSi no cumples alguno de estos puntos no te desanimes, queremos conocerte igualmente.\\nEl trabajo es 100% remoto, pero es necesario que tengas RUT y/o papeles al d√≠a en Chile.\\n Deseables\\nSuman puntos en tu postulaci√≥n si cumples alguna de las siguientes habilidades, ninguno de estos son excluyentes:\\n- Conocimiento de herramientas Google Cloud, entre ellas Google BigQuery, Dataflow, Data Fusion y Pub Sub. \\n- Experiencia en plataformas de deployment de infraestructura como Terraform. \\n- Experiencia utilizando la herramienta de consola gcloud. \\n Beneficios\\nPrometemos un ambiente muy grato de trabajo, lleno de desaf√≠os y donde podr√°s ver los proyectos en los que estas involucrada/o siendo utilizados en un corto tiempo activamente por nuestros clientes, lo que siempre es muy gratificante.\\nOtras Actividades\\n- Actividades mensuales (Cupones de Food delivery, juegos en l√≠nea, actividades grupales).\\n- Actividad paseo anual: La empresa se junta por 2 d√≠as en alg√∫n lugar tur√≠stico para realizar actividades grupales y unir al equipo.\\n- D√≠a libre flexible en tu cumplea√±os.\\n- Capacitaciones en lo que m√°s te guste.\\n- Certificaciones Google Cloud: Programa de certificaci√≥n en distintas ramas profesionales de GCP, gracias a que somos Partner Premier de Google Cloud en Chile.        \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer (GCP & DataFlow & Bigquery)', 'company': 'Option', 'location': 'Santiago Metropolitan Area', 'date': '2025-04-12', 'job_url': 'https://www.linkedin.com/jobs/view/4208792219/', 'job_description': '¬øQui√©nes somos?\\nEn \\nOption\\n, creemos en un mundo donde las soluciones tecnol√≥gicas no tienen l√≠mites. Nuestra misi√≥n es transformar los desaf√≠os en oportunidades mediante la creaci√≥n de soluciones innovadoras que potencien la Aceleraci√≥n Digital. Nuestro equipo es din√°mico, colaborativo y apasionado por la tecnolog√≠a. √önete a una organizaci√≥n que est√° redefiniendo c√≥mo el mundo utiliza los datos y la tecnolog√≠a para resolver problemas complejos.\\n¬øQu√© buscamos?\\nEstamos en la b√∫squeda de un/a \\nIngeniero/a de Datos\\n para unirse al equipo de Data Services. Este rol ser√° clave en el levantamiento, an√°lisis y migraci√≥n de procesos ETL desde un Data Lake mal gobernado hacia una arquitectura moderna sobre Google Cloud Platform (GCP). ¬°Te estamos buscando!\\n¬øQu√© te ofrece este puesto?\\n- Participaci√≥n en un proceso estrat√©gico de migraci√≥n a la nube.\\n- Un entorno de trabajo colaborativo y con l√≠deres t√©cnicos accesibles.\\n- Uso de tecnolog√≠as modernas como GCP, Dataflow y BigQuery.\\n- Trabajo conjunto con equipos de anal√≠tica, desarrollo y operaci√≥n.\\n¬øCu√°les ser√°n tus principales responsabilidades?\\n- Levantar y documentar los ETLs actuales en Data Services.\\n- Analizar el ambiente de datos y planificar su migraci√≥n a GCP.\\n- Tomar iniciativa en la migraci√≥n de ETLs cr√≠ticos.\\n- Resolver incidencias relacionadas a ETLs mediante la mesa de ayuda.\\n- Participar en el dise√±o del plan de migraci√≥n.\\n- Colaborar con los l√≠deres t√©cnicos y equipos multidisciplinarios.\\n¬øQu√© necesitas para ser nuestro pr√≥ximo Ingeniero de Datos?\\nHabilidades T√©cnicas Excluyentes\\n- Oracle\\n- Python\\n- Dataflow (GCP)\\n- Dataform (GCP)\\n- GitLab\\n- BigQuery (GCP)\\n- Data Modeling\\n- Composer (GCP)\\nHabilidades T√©cnicas Deseables\\n- Oracle Data Integrator (ODI)\\nUbicaci√≥n: LATAM\\nModalidad de trabajo:\\n 100% Remoto\\n¬°√önete a nuestro equipo y transforma el futuro con nosotros!\\nhttps://www.option.tech        \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'ICONSTRUYE', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205295718/', 'job_description': 'En ICONSTRUYE, hemos estado a la vanguardia de la tecnolog√≠a en la construcci√≥n durante m√°s de 20 a√±os. Nuestra robusta plataforma tecnol√≥gica es un testimonio de nuestra experiencia y compromiso con la industria. Con m√°s de 4,000 clientes en Chile, Colombia y Per√∫, nos enorgullecemos de proporcionar soluciones integrales que simplifican la cadena de abastecimiento. Buscamos un Ingeniero de Datos que se una a nosotros en la transformaci√≥n de la industria de la construcci√≥n, siendo el puente entre los datos brutos y aquellos que toman decisiones cr√≠ticas.\\nTus Funciones Principales\\nTu misi√≥n:\\n Ser el puente entre los datos brutos y quienes necesitan realizar an√°lisis y/o tomar decisiones con esos datos.\\n- Garantizar la calidad, integridad y seguridad de los datos.\\n- Colaborar con diversos stakeholders para comprender sus necesidades de datos.\\n- Desarrollar procesos de extracci√≥n, transformaci√≥n y carga (ETL) de datos para nuestro data lake, proporcionando informaci√≥n valiosa para el an√°lisis y toma de decisiones.\\n- Implementar nuevas bases de datos y/o data warehouses para satisfacer las necesidades de la empresa.\\n- Contribuir a la definici√≥n de pol√≠ticas de gobernanza de datos.\\n- Ser una autoridad en la creaci√≥n, implementaci√≥n y operaci√≥n de soluciones escalables y de bajo costo, facilitando el flujo de datos desde sistemas de producci√≥n hasta el data lake.\\nRequerimientos T√©cnicos\\n- Dominio de Python o Go. \\n- Dominio de SQL. \\n- Conocimiento de base de datos relacionales y no relacionales (NoSQL). \\n- Conocimiento de AirFlow, Luigi, Dagster. \\n- Conocimientos de Kafka y/o RabbitMQ. \\n- Conocimiento en Docker y Kubernetes. \\nBeneficios Que Ofrecemos\\n- üå¥ 5 d√≠as extras de descanso al a√±o.\\n- üçî Tarjeta amipass para utilizar en restaurantes, delivery y supermercados.\\n- üë®\\u200d‚öïÔ∏è Seguro complementario de salud, dental y de vida.\\n- üè† Modalidad de trabajo h√≠brido.\\n- üì† Flexibilidad con permisos para tr√°mites y asuntos familiares.\\n- üë©\\u200düë¶ Jornada reducida en d√≠as de vacaciones escolares (viernes medio d√≠a).\\n- üéÇ Tarde libre en tu cumplea√±os.\\n¬°√önete a nosotros y s√© parte de nuestra misi√≥n de transformar la industria de la construcci√≥n!\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos ($1.400.000 l√≠quidos)', 'company': 'Vector', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4203857279/', 'job_description': 'Somos una empresa L√≠der en el rubro TI. Nos encontramos en la b√∫squeda de Ingeniero de Datos, con experiencia en extracci√≥n de datos desde los sistemas fuente de est√°ndares industriales y el√©ctricos y su almacenaje en los destinos correspondientes, as√≠ como tambi√©n el asegurar la continuidad del funcionamiento de aplicaciones y redes OT que proporcionan datos a PMAC y ROCC.\\nPrincipales Tareas\\n- Sistematizar el traspaso de datos desde los distintos sistemas de la compa√±√≠a hacia los repositorios correspondientes para su consumo.\\n- Participar en proyectos y entregar soluciones t√©cnicas, procesos y requisitos.\\n- Enfoque en la creaci√≥n de indicadores y KPI relevantes de las diferentes aplicaciones para reportar a nivel t√©cnico y administrativo.\\n- Realizar revisiones continuas de monitoreo para asegurarse de la continuidad del servicio.\\n- Monitorear y controlar solicitudes y requerimientos de soporte (gesti√≥n de tickets).\\n- Gestionar cualquier proceso de solicitud de cambio, asegur√°ndose de que todas las solicitudes est√©n debidamente documentadas y rastreadas. \\n- Entregar soporte para que los servicios de OT se entreguen de acuerdo con los procedimientos operativos est√°ndar y/o SLAs acordados; con enfoque en el servicio operativo, resoluci√≥n de problemas y respuesta √°gil para el usuario final.\\n- Escalar consultas complejas a la organizaci√≥n de soporte especializado correspondiente.\\n- Identificar oportunidades de mejora del servicio a partir del an√°lisis de tendencias de datos y las necesidades y aportes de los clientes/usuarios.\\n- Involucrarse con stakeholders clave y para comprender sus requisitos y transmitir al √°rea de resoluci√≥n correspondiente. \\nConocimientos y experiencia \\n- Estudios t√©cnicos o profesionales en Telecomunicaciones, Instrumentaci√≥n, Sistemas, Computaci√≥n, Inform√°tica, Electr√≥nica o carreras afines).\\n- Instrumentista con conocimiento en programaci√≥n y transferencia de datos, o Ingeniero de Datos con conocimiento en protocolos industriales y sus est√°ndares de comunicaci√≥n.\\n- Conocimientos de redes de comunicaciones y soluciones de transporte de datos.\\n- Gesti√≥n de datos y visualizaci√≥n usando herramientas cloud (Google, Microsoft).\\n- Conocimientos de un lenguaje de scripting, preferiblemente Python.\\n- Manejo b√°sico de base de datos SQL.\\n- Conocimientos b√°sicos en gesti√≥n de accesos e identidades.\\n- Conocimientos b√°sicos en administraci√≥n de servidores.\\n- Experiencia laboral de 5 a√±os preferiblemente en empresas industriales.\\n- Deseable manejo de ingles a nivel t√©cnico intermedio.\\nConocimientos espec√≠ficos\\n- Conocimiento de protocolos industriales del sector el√©ctrico (IEC-60870-5-104, Modbus, DNP 3.0).\\n- Protocolos Industriales de comunicaci√≥n: Modbus TCP/IP, JSON, CSV, DNP3, SQL.\\n- Conocimiento de sistemas SCADA.\\n- Conocimientos de protocolos de transici√≥n con industria 4.0 (Modbus TCP, OPC UA, MQTT, HTTP, etc.).\\nFundamentos de ciberseguridad.\\nHorario\\nLunes a viernes 08:00 a 18:00 / 08:30 a 18:30\\nBeneficios\\n-  Reajuste anual de sueldo de acuerdo a IPC\\n-  Bonificaci√≥n anual por desempe√±o laboral.\\n-  Posibilidad de acceder a cursos de capacitaci√≥n en las diversas tem√°ticas del cargo.\\n-  Convenios de Salud, Dentales y √≥pticos, accesos a descuentos preferenciales y facilidades de pagos mediante descuentos por planilla sin inter√©s.\\n-  Posibilidad de entrega de aguinaldo de fiestas patrias y Navidad conforme a cumplimiento de antig√ºedad.\\n-  Convenio seguro Oncol√≥gico a valor preferencial y con aporte de la organizaci√≥n y del colaborador.\\n-  Regalo de gift card por nacimiento de hijo (a).\\n-  Convenios bancarios (scotiabank y Banco de Chile) para planes de tarjetas de cuentas vista y corriente a valores preferenciales.        \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Contract', 'Job function': 'Information Technology', 'Industries': 'Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer Soluciones de Datos', 'company': 'LISIT', 'location': 'Biob√≠o Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294845/', 'job_description': 'En *Lisit*, nos dedicamos a crear, desarrollar e implementar servicios de software que ofrecen herramientas de automatizaci√≥n y optimizaci√≥n. Nuestra misi√≥n es promover la eficacia en la operatividad de nuestros clientes a trav√©s de un soporte consultivo que integra diversas herramientas y pr√°cticas. Buscamos contribuir al √©xito de las transformaciones empresariales mediante estrategias integrales de acompa√±amiento e implementaci√≥n.\\n Que estamos buscando\\n- Dise√±ar, desarrollar y mantener infraestructuras y pipelines de datos escalables y confiables.\\n- Optimizar el almacenamiento, procesamiento y recuperaci√≥n de datos para un funcionamiento eficiente e impecable.\\n- Colaborar con equipos de diferentes departamentos para recopilar y analizar los requisitos de datos.\\n- Garantizar la calidad, integridad y seguridad de los datos durante todo el ciclo de vida de estos.\\n- Mantenerse actualizado sobre los √∫ltimos avances, desarrollos y enfoques en ingenier√≠a de datos.\\n ¬øQu√© habilidades y experiencia necesitas?\\n- Fuertes habilidades anal√≠ticas y de resoluci√≥n de problemas.\\n- Al menos 3 a√±os de experiencia en ingenier√≠a de datos.\\n- Experiencia comprobada en el dise√±o y desarrollo de data pipelines y procesos ETL, preferiblemente con Azure Data Factory.\\n- Amplia experiencia en SQL y dominio de al menos un lenguaje de ingenier√≠a de datos, como Python o Scala.\\n- Experiencia con Spark, Airflow y tecnolog√≠as Big Data relacionadas.\\n- Familiaridad con plataformas de datos basadas en la nube como AWS, Azure o GCP.\\n- Excelentes habilidades de comunicaci√≥n y colaboraci√≥n.\\n Deseable\\nSe valorar√° la experiencia con herramientas de BI como Power BI y Microsoft Fabric. Tambi√©n es deseable contar con alguna de las siguientes certificaciones: DP-203, PL-300, DP-600 y/o DP-700.\\n √önete a nosotros\\nEn *Lisit* ofrecemos un ambiente de trabajo innovador y colaborativo. Nos aseguramos de que nuestros empleados disfruten de un equilibrio entre trabajo y vida personal, con programas de capacitaci√≥n y desarrollo continuo. Valoramos tu entusiasmo y pasi√≥n por la ingenier√≠a de datos.\\nEstamos emocionados por conocer a personas con una mentalidad abierta y dispuestas a enfrentar nuevos desaf√≠os. ¬°Si est√°s listo para innovar y crecer con nosotros, te queremos en nuestro equipo!\\nEn el caso de residir en Santiago, debe tener disponibilidad para viajar una o dos semanas a Los Angeles, regi√≥n del BioB√≠o\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'Seeds', 'location': 'Santiago Metropolitan Region, Chile', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4189755534/', 'job_description': '¬øSos \\nData Engineer\\n? Entonces‚Ä¶ ¬øQu√© est√°s esperando para sumarte a nuestra comunidad de Seeders? ¬°Aplica a nuestra comunidad y accede a trabajo on-demand en las empresas l√≠deres, sumate al Present of Work!\\n¬øQui√©nes somos?\\nSomos una \\ncomunidad\\n que re√∫ne al mejor talento on-demand de Latinoam√©rica, y lo conecta con las empresas l√≠deres de la regi√≥n. Gestionamos el match perfecto entre las necesidades de las empresas y el talento con las competencias y la experiencia buscada, fomentando flexibilidad y el desarrollo profesional de nuestra comunidad.\\nNo somos una plataforma m√°s de freelancers, Seeds lidera un dream team de profesionales altamente calificados que eligen d√≥nde, c√≥mo y para qui√©n trabajar, disfrutando as√≠ de contribuir a una misi√≥n m√°s grande, definiendo y moldeando la forma en que trabajamos.\\nEstamos buscando sumar a nuestro Talent Pool roles de \\nData Engineer\\n para nuestra comunidad de Seeders.\\nEstas son algunas de las responsabilidades usuales del rol:\\n- Dise√±ar, construir y mantener arquitecturas de datos robustas y escalables.\\n- Desarrollar y optimizar pipelines de datos para recopilaci√≥n, almacenamiento, procesamiento y an√°lisis de grandes vol√∫menes de datos.\\n- Implementar modelos de datos y algoritmos para resolver problemas de negocio y proveer insights accionables.\\n- Trabajar en estrecha colaboraci√≥n con equipos de data scientists y analistas para apoyar sus requisitos de datos y facilitar el an√°lisis de datos.\\n- Asegurar la integridad, disponibilidad y confidencialidad de los datos a trav√©s de las mejores pr√°cticas de seguridad y gobernanza de datos.\\n- Mantenerse al d√≠a con las √∫ltimas tecnolog√≠as y tendencias en el campo de la ingenier√≠a de datos.\\nRequisitos\\n- Experiencia m√≠nima de 3 a√±os en roles de ingenier√≠a de datos.\\n- Fuerte dominio de lenguajes de programaci√≥n como Python, Java o Scala.\\n- Experiencia trabajando con grandes vol√∫menes de datos y herramientas de procesamiento de datos (como Hadoop, Spark).\\n- Conocimientos en bases de datos SQL y NoSQL, as√≠ como en soluciones de almacenamiento de datos en la nube (AWS, Google Cloud, Azure).\\n- Capacidad para trabajar en entornos √°giles y multidisciplinarios.\\n- Ingl√©s intermedio (deseable).\\n¬øPor qu√© sumarte a nuestra comunidad de Seeders?\\nEleg√≠ tus proyectos.\\nTrabaj√° desde donde vos quieras.\\nEventos de networking.\\nAsesoramiento personalizado.\\nSeeds Academy: Potencia tu desarrollo profesional adquiriendo nuevas skills (upskilling & reskilling), participando de webinars, Bootcamps y otras acciones exclusivas para la comunidad.\\nNo dejes de sumarte a nuestra comunidad de Seeds y aplicar a oportunidades de empresas lideres de la regi√≥n. ¬°Te esperamos!        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Consulting', 'Industries': 'Technology, Information and Media'}\n",
      "------------------------------\n",
      "{'title': 'Senior Data Engineer Python', 'company': '23people', 'location': 'Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294906/', 'job_description': '√önete a Equifax Chile como Senior Data Engineer Python Somos l√≠deres en soluciones de informaci√≥n y tecnolog√≠a, operando globalmente para transformar el uso de la informaci√≥n con transparencia y seguridad. Estamos en un proyecto de migraci√≥n clave que requiere revisi√≥n de pipelines de datos, creaci√≥n de queries, dise√±o de flujos de procesos, an√°lisis de sistemas legados y documentaci√≥n t√©cnica y de negocio. Valoramos la innovaci√≥n, la colaboraci√≥n y el conocimiento t√©cnico. Si tienes habilidades anal√≠ticas excepcionales y pasi√≥n por la tecnolog√≠a, ¬°aplica hoy y s√© parte de nuestra transformaci√≥n digital!\\n Funciones del cargo\\n¬øQu√© har√°s en tu d√≠a a d√≠a?\\nEl profesional colaborar√° con un equipo multidisciplinario en un proyecto de expansi√≥n internacional, enfocado en la migraci√≥n estrat√©gica de la plataforma hacia nuevos mercados. Su participaci√≥n ser√° fundamental para asegurar una implementaci√≥n eficiente que considere las particularidades de cada pa√≠s destino, garantizando as√≠ el √©xito de esta iniciativa global.\\nAlgunas De Sus Tareas Diarias Son Las Siguientes\\n- Implementar mecanismos para verificar la integridad de los datos migrados\\n- Implementar transformaciones espec√≠ficas para requisitos regionales\\n- Dirigir el equipo t√©cnico durante las fases cr√≠ticas de migraci√≥n\\n- Gestionar el proceso integral de ETL entre diversos sistemas, desarrollando y optimizando los esquemas de mapeo necesarios para garantizar la compatibilidad entre las estructuras de datos de origen y destino.\\n Requerimientos del cargo\\nSkills\\nT√©cnicas\\n- Python\\n- BigQuery/SQL\\n- GitHub\\n- Apache Beam/Spark/Google Dataflow\\nPersonales\\n- Capacidad de autogesti√≥n\\n- Buenos skills de comunicaci√≥n\\n- Fortaleza en trabajo en equipo\\n- Adaptaci√≥n al cambio (trabajar√°n en distintas geos de Latam)\\nContrato indefinido desde el inicio con 23people\\nModalidad: Home Office, Con residencia en Chile (Deber√°s ir a buscar el PC en primera instancia)\\nExperiencia: Desde 5 a√±os en adelante\\nHorario: Lunes a Jueves de 8:30 a 6:30 y Viernes de 8:30 a 5:30 hrs.\\n Deseables\\n- Perfil Anal√≠tico\\n- UnitTest\\n- AirFlow\\n- PySpark\\n- CI/CD\\n- Postman\\n- Jmeter\\n Beneficios\\nAlgunos de nuestros beneficios\\n- Seguro complementario: Seguro de salud, vida y dental\\n- Curso de ingl√©s: En nuestro programa de formaci√≥n en idioma ingl√©s, ofrecemos dos modalidades para adaptarnos a tus necesidades y objetivos.\\n- Reembolso de certificaciones internacionales: Apoyamos el crecimiento profesional, por lo que te reembolsamos el costo de un examen de certificaci√≥n internacional que quieras realizar.\\n- Bono de vacaciones: Por cada semana que te tomes de vacaciones te otorgamos una compensaci√≥n.\\n- Aguinaldos en fiestas patrias y Navidad: Queremos que en fechas tan especiales la pases bien junto a tu familia, por lo que te entregamos un bono en septiembre y diciembre\\n- D√≠a libre de cumplea√±os: Puedes optar por tomar tu d√≠a libre, el d√≠a previo a tu cumplea√±os, el mismo d√≠a de tu cumplea√±os o el d√≠a posterior.        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Analista de datos', 'company': 'Ripley Chile', 'location': 'Las Condes, Santiago Metropolitan Region, Chile', 'date': '2025-04-08', 'job_url': 'https://www.linkedin.com/jobs/view/4204266753/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Graduate 2025 Software Engineer I Backend, Chile', 'company': 'Uber', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205853556/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos/ Dbt', 'company': 'BC Tecnolog√≠a', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205500332/', 'job_description': 'En BC Tecnolog√≠a, somos una consultora de TI con m√°s de seis a√±os de experiencia, especializada en ofrecer soluciones personalizadas para nuestros clientes en sectores como servicios financieros, seguros, retail y gobierno. Nos enfocamos en consultor√≠a, outsourcing, desarrollo de proyectos y formaci√≥n de equipos, siempre con un claro compromiso hacia la satisfacci√≥n del cliente. Como parte de nuestro equipo, el ingeniero/a de datos jugar√° un papel clave en la creaci√≥n de soluciones basadas en tecnolog√≠as de la nube, impulsando la innovaci√≥n y la colaboraci√≥n en un entorno de trabajo √°gil.\\n Responsabilidades Clave\\nEl Ingeniero/a De Datos Ser√° Responsable De\\n- Dise√±ar y mantener pipelines de datos utilizando BigQuery y DBT.\\n- Implementar tareas programadas en Google Cloud Platform (GCP) para la ingesta y procesamiento continuo de datos.\\n- Construir y documentar modelos de datos optimizados para su an√°lisis.\\n- Validar y realizar pruebas para garantizar la precisi√≥n de los datos transformados.\\n- Realizar seguimiento y documentaci√≥n de cambios en modelos y sus transformaciones.\\n Requisitos T√©cnicos\\nBuscamos Un Ingeniero/a De Datos Con\\n- Experiencia avanzada en BigQuery y DBT.\\n- Conocimiento pr√°ctico en Google Cloud Platform, incluyendo la programaci√≥n de tareas y almacenamiento.\\n- S√≥lido manejo de SQL y experiencia en modelado de datos.\\n- Capacidad para documentar procesos y realizar pruebas de calidad de datos de manera eficiente.\\n Lo que ofrecemos\\nBrindamos un contrato por proyecto de 12 meses en modalidad h√≠brida, lo que permite combinar trabajo remoto con visitas a la oficina 2 a 3 d√≠as a la semana. Tambi√©n garantizamos un enfoque en la inclusi√≥n, en cumplimiento con la Ley N¬∫ 21.015, promoviendo un entorno donde todos los empleados puedan prosperar.\\n Beneficios        \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst', 'company': 'Macal Remates', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205298423/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos Maestros (Proyecto Corporativo)', 'company': 'Agrosuper', 'location': \"Rancagua, O'Higgins Region, Chile\", 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297494/', 'job_description': 'En Agrosuper, tenemos la misi√≥n de llevar alimentos de la m√°s alta calidad a las familias de Chile y el mundo. Nos mueve el deseo de alimentar el talento y las ganas de crecer constantemente. Buscamos mejorar y fomentar un entorno donde todos disfruten lo bueno de la vida, por lo que valoramos a las personas, que son el alma de nuestra organizaci√≥n. Este cargo de Ingeniero de Datos Maestros (Corporativo) es fundamental para garantizar la calidad y disponibilidad de nuestros Datos Maestros a trav√©s de la optimizaci√≥n de procesos y recursos en nuestras unidades de negocio.\\n Principales Funciones\\n- Gestionar los Datos Maestros en diversos Proyectos Corporativos.\\n- Identificar y proponer mejoras, optimizando y eficientando nuestros procesos internos.\\n- Gestionar la creaci√≥n de c√≥digos de distintos Datos Maestros considerados cr√≠ticos por la Organizaci√≥n.\\n- Definir y configurar en SAP Estrategias de Liberaci√≥n (Compras).\\n- Validar y autorizar √ìrdenes de Transportes Customizing en SAP.\\n- Validar est√°ndares de los Datos Maestros en SAP.\\n- Evaluar y desarrollar parametrizaciones t√©cnicas de Customizing alrededor de los Datos Maestros en SAP.\\n- Asesorar al Equipo de Datos Maestros sobre dudas y buenas pr√°cticas en el Gobierno de Datos Maestros.\\n Requisitos\\n- T√≠tulo profesional en √°reas como Ingenier√≠a Civil Industrial, Comercial, Inform√°tica o similar.\\n- Experiencia laboral m√≠nima de 2 a√±os en roles similares.\\n- Experiencia en SAP, espec√≠ficamente en Gobierno de Datos Maestros (certificado).\\n- Conocimientos en herramientas de an√°lisis y visualizaci√≥n, especialmente en Excel a nivel avanzado.\\nDesirable Skills\\nSi bien los requisitos mencionados son fundamentales, tambi√©n valoramos habilidades adicionales que pueden enriquecer la experiencia en este rol. Esto incluye certificaciones adicionales en SAP, experiencia en gesti√≥n de proyectos y habilidades en liderazgo y trabajo en equipo. Adem√°s, el deseo de mantenerse al d√≠a con las tendencias en tecnolog√≠a y an√°lisis de datos ser√° considerado un gran plus.\\n Beneficios\\nAgrosuper ofrece un entorno de trabajo inspirador donde se valora el crecimiento tanto profesional como personal. Contamos con planes de crecimiento y desarrollo, capacitaci√≥n continua y becas de estudios, adem√°s de convenios con distintas instituciones. Tambi√©n ofrecemos bonos asociados al desempe√±o para incentivar el trabajo de nuestros colaboradores. Adem√°s, promovemos la inclusi√≥n de colaboradores con discapacidad, asegurando que todos tengan la oportunidad de contribuir a nuestro prop√≥sito de alimentar lo bueno de la vida.\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos', 'company': 'AyCA SpA', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4206696535/', 'job_description': 'Company Description: AyCA Spa\\nJob Description: En AyCA SPA nos encontramos en b√∫squeda de un Ingeniero de Datos.\\nProp√≥sito o Misi√≥n del Cargo\\nEl Ingeniero de Datos en Mantenimiento de Planta es responsable de dise√±ar, implementar y gestionar la infraestructura de datos y los sistemas de an√°lisis necesarios para optimizar las estrategias y procesos de mantenimiento. Su rol principal es transformar los datos generados por los equipos, sistemas de monitoreo y actividades de mantenimiento en informaci√≥n valiosa y accionable que permita mejorar la confiabilidad de los activos, reducir costos, predecir fallas y optimizar la planificaci√≥n de las intervenciones.\\nPrincipales Responsabilidades\\n-  Dise√±o e Implementaci√≥n de la Arquitectura de Datos\\n-  Colaborar con el equipo de mantenimiento y TI para comprender las necesidades de datos y dise√±ar una arquitectura robusta y escalable para la recopilaci√≥n, almacenamiento, procesamiento y an√°lisis de datos de mantenimiento.\\n-  Seleccionar e implementar las herramientas y tecnolog√≠as adecuadas para la gesti√≥n de datos (bases de datos, data lakes, plataformas de procesamiento en la nube, etc.).\\n-  Establecer y mantener los procesos de extracci√≥n, transformaci√≥n y carga (ETL/ELT) de datos desde diversas fuentes (CMMS, sensores IoT, registros manuales, etc.).\\n-  Integraci√≥n de sistemas SCADA y PLCs con tecnolog√≠as cloud (OPC UA, MQTT, REST APIs)\\n-  Garantizar la calidad, integridad y seguridad de los datos de mantenimiento.\\n-  Desarrollo de Soluciones de An√°lisis y Reporte\\n-  Desarrollar modelos de datos y esquemas que faciliten el an√°lisis y la generaci√≥n de insights relevantes para el mantenimiento.\\n-  Crear dashboards, informes y visualizaciones interactivas que permitan al equipo de mantenimiento monitorear KPIs, identificar tendencias, evaluar la efectividad de las estrategias y tomar decisiones informadas.\\n-  Implementar t√©cnicas de an√°lisis predictivo (machine learning, inteligencia artificial) para predecir fallas de equipos, optimizar la planificaci√≥n de mantenimiento preventivo y proactivo.\\n-  Automatizar la generaci√≥n de informes y alertas para facilitar la toma de decisiones en tiempo real.\\n-  Dise√±ar e implementar flujos de procesamiento de datos industriales.\\n-  Construir y entrenar modelos de ML para detecci√≥n de fallas y patrones de operaci√≥n.\\n-  Dise√±ar estrategias para la optimizaci√≥n y escalabilidad del sistema de IA.\\n-  Integrar modelos de IA con bases de datos y sistemas de control industriales.\\n-  Asegurar la seguridad y confiabilidad del sistema en entornos industriales.\\n-  Soporte y Optimizaci√≥n de Sistemas de Datos\\n-  Monitorear y mantener el rendimiento y la disponibilidad de la infraestructura de datos de mantenimiento.\\n-  Identificar y resolver problemas relacionados con la calidad, integridad y flujo de datos.\\n-  Optimizar los procesos de ETL/ELT y las consultas de datos para mejorar la eficiencia del an√°lisis.\\n-  Mantener la documentaci√≥n t√©cnica de la arquitectura de datos, los procesos y las soluciones implementadas.\\n-  Colaboraci√≥n y Comunicaci√≥n\\n-  Trabajar en estrecha colaboraci√≥n con el equipo de mantenimiento (planificadores, supervisores, t√©cnicos), el departamento de TI y otros stakeholders para comprender sus necesidades de datos y ofrecer soluciones efectivas.\\n-  Comunicar de manera clara y concisa los hallazgos del an√°lisis de datos y las recomendaciones al equipo de mantenimiento y la gerencia.\\n-  Participar en reuniones y proyectos relacionados con la mejora continua y la transformaci√≥n digital del √°rea de mantenimiento.\\n-  Capacitar al personal de mantenimiento en el uso de las herramientas y los informes de an√°lisis de datos.\\n-  Documentar procesos y modelos.\\n-  Investigaci√≥n y Desarrollo\\n-  Mantenerse actualizado sobre las √∫ltimas tendencias y tecnolog√≠as en el campo del an√°lisis de datos, la inteligencia artificial y el mantenimiento predictivo.\\n-  Investigar y proponer nuevas herramientas y t√©cnicas que puedan mejorar la eficiencia y efectividad del mantenimiento basado en datos.\\n-  Participar en proyectos piloto para la implementaci√≥n de nuevas soluciones de an√°lisis.\\nRequisitos\\n-  T√≠tulo profesional en Ingenier√≠a (Inform√°tica, Industrial, Mec√°nica, El√©ctrica o carreras afines) con especializaci√≥n o experiencia en an√°lisis de datos, ciencia de datos o gesti√≥n de informaci√≥n.\\nExperiencia\\n-  Plataformas de nube p√∫blica: AWS (IoT Core, Lambda, S3), Azure (IoT Hub, Functions) o Google Cloud (Pub/Sub, Firestore).\\n-  Dise√±o o implementaci√≥n de dashboards para visualizaci√≥n de datos industriales (Power BI, Grafana, etc.).\\n-  Haber desarrollado proyectos similares, ya sea como profesional o estudiante (tesis).\\n-  Experiencia en el desarrollo de modelos de Machine Learning.\\n-  Experiencia pr√°ctica con Python, pandas, scikit-learn, TensorFlow, XGBoost o similares.\\n-  Experiencia en arquitectura de datos: bases SQL, ETL, APIs.\\n-  Conocimientos en integraci√≥n de sistemas industriales mediante APIs REST, OPC-UA o MQTT.\\n-  Capacidad para dise√±ar arquitecturas escalables y eficientes.\\n-  Conocimiento en ciberseguridad industrial.\\n-  Familiaridad con software industriales.\\n-  Experiencia en desarrollo de aplicaciones para entornos industriales.\\nSi crees que cumples con las competencias env√≠anos tu CV indicando pretensiones de renta y disponibilidad.\\nAy√∫danos a compartir para llegar a mas personas !!\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Mining'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer AWS ‚Äì Contrato Indefinido.', 'company': 'BC Tecnolog√≠a', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4204878459/', 'job_description': 'Company Description: BC Tecnolog√≠a\\nJob Description: Experiencia de 3 a√±os en:\\n-  Explotaci√≥n de datos (Tunnig)\\n-  ETL\\n-  SQL\\n-  Python\\n-  Apache Airflow (Deseable)\\n-  AWS (Glue, Lambda, S3, Redshift, Dynamodb\\n-  Trabajo Hibrido\\nInteresados o referidos favor enviar cv actualizado a [email] indicando en asunto de e-mail cargo al cual postula (Data Engineer AWS)\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer ‚Äì Proyecto de 6 Meses', 'company': 'BC Tecnolog√≠a', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297473/', 'job_description': 'En BC Tecnolog√≠a, somos una consultora de TI comprometida con ofrecer soluciones innovadoras y adaptadas a las necesidades de nuestros clientes. Con m√°s de 6 a√±os de experiencia en el sector, trabajamos con empresas en diferentes industrias, incluyendo servicios financieros, seguros, retail y gobierno. En este proyecto de Data Engineering, tendr√°s la oportunidad de contribuir al dise√±o y construcci√≥n de pipelines de datos para nuestros clientes, utilizando metodolog√≠as √°giles y colaborando con equipos altamente especializados.\\n Responsabilidades del Rol\\n- Dise√±ar y construir pipelines de datos efectivos para cumplimentar las necesidades anal√≠ticas de nuestros clientes.\\n- Programar usando lenguajes como Python, Scala o SQL para manipulaci√≥n y transformaci√≥n de datos.\\n- Implementar y gestionar herramientas de orquestaci√≥n de pipelines, como Airflow, Mage, NiFi o similares.\\n- Colaborar en pr√°cticas de CI/CD, incluidos conocimientos b√°sicos en Git y versionado de c√≥digo.\\n- Integrar arquitecturas de datos, con un enfoque en Datalakes, Datawarehouses o Lakehouse.\\n- Participar en modelado de datos utilizando t√©cnicas dimensional, estrella y copo de nieve, si es requerido.\\n Requisitos y Habilidades\\nBuscamos candidatos que cuenten con al menos 2 a√±os de experiencia en el √°rea de Data Engineering. Deber√°n tener competencias en dise√±o y construcci√≥n de pipelines de datos, as√≠ como experiencia con lenguajes de programaci√≥n pertinentes como Python, Scala o SQL.\\nEs esencial dominar herramientas de orquestaci√≥n de datos, y tener un conocimiento b√°sico sobre integraciones de CI/CD y flujos de trabajo de versionamiento de c√≥digo. Adicionalmente, es deseable contar con experiencia en arquitecturas de datos y modelado, incluidos Datalakes y t√©cnicas de modelado espec√≠ficas.\\nLa modalidad de trabajo es h√≠brida, lo que permitir√° equilibrar la colaboraci√≥n en persona con flexibilidad laboral.\\n Habilidades Deseables\\nSi bien no es un requisito, consideraremos positivamente la experiencia previa con Datalakes y Datawarehouses, as√≠ como familiaridad con t√©cnicas de modelado como dimensional, estrella o copo de nieve. Esto contribuir√° a un mejor entendimiento del contexto de las soluciones que desarrollaremos.\\n Beneficios y Condiciones\\nOfrecemos Un Contrato Por Proyecto De 6 Meses, Con Posibilidad De Extensi√≥n. Los Empleados Disfrutar√°n De Un Sueldo a Convenir, Adem√°s De Beneficios Adicionales Como\\n- Seguro complementario.\\n- Amipass de $4,500 por d√≠a laborado.\\n- Convenciones, actividades y bonos.\\nEstamos ubicados en Alto Las Condes, permitiendo un ambiente de trabajo funcional y moderno. ¬°Nos encantar√≠a contar contigo en nuestro equipo! üåü\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer', 'company': 'NeuralWorks', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205295705/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Analista de Datos en GCP', 'company': 'BC Tecnolog√≠a', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294840/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Analista de Datos', 'company': 'MindCo', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205553758/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Analista de Datos', 'company': 'Outlier', 'location': 'Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207881229/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Senior Data Engineer', 'company': 'Grupo Falabella', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4205321119/', 'job_description': 'Somos m√°s de 90 mil personas que, d√≠a a d√≠a, dedicamos nuestra pasi√≥n y energ√≠a a cumplir nuestro Prop√≥sito de ‚ÄúSimplificar y Disfrutar M√°s la Vida‚Äù. Prop√≥sito que hoy vive a trav√©s de nuestro ecosistema f√≠sico y digital en todas nuestras empresas (Falabella Retail, Sodimac, IKEA, Tottus, Mallplaza, Falabella Inmobiliario, Falabella.com, Linio, Falabella Financiero, Banco Falabella, Falabella Soriana, Seguros Falabella, Fazil, Fpay y Falabella Corporativo) y pa√≠ses (Argentina, Brasil, Chile, China, Colombia, India, M√©xico, Per√∫ y Uruguay).\\nSi disfrutas nuevos desaf√≠os con alta responsabilidad y exposici√≥n en el epicentro de la transformaci√≥n en Latinoam√©rica, esta oportunidad es para ti. Buscamos un Senior Data Engineerüë®\\u200düíª para sumarse a uno de nuestros equipo, quien sera el encargado de dise√±ar, construir y mantener sistemas de datos escalables, para el an√°lisis y la toma de decisiones en la organizaci√≥n.\\nFunciones Del Cargo\\nDise√±ar y desarrollar canalizaciones de datos (ETL/ELT) robustas y eficientes. \\nColaborar con equipos de ingenier√≠a de datos.\\nImplementar y gestionar bases de datos y data warehouses. \\nOptimizar el rendimiento de las bases de datos y sistemas de almacenamiento de datos. \\nGarantizar la calidad, integridad y seguridad de los datos. \\nAutomatizar procesos de ingesti√≥n y transformaci√≥n de datos.\\nMonitorizar y solucionar problemas relacionados con los sistemas de datos. \\nDocumentar procesos, arquitecturas y mejores pr√°cticas relacionadas con el manejo de datos.\\nRequisitos\\nProfesional titulado en Ingenier√≠a Civil Computaci√≥n, Industrial, matem√°tico u el√©ctrico.\\nExperiencia demostrable como Data Engineer\\nExperiencia en lenguajes de programaci√≥n Python.\\nExperiencia con Google Cloud Platform (Composer, Cloud Functions, Bigquery, Dataproc, etc)\\nExperiencia utilizando git.\\nConocimientos profundos en SQL y en bases de datos relacionales y no relacionales\\nDeseable: Certificaci√≥n Associate Engineer\\nDeseable: Nivel de Ingl√©s intermedio (B1+)\\nDeseable: Certificaciones relevantes en tecnolog√≠as de datos y cloud.\\nSi te apasionan los desafios numerico üöÄüë®\\u200düíªy buscas ser parte de un gran team, ven y postula con nosotros!!\\nSomos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusi√≥n en todas sus formas, sin importar religi√≥n, raza, g√©nero, situaci√≥n de discapacidad, nacionalidad.\\nConoce m√°s oportunidades para vivir la #ExperienciaFalabella en https://muevete.falabella.com/        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Financial Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'Mediastream', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4206504298/', 'job_description': 'Description\\nMediastream is a leading streaming technology company that has been in business for over 16 years. We collaborate with major companies and broadcasters around the world to offer a quality end-to-end solution for content administration, distribution, audiovisual production, and user experience. Our goal is to connect our customers with their audience in a simple and effective way, creating new revenue streams for their businesses.\\nRole Description\\nThis is a hibrid role for a Data Egineer. The Data Engineer will be responsible for proposing advanced applications of our data, reviewing patterns, deviations to detect trends to optimize dashboards and optimize advertising strategies. Promote new strategies and technologies to process, analyze and leverage customer data and improve user engagement. With the main objective of: Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights, which serve for product roadmap, Develop and manage efficient data pipelines and ETL workflows for the integration of diverse data sources and Use machine learning models and recommendation algorithms to personalize strategies.\\nResponsibilities\\n- Create, implement and maintain the company\\'s data architecture.\\n- Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights for product roadmap.\\n- Develop and manage data pipelines and ETL workflows for the integration of diverse data sources.\\n- Use machine learning models and recommendation algorithms to personalize strategies.\\n- Create interactive visualizations and dashboards for studies to monitor performance and make data-driven decisions.\\n- Collaborate closely with the development team to integrate, create features and roadmap proposals. \\n- Have a product vision and work closely with the marketing and development teams to align strategies with business objectives.\\n\">\\nMediastream is a leading streaming technology company that has been in business for over 16 years. We collaborate with major companies and broadcasters around the world to offer a quality end-to-end solution for content administration, distribution, audiovisual production, and user experience. Our goal is to connect our customers with their audience in a simple and effective way, creating new revenue streams for their businesses.\\nRole Description\\nThis is a hibrid role for a Data Egineer. The Data Engineer will be responsible for proposing advanced applications of our data, reviewing patterns, deviations to detect trends to optimize dashboards and optimize advertising strategies. Promote new strategies and technologies to process, analyze and leverage customer data and improve user engagement. With the main objective of: Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights, which serve for product roadmap, Develop and manage efficient data pipelines and ETL workflows for the integration of diverse data sources and Use machine learning models and recommendation algorithms to personalize strategies.\\nResponsibilities\\n- Create, implement and maintain the company\\'s data architecture.\\n- Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights for product roadmap.\\n- Develop and manage data pipelines and ETL workflows for the integration of diverse data sources.\\n- Use machine learning models and recommendation algorithms to personalize strategies.\\n- Create interactive visualizations and dashboards for studies to monitor performance and make data-driven decisions.\\n- Collaborate closely with the development team to integrate, create features and roadmap proposals.\\n- Have a product vision and work closely with the marketing and development teams to align strategies with business objectives.\\nMinimum Requirements\\n- At least 3 years of experience in Data Engineer roles.\\n- Bachelor\\'s degree in computer science or related field.\\n- Knowledge in: SQL/No SQL: Advanced, Power BI, Looker, tableau or others: Intermediate, Python and development knowledge: Basic, machine learning, AI or similar technologies: Basic, Identification of cluster patterns, trends, deviations: Intermediate, cloud technologies: Intermediate.\\nSoft Skills:\\n- Teamwork\\n- Decision-making\\n- Attention to detail\\n- Adaptability \\n\">\\n- At least 3 years of experience in Data Engineer roles.\\n- Bachelor\\'s degree in computer science or related field.\\n- Knowledge in: SQL/No SQL: Advanced, Power BI, Looker, tableau or others: Intermediate, Python and development knowledge: Basic, machine learning, AI or similar technologies: Basic, Identification of cluster patterns, trends, deviations: Intermediate, cloud technologies: Intermediate.\\nSoft Skills:\\n- Teamwork\\n- Decision-making\\n- Attention to detail\\n- Adaptability        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer AWS', 'company': 'BC Tecnolog√≠a', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294910/', 'job_description': 'En \\nBC Tecnolog√≠a\\n, nos especializamos en la consultor√≠a de TI, ofreciendo un amplio rango de servicios para adaptarnos a las necesidades espec√≠ficas de nuestros clientes, principalmente en finanzas, seguros, retail y gobierno. Nuestro equipo trabaja mediante metodolog√≠as √°giles, lo que nos permite dise√±ar e implementar soluciones tecnol√≥gicas efectivas y dirigidas al cliente. Actualmente, estamos buscando un Data Engineer con experiencia en AWS para sumarse a nuestro equipo y contribuir a proyectos innovadores en la gesti√≥n y explotaci√≥n de datos.\\n Responsabilidades del Cargo\\n- Desarrollar y gestionar procesos de ETL, asegurando la calidad y fiabilidad de los datos.\\n- Optimizar la explotaci√≥n de datos a trav√©s de t√©cnicas de Tuning.\\n- Implementar soluciones utilizando herramientas de AWS, incluyendo Glue, Lambda, S3, Redshift y DynamoDB.\\n- Colaborar con los equipos de desarrollo de software para asegurar la integraci√≥n de datos eficiente.\\n- Realizar an√°lisis y visualizaci√≥n de datos para apoyar en la toma de decisiones.\\n- Mantener un enfoque en la innovaci√≥n y la mejora continua de los procesos y herramientas utilizadas.\\n Descripci√≥n del Cargo\\nBuscamos Un Data Engineer AWS Con Un M√≠nimo De 3 A√±os De Experiencia En El Manejo De Datos. El Candidato Ideal Tendr√° Conocimientos S√≥lidos En\\n- Explotaci√≥n de datos y Tuning.\\n- Dise√±o e implementaci√≥n de procesos ETL.\\n- Desarrollo de consultas efectivas en SQL.\\n- Programaci√≥n en Python.\\n- Uso de herramientas de orquestaci√≥n como Apache Airflow (deseable).\\nValoramos habilidades como el trabajo en equipo, la proactividad y la capacidad para adaptarse a nuevas tecnolog√≠as. La combinaci√≥n de habilidades t√©cnicas y soft skills es esencial para unirse a nuestro equipo din√°mico.\\n Habilidades Deseables\\nAdem√°s de los requisitos mencionados, ser√≠a beneficioso contar con experiencia en:\\n- Integraciones y gesti√≥n de datos en m√∫ltiples fuentes.\\n- Implementaci√≥n de soluciones en la nube de AWS.\\n- Conocimientos en herramientas de visualizaci√≥n de datos.\\nEstas habilidades ayudar√°n al candidato a integrarse de manera efectiva en nuestros equipos de trabajo y contribuir a proyectos futuros.\\n Beneficios de Trabajar con Nosotros\\nEn \\nBC Tecnolog√≠a\\n, valoramos a nuestro equipo y ofrecemos un entorno flexible y beneficios atractivos:\\n- Contrato indefinido.\\n- Modalidad h√≠brida, combinando trabajo remoto y en oficina.\\n- Paquete de beneficios corporativos que incluye salud prepaga de primer nivel para el empleado y su familia.\\n- Un d√≠a de home office a la semana, junto con desayunos y un comedor en la planta.\\n- Acceso a un Sport Club y asistencia de un nutricionista.\\n¬°√önete a nosotros y marca una diferencia en el mundo de la tecnolog√≠a! üéâ\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst', 'company': 'LISIT', 'location': 'Los √Ångeles, Biob√≠o Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297449/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer Python', 'company': 'Equifax', 'location': 'Providencia, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4165780801/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer GCP', 'company': 'Soluciones - Data & Analytics Consulting', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4206574777/', 'job_description': '‚úîÔ∏è\\n¬øQui√©nes Somos?\\nSomos una consultora enfocada en Data & Analytics y contamos con m√°s de 20 a√±os de experiencia y exitosa participaci√≥n en implementaci√≥n de proyectos de peque√±a, mediana y gran envergadura. Nuestro equipo, compuesto por consultores multidisciplinarios expertos y certificados, ha entregado soluciones tecnol√≥gicas de calidad que exceden las expectativas de cada cliente. A trav√©s de una metodolog√≠a flexible y adaptable, logramos entregar soluciones adecuadas a la realidad de cada organizaci√≥n, satisfaciendo los est√°ndares de cada una de las empresas que conf√≠an en nosotros.\\n‚úîÔ∏è\\n ¬øQu√© har√°s?\\n- Integraci√≥n de productos de datos.\\n- Se trabajar√° con informaci√≥n para conocer a clientes y segmentarlos, para innovar en productos.\\n- Trabajar√° los procesos ETL de inicio a fin (ingesta, transformaci√≥n, disponibilizaci√≥n).\\n- Conocimientos Full GCP (airflow, bigquery, cloudstorage como herramientas principales)\\n- Deber√° generar el flujo completo del dato desde la ingesta, transformaci√≥n y disponibilizaci√≥n.\\n‚úîÔ∏è\\n ¬øQu√© se requiere?\\n- Experiencia en el rol o cargo de Ingeniero de Datos Google Cloud Platform (GCP)\\n‚úîÔ∏è\\nConocimientos t√©cnicos excluyentes:\\n- Experiencia en datos y modelo de datos\\n- Metodolog√≠a agile\\n- Procesos ETL\\n- Conocimientos en Suit GCP\\n‚úîÔ∏è ¬øQu√© Ofrecemos ?\\n- Seguros complementario de salud\\n- Rutas de estudios\\n- D√≠a libre cumplea√±os\\n- Reajuste salarial anual seg√∫n variaci√≥n del IPC        \\n            \\n                            \\n            ', 'Seniority level': 'Associate', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Senior Data Engineer', 'company': '23people', 'location': 'Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207846989/', 'job_description': '¬°Hola! Estamos buscando un Senior Data Engineer \\nüåê\\nRango salarial entre: $2.200.000 - $2.400.000 CLP\\nPa√≠s: Residentes en Chile \\nSkills\\nT√©cnicas\\n- Python\\n- BigQuery/SQL\\n- GitHub\\n- Apache Beam/Spark/Google Dataflow\\nPersonales\\n- Capacidad de autogesti√≥n\\n- Buenos skills de comunicaci√≥n\\n- Fortaleza en trabajo en equipo\\n- Adaptaci√≥n al cambio (trabajar√°n en distintas geos de Latam)\\nDeseable (NO excluyente)\\n- Perfil Anal√≠tico\\n- UnitTest\\n- AirFlow\\n- PySpark\\n- CI/CD\\n- Postman\\n- Jmeter\\n¬øQu√© har√°s en tu d√≠a a d√≠a?\\nEl profesional colaborar√° con un equipo multidisciplinario en un proyecto de expansi√≥n internacional, enfocado en la migraci√≥n estrat√©gica de la plataforma hacia nuevos mercados. Su participaci√≥n ser√° fundamental para asegurar una implementaci√≥n eficiente que considere las particularidades de cada pa√≠s destino, garantizando as√≠ el √©xito de esta iniciativa global.\\nAlgunas de sus tareas diarias son las siguientes:\\n- Implementar mecanismos para verificar la integridad de los datos migrados\\n- Implementar transformaciones espec√≠ficas para requisitos regionales\\n- Dirigir el equipo t√©cnico durante las fases cr√≠ticas de migraci√≥n\\n- Gestionar el proceso integral de ETL entre diversos sistemas, desarrollando y optimizando los esquemas de mapeo necesarios para garantizar la compatibilidad entre las estructuras de datos de origen y destino.\\nContrato indefinido desde el inicio con 23people\\nModalidad: Home Office, Con residencia en Chile (Deber√°s ir a buscar el PC en primera instancia)\\nExperiencia: Desde 5 a√±os en adelante\\nHorario: Lunes a Jueves de 8:30 a 6:30 y Viernes de 8:30 a 5:30 hrs.\\nAlgunos de nuestros beneficios:\\n- Seguro complementario: Seguro de salud, vida y dental\\n- Curso de ingl√©s: En nuestro programa de formaci√≥n en idioma ingl√©s, ofrecemos dos modalidades para adaptarnos a tus necesidades y objetivos.\\n- Reembolso de certificaciones internacionales: Apoyamos el crecimiento profesional, por lo que te reembolsamos el costo de un examen de certificaci√≥n internacional que quieras realizar.\\n- Bono de vacaciones: Por cada semana que te tomes de vacaciones te otorgamos una compensaci√≥n.\\n- Aguinaldos en fiestas patrias y Navidad: Queremos que en fechas tan especiales la pases bien junto a tu familia, por lo que te entregamos un bono en septiembre y diciembre\\n- D√≠a libre de cumplea√±os: Puedes optar por tomar tu d√≠a libre, el d√≠a previo a tu cumplea√±os, el mismo d√≠a de tu cumplea√±os o el d√≠a posterior.        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer AWS', 'company': 'Soluciones - Data & Analytics Consulting', 'location': 'Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207848749/', 'job_description': '‚úîÔ∏è\\n¬øQui√©nes Somos?\\nSomos una consultora enfocada en Data & Analytics y contamos con m√°s de 20 a√±os de experiencia y exitosa participaci√≥n en implementaci√≥n de proyectos de peque√±a, mediana y gran envergadura. Nuestro equipo, compuesto por consultores multidisciplinarios expertos y certificados, ha entregado soluciones tecnol√≥gicas de calidad que exceden las expectativas de cada cliente. A trav√©s de una metodolog√≠a flexible y adaptable, logramos entregar soluciones adecuadas a la realidad de cada organizaci√≥n, satisfaciendo los est√°ndares de cada una de las empresas que conf√≠an en nosotros.\\n‚úîÔ∏è\\n ¬øQu√© har√°s?\\n- Responsabilidades del cargo: Dise√±ar, construir y mantener procesos de ingesta de datos que permiten recolectar, almacenar, procesar y acceder a grandes vol√∫menes de datos de manera eficiente y segura. Su trabajo asegura que los datos est√©n disponibles, limpios y organizados para su an√°lisis adhiri√©ndose a los est√°ndares definidos por el cliente.\\n‚úîÔ∏è\\n ¬øQu√© se requiere?\\n- Experiencia de al menos 3 a√±os en el rol\\n- Conocimientos t√©cnicos excluyentes: S3, Lambdas, Glue Jobs, DynamoDB, Redshift, StepFunctions, Python, SQS.\\n- Conocimientos t√©cnicos deseables: API Gateway, Transfer Family.\\n‚úîÔ∏è ¬øQu√© Ofrecemos ?\\n- Seguros complementario de salud\\n- Rutas de estudios\\n- D√≠a libre cumplea√±os\\n- Reajuste salarial anual seg√∫n variaci√≥n del IPC        \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer Senior', 'company': 'Equifax', 'location': 'Las Condes, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4144902157/', 'job_description': 'Como Data Engineer, estar√°s a cargo de integrar, consolidar y estructurar los datos, apoy√°ndote en un las mejores pr√°cticas para manejar, mantener y mejorar nuestras soluciones.\\n \\n \\n ¬øQu√© vas a hacer? \\n \\n \\n-  Evaluar, gestionar y resolver incidentes. \\n-  Realizar c√°lculos en linea utilizando Python. \\n-  Ejecuci√≥n de pruebas. \\n \\n \\n ¬øQu√© experiencia necesita? \\n \\n \\n-  + 4 a√±os de experiencia trabajando en Python. \\n-  + 4 a√±os de experiencia BigQuery. \\n-  + 4 a√±os de experiencia trabajando con Apache Beam y GitHub. \\n \\n \\n ¬øQu√© podr√≠a diferenciarte? \\n \\n \\n-  Poseer alguna certificaci√≥n de Google en Data Engineer. \\n-  Experiencia trabajando con Airflow. \\n-  Experiencia Trabajando con Jmeter. \\n-  Experiencia trabajando con Unit Test. \\n-  Experiencia trabajando con PySpark. \\n-  Experiencia trabajando con CI/DF. \\n-  Experiencia trabajando con Postman.        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Financial Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer Semisenior o Senior', 'company': 'LISIT', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297492/', 'job_description': 'Lisit es una empresa comprometida con la creaci√≥n, desarrollo e implementaci√≥n de soluciones de software que faciliten la automatizaci√≥n y optimizaci√≥n para nuestros clientes. Nuestra visi√≥n se centra en brindar servicios que no solo cumplan con las necesidades del mercado, sino que tambi√©n transformen la operatividad de las organizaciones. Tu funci√≥n como Ingeniero de Datos ser√° fundamental para lograr un acompa√±amiento consultivo integral en sus procesos de transformaci√≥n.\\n Responsabilidades del puesto\\nComo Ingeniero De Datos Semi-senior o Senior En Lisit, Ser√°s Una Pieza Clave En El Dise√±o y Desarrollo De Soluciones De Datos Que Optimicen Nuestros Servicios y Herramientas. Tus Tareas Incluir√°n\\n- Generar pipelines de datos eficientes y resolver integraciones entre diversos sistemas.\\n- Modelar datos para garantizar que nuestras plataformas sean √∫tiles y escalables.\\n- Colaborar en la implementaci√≥n de herramientas de infraestructura como c√≥digo (IaC) y gestionar el versionamiento a trav√©s de GitHub o GitLab.\\n- Desarrollar y ejecutar procesos ETL/ELT utilizando Azure Data Factory, asegurando la calidad y accesibilidad de los datos.\\n Descripci√≥n del puesto\\nBuscamos un Ingeniero de Datos altamente motivado, con un m√≠nimo de 3 a√±os de experiencia en el tratamiento de datos. Tu destreza con lenguajes de programaci√≥n como Python y Spark te permitir√° desempe√±arte con solidez en el equipo. Se requiere un conocimiento intermedio-avanzado de herramientas de IaC (Terraform) y manejo de versionamiento de c√≥digo (GitHub/GitLab), as√≠ como una s√≥lida comprensi√≥n del lenguaje SQL y bases de datos.\\nEs esencial que tengas experiencia con plataformas en la nube como Google Cloud Platform (GCP) o Azure, y herramientas como Airflow, Cloud Run, Cloud Composer y BigQuery. Adem√°s, el dominio de Azure Data Factory para procesos ETL-ELT es un requisito excluyente. Las certificaciones en Ingenier√≠a de Datos son valoradas, tales como Azure DP-700, AZ-203, DP-600 y Google Cloud Digital Leader.\\n Habilidades deseables\\nSi cuentas con conocimientos en Microsoft Power BI o Fabric, ser√≠a un gran plus para tu perfil. Queremos personas que no solo cumplan con los requisitos, sino que tambi√©n aporten un enfoque innovador y colaborativo a nuestro equipo.\\n Beneficios de trabajar con nosotros\\nEn Lisit, Fomentamos Un Ambiente De Trabajo Excepcional, Donde La Innovaci√≥n y La Pasi√≥n Por El Aprendizaje Son Clave. Te Ofrecemos\\n- Acceso a oportunidades continuas de desarrollo profesional en tecnolog√≠as emergentes.\\n- Un equipo motivado y apasionado que valora tu entusiasmo y contribuciones.\\nAqu√≠, tendr√°s la oportunidad de crecer y alcanzar tus objetivos profesionales mientras colaboras en proyectos desafiantes y de alto impacto.\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos', 'company': 'Amaris Consulting', 'location': 'Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4206597362/', 'job_description': 'Who are we?\\nAmaris Consulting es una firma independiente de asesor√≠a tecnol√≥gica que ofrece servicios de orientaci√≥n y soluciones para las empresas.\\nRe√∫ne a m√°s de 7 600 personas distribuidas en 5 continentes y m√°s de 60 pa√≠ses. Con m√°s de 1 000 clientes en todo el mundo, hemos implementado soluciones en proyectos importantes durante m√°s de una d√©cada.\\nNuestros especialistas cubren sectores que abarcan desde servicios financieros y transporte hasta atenci√≥n sanitaria y tecnolog√≠a.\\nAmaris es su ‚Äòstepping stone‚Äô para atravesar r√≠os de cambio, afrontar retos y realizar todos sus proyectos con √©xito.\\nJob Description\\nBuscamos consultores din√°micos para hacer crecer nuestro equipo de \\nSistemas de Informaci√≥n y Digital\\n en\\n Chile\\n. Tu experiencia, conocimiento y compromiso nos ayudar√°n a enfrentar los desaf√≠os de nuestros clientes.\\nEstar√°s apoyando diferentes proyectos a trav√©s de tu experiencia como \\nIngeniero de Datos.\\nSus principales responsabilidades:\\n- Asegurar que las soluciones de datos sean escalables, eficientes y alineadas con los objetivos de negocio.\\n- Dise√±ar, desarrollar e implementar soluciones de gesti√≥n y an√°lisis de datos en la industria.\\n- Utilizar herramientas como Python y SQL para extraer, transformar y cargar (ETL) datos.\\n- Trabajar con bases de datos en la nube, utilizando alguna de las principales plataformas: Google Cloud Platform (GCP), Amazon Web Services (AWS) o Microsoft Azure.\\n- Desarrollar y mantener pipelines de datos para la gesti√≥n y an√°lisis eficiente.\\n- Desarrollar APIs y plugins para integrar soluciones de datos con otras aplicaciones y sistemas.\\n- Implementar y gestionar entornos de desarrollo y pruebas para soluciones de datos.\\n- Mantenerse actualizado con las √∫ltimas tendencias y herramientas en el √°mbito de la ingenier√≠a de datos.\\nRequisitos\\n:\\n- Al menos 2 a√±os de experiencia como Ingeniero de Datos.\\n- Al menos 2 a√±os de experiencia con alguna de las principales nubes (GCP, AWS, Azure).\\n- Dominio de Python.\\n- Dominio de bases de datos SQL.\\n- Experiencia con procesos ETL.\\nAmaris Consulting se enorgullece de ser un lugar de trabajo con igualdad de oportunidades. Estamos comprometidos con la promoci√≥n de la diversidad dentro de la fuerza de trabajo y la creaci√≥n de un ambiente de trabajo inclusivo. Para ello, damos la bienvenida a las solicitudes de todos los candidatos cualificados, independientemente de su g√©nero, orientaci√≥n sexual, raza, etnia, creencias, edad, estado civil, discapacidad u otras caracter√≠sticas.        \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Analista de Datos', 'company': 'Outlier', 'location': 'La Serena, Coquimbo Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207883217/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer - GCP Ssr', 'company': 'axity', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4204875774/', 'job_description': 'Company Description: axity\\nJob Description: Axity una compa√±√≠a con m√°s de 35 a√±os de trayectoria nuestro portafolio de servicios es uno de los m√°s grandes en la industria: Estrategia Digital, Desarrollo de Software, Bussiness Intelligence, Big Data, Anal√≠tica Avanzada, Seguridad, IOT.\\nBuscamos Data Analyst / Data Engineer ‚Äì Nivel Medio/Avanzado\\n¬øTe apasiona convertir datos en informaci√≥n valiosa y accionable?\\nEstamos en b√∫squeda de un profesional con experiencia en desarrollo de productos de complejidad media a avanzada, capaz de entregar soluciones de calidad dentro de los plazos establecidos.\\nResponsabilidades\\nDesarrollar productos anal√≠ticos cumpliendo con est√°ndares de calidad y tiempos definidos.\\nTraducir datos en informaci√≥n √∫til para la toma de decisiones.\\nTrabajar en conjunto con equipos de anal√≠tica para profundizar en el an√°lisis y la s√≠ntesis de datos.\\nSeleccionar y aplicar t√©cnicas anal√≠ticas adecuadas a cada requerimiento.\\nMantenerse actualizado sobre herramientas anal√≠ticas y productos de manipulaci√≥n de datos.\\nRealizar procesos de recolecci√≥n, clasificaci√≥n, limpieza e interpretaci√≥n de grandes vol√∫menes de datos.\\nAplicar pr√°cticas de gobernanza y seguridad de los datos.\\nParticipar en iniciativas que involucren integraci√≥n de datos para procesos como planeaci√≥n de compras, demanda y gesti√≥n de inventarios.\\nRequisitos\\nExperiencia en GCP (Google Cloud Platform): BigQuery, Cloud Storage, Dataflow, Cloud Functions, Composer, Pub/Sub.\\nConocimientos b√°sicos en Kubernetes, contenedores y consumo de APIs.\\nExperiencia en manejo de grandes vol√∫menes de datos.\\nConocimiento de sistemas legados, flujos de compras y demand forecasting.\\nCapacidad de interacci√≥n continua con √°reas de negocio.\\nOfrecemos\\nHorario: Lunes a viernes de 9:00 a 18:30\\nContrato a plazo fijo luego a indefinido\\nOportunidad de trabajar en proyectos desafiantes con impacto directo en el negocio\\nAmbiente colaborativo e innovador\\nSi te motiva trabajar con datos, impactar decisiones estrat√©gicas y enfrentarte a desaf√≠os t√©cnicos, ¬°postula con nosotros!\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Gobierno de Datos - Subgerencia de Gobierno de Datos', 'company': 'Consorcio', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-08', 'job_url': 'https://www.linkedin.com/jobs/view/4204238135/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer - AWS Ssr', 'company': 'axity', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4204874848/', 'job_description': 'Company Description: axity\\nJob Description: Axity una compa√±√≠a con m√°s de 35 a√±os de trayectoria nuestro portafolio de servicios es uno de los m√°s grandes en la industria: Estrategia Digital, Desarrollo de Software, Bussiness Intelligence, Big Data, Anal√≠tica Avanzada, Seguridad, IOT.\\nResponsabilidades Principales\\n-  Dise√±o eficiente de almacenamiento de datos: utilizando servicios como Amazon S3, DynamoDB, RDS, entre otros, optimizando costos, rendimiento y accesibilidad.\\n-  Optimizaci√≥n de consultas: aplicando √≠ndices, claves de partici√≥n y patrones de acceso eficientes (Query, GetItem, etc.).\\n-  Integraci√≥n y procesamiento de datos: a trav√©s de herramientas como AWS Glue, Amazon Kinesis y/o Firehose para ingesta, transformaci√≥n y orquestaci√≥n.\\n-  Uso de formatos optimizados: como Parquet, ORC, entre otros, para mejorar la compresi√≥n y velocidad de lectura/escritura.\\n-  Infraestructura como C√≥digo (IaC): despliegue de infraestructura en AWS mediante CloudFormation, AWS CDK o Terraform.\\n________________________________________\\nÔ∏è Conocimientos T√©cnicos Clave\\n-  Amplio manejo de servicios AWS: S3, DynamoDB, RDS, AWS Glue, Kinesis/Firehose.\\n-  Dominio de bases de datos SQL/NoSQL: dise√±o de esquemas, indexaci√≥n y tuning.\\n-  Experiencia en optimizaci√≥n y particionamiento de grandes vol√∫menes de datos.\\n-  Familiaridad con automatizaci√≥n y orquestaci√≥n de pipelines: scripting, Jenkins, Shell, entre otros.\\n-  Modalidad: H√≠brido\\n-  √Årea: Tecnolog√≠a ‚Äì Cloud\\n-  Horario: Lunes a viernes de 9:00 a 18:00 hrs\\n-  Tipo de Contrato: Plazo fijo, con posibilidad de pasar a indefinido\\n________________________________________\\n¬øPor qu√© postular?\\n-  Ser√°s parte de una empresa con enfoque en la innovaci√≥n y la transformaci√≥n digital.\\n-  Trabajar√°s con tecnolog√≠as de vanguardia en un entorno colaborativo.\\n-  Tendr√°s oportunidades reales de crecimiento profesional.        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero en Gesti√≥n de Datos', 'company': 'Genesys', 'location': 'Las Condes, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4206087107/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer', 'company': 'IGX', 'location': 'Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205299322/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Consultor Data Analyst', 'company': 'LISIT', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297448/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer', 'company': 'Banco Falabella', 'location': 'Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4205421235/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer Azure', 'company': '', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4206654598/', 'job_description': 'Resumen del Cargo:\\nBusco Ingeniero de Datos  para liderar y ejecutar proyectos de Data & Analytics. \\nSer√° responsable del dise√±o, desarrollo e implementaci√≥n de soluciones de datos usando Azure Databricks, Data Factory, Python  y otros servicios en la nube, asegurando que la infraestructura de datos sea escalable, segura y optimizada para la toma de decisiones. \\nAdem√°s, deber√° interactuar directamente con √°reas de negocio para levantar requerimientos y traducirlos en soluciones t√©cnicas eficientes.\\n\\xa0\\n\\xa0\\nResponsabilidades:\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0‚Ä¢\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Dise√±ar y desarrollar soluciones de ingesti√≥n, transformaci√≥n y modelado de datos en Azure DataFactory, Databricks y otras tecnolog√≠as relacionadas.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0‚Ä¢\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Optimizar procesos de ETL/ELT, asegurando calidad, integridad y eficiencia en el procesamiento de datos.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0‚Ä¢\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Colaborar con equipos de negocio para entender necesidades, identificar oportunidades y proponer soluciones basadas en datos.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0‚Ä¢\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Implementar arquitecturas de datos escalables que soporten anal√≠tica avanzada, machine learning e inteligencia de negocio.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0‚Ä¢\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Garantizar la seguridad y el cumplimiento normativo en el manejo de datos, siguiendo est√°ndares bancarios y regulatorios.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0‚Ä¢\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Desarrollar y optimizar pipelines de datos para la explotaci√≥n en entornos anal√≠ticos y de reportes.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0‚Ä¢\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Documentar procesos, arquitecturas y modelos de datos, asegurando buenas pr√°cticas de gobernanza.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0‚Ä¢\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Trabajar en conjunto con equipos de Data Science, BI y Tecnolog√≠a para garantizar la disponibilidad y calidad de los datos.\\n\\xa0        \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology'}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer', 'company': 'ZeroFox', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4203138895/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Backoffice - Analista de datos', 'company': 'Infinity Ingenieria SPA', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4204075434/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Analista de datos de Farmacia', 'company': 'IQVIA', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-12', 'job_url': 'https://www.linkedin.com/jobs/view/4208763580/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst Power BI- Bigquery', 'company': 'Soluciones - Data & Analytics Consulting', 'location': 'Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207890015/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst Senior Modelos y Datos Riesgo', 'company': 'Banco Bci', 'location': 'Las Condes, Santiago Metropolitan Region, Chile', 'date': '2025-04-08', 'job_url': 'https://www.linkedin.com/jobs/view/4203767105/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Insights Specialist', 'company': 'Nestl√©', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4202697660/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst I - Operations', 'company': 'Signant Health', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4202554692/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer II, Gerencia Tecnolog√≠a', 'company': 'Walmart Chile', 'location': 'Huechuraba, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4206684576/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer III, Gerencia Tecnolog√≠a', 'company': 'Walmart Chile', 'location': 'Huechuraba, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4206686540/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Salesforce Software Engineer', 'company': 'Banco Falabella', 'location': 'Santiago Metropolitan Area', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4203137306/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Analista BI', 'company': 'Chubb', 'location': 'Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4208212282/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer III', 'company': 'Mindbody', 'location': 'Chile', 'date': '2025-04-13', 'job_url': 'https://www.linkedin.com/jobs/view/4169374324/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Senior Software Engineer, Backend (Remote)', 'company': 'Mindbody', 'location': 'Chile', 'date': '2025-04-12', 'job_url': 'https://www.linkedin.com/jobs/view/4170144703/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Senior Data Engineer', 'company': 'Grupo Falabella', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4205465977/', 'job_description': 'Descripci√≥n Empresa\\nSomos m√°s de 90 mil personas que, d√≠a a d√≠a, dedicamos nuestra pasi√≥n y energ√≠a a cumplir nuestro Prop√≥sito de ‚ÄúSimplificar y Disfrutar M√°s la Vida‚Äù. Prop√≥sito que hoy vive a trav√©s de nuestro ecosistema f√≠sico y digital en todas nuestras empresas (Falabella Retail, Sodimac, IKEA, Tottus, Mallplaza, Falabella Inmobiliario, Falabella.com, Linio, Falabella Financiero, Banco Falabella, Falabella Soriana, Seguros Falabella, Fazil, Fpay y Falabella Corporativo) y pa√≠ses (Argentina, Brasil, Chile, China, Colombia, India, M√©xico, Per√∫ y Uruguay).\\nValoramos las distintas miradas porque entendemos que la diversidad es la clave de nuestra innovaci√≥n. Queremos ir m√°s all√° de cualquier l√≠mite, desafiarnos constantemente, divertirnos haciendo lo que nos gusta y dejar huella en lo que hacemos. Y sabemos que existe una forma de hacerlo: como UN SOLO EQUIPO.\\nMisi√≥n Del Cargo\\n¬°√önete a Falabella Retail y lleva tus habilidades de Ingenier√≠a de Datos al pr√≥ximo nivel!\\nFunciones Del Cargo\\nFormar√°s parte de un equipo de alto impacto que lidera la transformaci√≥n digital, trabajando en proyectos cr√≠ticos para optimizar y escalar nuestras operaciones en uno de los ecosistemas m√°s din√°micos de la regi√≥n.\\nMision: Responsable de dise√±ar, construir y mantener sistemas de datos escalables para el an√°lisis y la toma de decisiones en la organizaci√≥n.\\nResponsabilidades\\nDise√±ar y desarrollar canalizaciones de datos (ETL/ELT) robustas y eficientes.\\nColaborar con equipos de ingenier√≠a de datos.\\nImplementar y gestionar bases de datos y data warehouses.\\nOptimizar el rendimiento de las bases de datos y sistemas de almacenamiento de datos.\\nGarantizar la calidad, integridad y seguridad de los datos.\\nAutomatizar procesos de ingesti√≥n y transformaci√≥n de datos.\\nMonitorizar y solucionar problemas relacionados con los sistemas de datos.\\nDocumentar procesos, arquitecturas y mejores pr√°cticas relacionadas con el manejo de datos.\\nSi disfrutas nuevos desaf√≠os con alta responsabilidad y exposici√≥n en el epicentro de la transformaci√≥n del retail en Latinoam√©rica, ¬°s√∫mate a trabajar con nosotros! Somos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusi√≥n en todas sus formas, sin importar religi√≥n, raza, g√©nero, situaci√≥n de discapacidad, nacionalidad.\\nConoce m√°s oportunidades para vivir la #ExperienciaFalabella en https://muevete.falabella.com/\\nRequisitos\\n- Profesional Titulado en Ingenier√≠a Civil Computaci√≥n, Industrial, matem√°tico u el√©ctrico.\\n- Experiencia demostrable como Data Engineer por mas de 04 a√±os\\n- Conocimientos en lenguajes de programaci√≥n Python.\\n- Experiencia con Google Cloud Platform (Composer, Cloud Functions, Bigquery, Dataproc, etc)\\n- Experiencia utilizando git\\n- Deseable: Conocimientos profundos en SQL y en bases de datos relacionales y no relacionales\\n- Deseable: Certificaciones relevantes en tecnolog√≠as de datos y cloud.\\nCondiciones Oferta\\nDescripci√≥n proceso de selecci√≥n:\\nEl proceso de selecci√≥n se realiza a trav√©s de Aira - plataforma de reclutamiento dise√±ado para mejorar tu experiencia de postulaci√≥n.\\nPara Postular Solo Necesitas\\n-  Postular a la oferta\\n-  Revisar tu email\\n-  Ingresar a Aira y contestar las preguntas y/o pruebas solicitadas\\nLuego, si vemos que tu perfil se ajusta a lo que estamos buscando, te contactaremos por email (a trav√©s de Aira) para seguir a la etapa presencial.\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Retail'}\n"
     ]
    }
   ],
   "source": [
    "for job in joblist:\n",
    "    print('-' * 30)\n",
    "    print(job)\n",
    "    # {print(v) for k, v in job.items() if job['job_description'] != ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(joblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (31, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>title</th><th>company</th><th>location</th><th>date</th><th>job_url</th><th>job_description</th><th>Seniority level</th><th>Employment type</th><th>Job function</th><th>Industries</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Data Engineer Junior&quot;</td><td>&quot;LISIT&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;En Lisit, nos dedicamos a crea‚Ä¶</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Technology, Information and In‚Ä¶</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Xepelin&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Somos una FinTech que busca de‚Ä¶</td><td>&quot;Not Applicable&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Software Development, IT Servi‚Ä¶</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;BC Tecnolog√≠a&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Could not find Job Description&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;2Brains&quot;</td><td>&quot;Chile&quot;</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;2Brains es una empresa dedicad‚Ä¶</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Technology, Information and In‚Ä¶</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Falabella&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-11&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Descripci√≥n Empresa\n",
       "Somos m√°s ‚Ä¶</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Retail&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Ingeniero de Datos&quot;</td><td>&quot;Amaris Consulting&quot;</td><td>&quot;Chile&quot;</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Who are we?\n",
       "Amaris Consulting ‚Ä¶</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer - GCP Ssr&quot;</td><td>&quot;axity&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Company Description: axity\n",
       "Job‚Ä¶</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer - AWS Ssr&quot;</td><td>&quot;axity&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Company Description: axity\n",
       "Job‚Ä¶</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer Azure&quot;</td><td>&quot;&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Resumen del Cargo:\n",
       "Busco Ingen‚Ä¶</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>null</td></tr><tr><td>&quot;Senior Data Engineer&quot;</td><td>&quot;Grupo Falabella&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Descripci√≥n Empresa\n",
       "Somos m√°s ‚Ä¶</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Retail&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (31, 10)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ title     ‚îÜ company   ‚îÜ location  ‚îÜ date      ‚îÜ ‚Ä¶ ‚îÜ Seniority ‚îÜ Employmen ‚îÜ Job       ‚îÜ Industri ‚îÇ\n",
       "‚îÇ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ   ‚îÜ level     ‚îÜ t type    ‚îÜ function  ‚îÜ es       ‚îÇ\n",
       "‚îÇ str       ‚îÜ str       ‚îÜ str       ‚îÜ str       ‚îÜ   ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---      ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ str       ‚îÜ str       ‚îÜ str       ‚îÜ str      ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ Data      ‚îÜ LISIT     ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Entry     ‚îÜ Full-time ‚îÜ Informati ‚îÜ Technolo ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 0         ‚îÜ   ‚îÜ level     ‚îÜ           ‚îÜ on Techno ‚îÜ gy, Info ‚îÇ\n",
       "‚îÇ Junior    ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ rmation  ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ and In‚Ä¶  ‚îÇ\n",
       "‚îÇ Data      ‚îÜ Xepelin   ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Not Appli ‚îÜ Full-time ‚îÜ Informati ‚îÜ Software ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ cable     ‚îÜ           ‚îÜ on Techno ‚îÜ Developm ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ ent, IT  ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ Servi‚Ä¶   ‚îÇ\n",
       "‚îÇ Data      ‚îÜ BC Tecnol ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ null      ‚îÜ null      ‚îÜ null      ‚îÜ null     ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ og√≠a      ‚îÜ Santiago  ‚îÜ 0         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îÇ Data      ‚îÜ 2Brains   ‚îÜ Chile     ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Mid-Senio ‚îÜ Full-time ‚îÜ Informati ‚îÜ Technolo ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ           ‚îÜ 0         ‚îÜ   ‚îÜ r level   ‚îÜ           ‚îÜ on Techno ‚îÜ gy, Info ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ rmation  ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ and In‚Ä¶  ‚îÇ\n",
       "‚îÇ Data      ‚îÜ Falabella ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Mid-Senio ‚îÜ Full-time ‚îÜ Informati ‚îÜ Retail   ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 1         ‚îÜ   ‚îÜ r level   ‚îÜ           ‚îÜ on Techno ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îÇ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶        ‚îÇ\n",
       "‚îÇ Ingeniero ‚îÜ Amaris    ‚îÜ Chile     ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Entry     ‚îÜ Full-time ‚îÜ Informati ‚îÜ IT       ‚îÇ\n",
       "‚îÇ de Datos  ‚îÜ Consultin ‚îÜ           ‚îÜ 0         ‚îÜ   ‚îÜ level     ‚îÜ           ‚îÜ on Techno ‚îÜ Services ‚îÇ\n",
       "‚îÇ           ‚îÜ g         ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ and IT   ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ Consulti ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ ng       ‚îÇ\n",
       "‚îÇ Data      ‚îÜ axity     ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Mid-Senio ‚îÜ Full-time ‚îÜ Informati ‚îÜ IT       ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ r level   ‚îÜ           ‚îÜ on Techno ‚îÜ Services ‚îÇ\n",
       "‚îÇ - GCP Ssr ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ and IT   ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ Consulti ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ ng       ‚îÇ\n",
       "‚îÇ Data      ‚îÜ axity     ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Mid-Senio ‚îÜ Full-time ‚îÜ Informati ‚îÜ IT       ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ r level   ‚îÜ           ‚îÜ on Techno ‚îÜ Services ‚îÇ\n",
       "‚îÇ - AWS Ssr ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ and IT   ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ Consulti ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ ng       ‚îÇ\n",
       "‚îÇ Data      ‚îÜ           ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Entry     ‚îÜ Full-time ‚îÜ Informati ‚îÜ null     ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 0         ‚îÜ   ‚îÜ level     ‚îÜ           ‚îÜ on Techno ‚îÜ          ‚îÇ\n",
       "‚îÇ Azure     ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îÇ Senior    ‚îÜ Grupo     ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Mid-Senio ‚îÜ Full-time ‚îÜ Informati ‚îÜ Retail   ‚îÇ\n",
       "‚îÇ Data      ‚îÜ Falabella ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ r level   ‚îÜ           ‚îÜ on Techno ‚îÜ          ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.filter(pl.col('job_description') != ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(pl.col('job_description') != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (31, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>title</th><th>company</th><th>location</th><th>date</th><th>job_url</th><th>job_description</th><th>Seniority level</th><th>Employment type</th><th>Job function</th><th>Industries</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Data Engineer Junior&quot;</td><td>&quot;LISIT&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;En Lisit, nos dedicamos a crea‚Ä¶</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Technology, Information and In‚Ä¶</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Xepelin&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Somos una FinTech que busca de‚Ä¶</td><td>&quot;Not Applicable&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Software Development, IT Servi‚Ä¶</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;BC Tecnolog√≠a&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Could not find Job Description&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;2Brains&quot;</td><td>&quot;Chile&quot;</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;2Brains es una empresa dedicad‚Ä¶</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Technology, Information and In‚Ä¶</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Falabella&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-11&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Descripci√≥n Empresa\n",
       "Somos m√°s ‚Ä¶</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Retail&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Ingeniero de Datos&quot;</td><td>&quot;Amaris Consulting&quot;</td><td>&quot;Chile&quot;</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Who are we?\n",
       "Amaris Consulting ‚Ä¶</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer - GCP Ssr&quot;</td><td>&quot;axity&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Company Description: axity\n",
       "Job‚Ä¶</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer - AWS Ssr&quot;</td><td>&quot;axity&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Company Description: axity\n",
       "Job‚Ä¶</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer Azure&quot;</td><td>&quot;&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Resumen del Cargo:\n",
       "Busco Ingen‚Ä¶</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>null</td></tr><tr><td>&quot;Senior Data Engineer&quot;</td><td>&quot;Grupo Falabella&quot;</td><td>&quot;Santiago, Santiago Metropolita‚Ä¶</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/‚Ä¶</td><td>&quot;Descripci√≥n Empresa\n",
       "Somos m√°s ‚Ä¶</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Retail&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (31, 10)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ title     ‚îÜ company   ‚îÜ location  ‚îÜ date      ‚îÜ ‚Ä¶ ‚îÜ Seniority ‚îÜ Employmen ‚îÜ Job       ‚îÜ Industri ‚îÇ\n",
       "‚îÇ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ   ‚îÜ level     ‚îÜ t type    ‚îÜ function  ‚îÜ es       ‚îÇ\n",
       "‚îÇ str       ‚îÜ str       ‚îÜ str       ‚îÜ str       ‚îÜ   ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---      ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ str       ‚îÜ str       ‚îÜ str       ‚îÜ str      ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ Data      ‚îÜ LISIT     ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Entry     ‚îÜ Full-time ‚îÜ Informati ‚îÜ Technolo ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 0         ‚îÜ   ‚îÜ level     ‚îÜ           ‚îÜ on Techno ‚îÜ gy, Info ‚îÇ\n",
       "‚îÇ Junior    ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ rmation  ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ and In‚Ä¶  ‚îÇ\n",
       "‚îÇ Data      ‚îÜ Xepelin   ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Not Appli ‚îÜ Full-time ‚îÜ Informati ‚îÜ Software ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ cable     ‚îÜ           ‚îÜ on Techno ‚îÜ Developm ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ ent, IT  ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ Servi‚Ä¶   ‚îÇ\n",
       "‚îÇ Data      ‚îÜ BC Tecnol ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ null      ‚îÜ null      ‚îÜ null      ‚îÜ null     ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ og√≠a      ‚îÜ Santiago  ‚îÜ 0         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îÇ Data      ‚îÜ 2Brains   ‚îÜ Chile     ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Mid-Senio ‚îÜ Full-time ‚îÜ Informati ‚îÜ Technolo ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ           ‚îÜ 0         ‚îÜ   ‚îÜ r level   ‚îÜ           ‚îÜ on Techno ‚îÜ gy, Info ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ rmation  ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ and In‚Ä¶  ‚îÇ\n",
       "‚îÇ Data      ‚îÜ Falabella ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Mid-Senio ‚îÜ Full-time ‚îÜ Informati ‚îÜ Retail   ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 1         ‚îÜ   ‚îÜ r level   ‚îÜ           ‚îÜ on Techno ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îÇ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶        ‚îÇ\n",
       "‚îÇ Ingeniero ‚îÜ Amaris    ‚îÜ Chile     ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Entry     ‚îÜ Full-time ‚îÜ Informati ‚îÜ IT       ‚îÇ\n",
       "‚îÇ de Datos  ‚îÜ Consultin ‚îÜ           ‚îÜ 0         ‚îÜ   ‚îÜ level     ‚îÜ           ‚îÜ on Techno ‚îÜ Services ‚îÇ\n",
       "‚îÇ           ‚îÜ g         ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ and IT   ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ Consulti ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ ng       ‚îÇ\n",
       "‚îÇ Data      ‚îÜ axity     ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Mid-Senio ‚îÜ Full-time ‚îÜ Informati ‚îÜ IT       ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ r level   ‚îÜ           ‚îÜ on Techno ‚îÜ Services ‚îÇ\n",
       "‚îÇ - GCP Ssr ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ and IT   ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ Consulti ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ ng       ‚îÇ\n",
       "‚îÇ Data      ‚îÜ axity     ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Mid-Senio ‚îÜ Full-time ‚îÜ Informati ‚îÜ IT       ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ r level   ‚îÜ           ‚îÜ on Techno ‚îÜ Services ‚îÇ\n",
       "‚îÇ - AWS Ssr ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ and IT   ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ Consulti ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ ng       ‚îÇ\n",
       "‚îÇ Data      ‚îÜ           ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Entry     ‚îÜ Full-time ‚îÜ Informati ‚îÜ null     ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 0         ‚îÜ   ‚îÜ level     ‚îÜ           ‚îÜ on Techno ‚îÜ          ‚îÇ\n",
       "‚îÇ Azure     ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îÇ Senior    ‚îÜ Grupo     ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Mid-Senio ‚îÜ Full-time ‚îÜ Informati ‚îÜ Retail   ‚îÇ\n",
       "‚îÇ Data      ‚îÜ Falabella ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ r level   ‚îÜ           ‚îÜ on Techno ‚îÜ          ‚îÇ\n",
       "‚îÇ Engineer  ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ logy      ‚îÜ          ‚îÇ\n",
       "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENAI PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "API_KEY = 'AIzaSyCaIGQDXLA-jmSCRl7NSE64uODswGHQ9tQ'\n",
    "TEXT_COLUMN_NAME = \"text_content\" # CHANGE if your text column has a different name\n",
    "OUTPUT_COLUMN_NAME = \"cloud_focus\"\n",
    "# Optional: Add a small delay between API calls to avoid rate limits\n",
    "API_CALL_DELAY_SECONDS = 0.5 # Adjust as needed, 0 for no delay\n",
    "\n",
    "# --- Gemini Setup ---\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY environment variable not set.\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Choose a Gemini model (e.g., 'gemini-1.5-flash' or 'gemini-pro')\n",
    "# Flash is faster and cheaper, Pro might be slightly more capable.\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Define allowed classification outputs (plus handling for errors/unknown)\n",
    "ALLOWED_OUTPUTS = {\"GCP\", \"Azure\", \"AWS\", \"Other\"}\n",
    "ERROR_OUTPUT = \"API_Error\"\n",
    "UNKNOWN_OUTPUT = \"Other\" # Default if Gemini doesn't give a clear answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cloud_focus(job_description_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses the Gemini API to classify the primary cloud focus of a job description.\n",
    "\n",
    "    Args:\n",
    "        job_description_text: The text of the job description.\n",
    "\n",
    "    Returns:\n",
    "        A string indicating the classification: \"GCP\", \"Azure\", \"AWS\", \"Other\",\n",
    "        or \"Error\" if the API call fails.\n",
    "    \"\"\"\n",
    "    if not job_description_text or not isinstance(job_description_text, str) or len(job_description_text.strip()) < 20:\n",
    "         # Handle empty or very short descriptions to save API calls\n",
    "        return \"Invalid_Input\"\n",
    "\n",
    "    # --- Prompt Engineering ---\n",
    "    # Be very specific about the desired output format.\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following job description text and determine its primary cloud platform focus.\n",
    "    Possible categories are: GCP, Azure, AWS.\n",
    "\n",
    "    - If the text strongly emphasizes Google Cloud Platform skills (like BigQuery, GKE, Cloud Functions, App Engine), classify it as 'GCP'.\n",
    "    - If the text strongly emphasizes Microsoft Azure skills (like Azure Functions, AKS, Azure SQL, Cosmos DB, Entra ID), classify it as 'Azure'.\n",
    "    - If the text strongly emphasizes Amazon Web Services skills (like EC2, S3, Lambda, RDS, EKS, DynamoDB), classify it as 'AWS'.\n",
    "    - If multiple platforms are mentioned significantly without a clear primary focus, or if no cloud platform is the main focus, classify it as 'Other'.\n",
    "\n",
    "    Job Description:\n",
    "    ---\n",
    "    {job_description_text}\n",
    "    ---\n",
    "\n",
    "    Output only one word: GCP, Azure, AWS, or Other.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- API Call with Error Handling ---\n",
    "    max_retries = 3\n",
    "    retry_delay = 5 # seconds\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            # Basic cleaning and validation\n",
    "            classification = response.text.strip().upper()\n",
    "            if classification in [\"GCP\", \"AZURE\", \"AWS\", \"OTHER\"]:\n",
    "                return classification\n",
    "            else:\n",
    "                 # The model might sometimes output extra text or fail the instruction.\n",
    "                 # Let's try to find the keyword within the response as a fallback.\n",
    "                if \"GCP\" in classification: return \"GCP\"\n",
    "                if \"AZURE\" in classification: return \"Azure\" # Keep consistent casing\n",
    "                if \"AWS\" in classification: return \"AWS\"\n",
    "                if \"OTHER\" in classification: return \"Other\" # Keep consistent casing\n",
    "                print(f\"Warning: Unexpected response format: '{response.text}'. Defaulting to 'Other'.\")\n",
    "                return \"Other\" # Fallback if model output is unexpected\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"API Error: {e}. Attempt {attempt + 1}/{max_retries}. Retrying in {retry_delay}s...\")\n",
    "            if attempt < max_retries - 1:\n",
    "                 time.sleep(retry_delay) # Wait before retrying\n",
    "                 retry_delay *= 2 # Exponential backoff\n",
    "            else:\n",
    "                print(\"API Error: Max retries reached.\")\n",
    "                return \"API_Error\" # Indicate an API failure\n",
    "\n",
    "    return \"API_Error\" # Should not be reached if retries work, but good failsafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Jobs:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 16/31 [00:11<00:09,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "]. Attempt 1/3. Retrying in 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Jobs:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 17/31 [00:16<00:30,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]. Attempt 1/3. Retrying in 5s...\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "]. Attempt 2/3. Retrying in 10s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Jobs:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 18/31 [00:32<01:21,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "]. Attempt 3/3. Retrying in 20s...\n",
      "API Error: Max retries reached.\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "]. Attempt 1/3. Retrying in 5s...\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "]. Attempt 2/3. Retrying in 10s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Jobs:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 19/31 [00:48<01:49,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]. Attempt 3/3. Retrying in 20s...\n",
      "API Error: Max retries reached.\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]. Attempt 1/3. Retrying in 5s...\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 20\n",
      "}\n",
      "]. Attempt 2/3. Retrying in 10s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Jobs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [01:10<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with Cloud Focus Classification:\n",
      "shape: (31, 11)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ title     ‚îÜ company   ‚îÜ location  ‚îÜ date      ‚îÜ ‚Ä¶ ‚îÜ Employmen ‚îÜ Job       ‚îÜ Industrie ‚îÜ cloud_fo ‚îÇ\n",
      "‚îÇ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ   ‚îÜ t type    ‚îÜ function  ‚îÜ s         ‚îÜ cus      ‚îÇ\n",
      "‚îÇ str       ‚îÜ str       ‚îÜ str       ‚îÜ str       ‚îÜ   ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---      ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ str       ‚îÜ str       ‚îÜ str       ‚îÜ str      ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ Data      ‚îÜ LISIT     ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Full-time ‚îÜ Informati ‚îÜ Technolog ‚îÜ OTHER    ‚îÇ\n",
      "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 0         ‚îÜ   ‚îÜ           ‚îÜ on Techno ‚îÜ y, Inform ‚îÜ          ‚îÇ\n",
      "‚îÇ Junior    ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ logy      ‚îÜ ation and ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ In‚Ä¶       ‚îÜ          ‚îÇ\n",
      "‚îÇ Data      ‚îÜ Xepelin   ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Full-time ‚îÜ Informati ‚îÜ Software  ‚îÜ GCP      ‚îÇ\n",
      "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ           ‚îÜ on Techno ‚îÜ Developme ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ logy      ‚îÜ nt, IT    ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ Servi‚Ä¶    ‚îÜ          ‚îÇ\n",
      "‚îÇ Data      ‚îÜ BC Tecnol ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ null      ‚îÜ null      ‚îÜ null      ‚îÜ OTHER    ‚îÇ\n",
      "‚îÇ Engineer  ‚îÜ og√≠a      ‚îÜ Santiago  ‚îÜ 0         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ Data      ‚îÜ 2Brains   ‚îÜ Chile     ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Full-time ‚îÜ Informati ‚îÜ Technolog ‚îÜ OTHER    ‚îÇ\n",
      "‚îÇ Engineer  ‚îÜ           ‚îÜ           ‚îÜ 0         ‚îÜ   ‚îÜ           ‚îÜ on Techno ‚îÜ y, Inform ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ logy      ‚îÜ ation and ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ In‚Ä¶       ‚îÜ          ‚îÇ\n",
      "‚îÇ Data      ‚îÜ Falabella ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Full-time ‚îÜ Informati ‚îÜ Retail    ‚îÜ GCP      ‚îÇ\n",
      "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 1         ‚îÜ   ‚îÜ           ‚îÜ on Techno ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ logy      ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶        ‚îÇ\n",
      "‚îÇ Ingeniero ‚îÜ Amaris    ‚îÜ Chile     ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Full-time ‚îÜ Informati ‚îÜ IT        ‚îÜ OTHER    ‚îÇ\n",
      "‚îÇ de Datos  ‚îÜ Consultin ‚îÜ           ‚îÜ 0         ‚îÜ   ‚îÜ           ‚îÜ on Techno ‚îÜ Services  ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ g         ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ logy      ‚îÜ and IT    ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ Consultin ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ g         ‚îÜ          ‚îÇ\n",
      "‚îÇ Data      ‚îÜ axity     ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Full-time ‚îÜ Informati ‚îÜ IT        ‚îÜ GCP      ‚îÇ\n",
      "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ           ‚îÜ on Techno ‚îÜ Services  ‚îÜ          ‚îÇ\n",
      "‚îÇ - GCP Ssr ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ logy      ‚îÜ and IT    ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ Consultin ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ g         ‚îÜ          ‚îÇ\n",
      "‚îÇ Data      ‚îÜ axity     ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Full-time ‚îÜ Informati ‚îÜ IT        ‚îÜ AWS      ‚îÇ\n",
      "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ           ‚îÜ on Techno ‚îÜ Services  ‚îÜ          ‚îÇ\n",
      "‚îÇ - AWS Ssr ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ logy      ‚îÜ and IT    ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ Consultin ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ g         ‚îÜ          ‚îÇ\n",
      "‚îÇ Data      ‚îÜ           ‚îÜ Santiago, ‚îÜ 2025-04-1 ‚îÜ ‚Ä¶ ‚îÜ Full-time ‚îÜ Informati ‚îÜ null      ‚îÜ AZURE    ‚îÇ\n",
      "‚îÇ Engineer  ‚îÜ           ‚îÜ Santiago  ‚îÜ 0         ‚îÜ   ‚îÜ           ‚îÜ on Techno ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ Azure     ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ logy      ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ Senior    ‚îÜ Grupo     ‚îÜ Santiago, ‚îÜ 2025-04-0 ‚îÜ ‚Ä¶ ‚îÜ Full-time ‚îÜ Informati ‚îÜ Retail    ‚îÜ GCP      ‚îÇ\n",
      "‚îÇ Data      ‚îÜ Falabella ‚îÜ Santiago  ‚îÜ 9         ‚îÜ   ‚îÜ           ‚îÜ on Techno ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ Engineer  ‚îÜ           ‚îÜ Metropoli ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ logy      ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îÇ           ‚îÜ           ‚îÜ ta‚Ä¶       ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifications = []\n",
    "# Iterating with tqdm to show progress\n",
    "for desc in tqdm(df[\"job_description\"], desc=\"Classifying Jobs\"):\n",
    "    classifications.append(classify_cloud_focus(desc))\n",
    "    # Optional: Add a small delay to respect potential API rate limits\n",
    "    time.sleep(2) # Adjust delay as needed (e.g., 1 second for free tier)\n",
    "\n",
    "\n",
    "# Add the results as a new column\n",
    "df = df.with_columns(\n",
    "    pl.Series(\"cloud_focus\", classifications)\n",
    ")\n",
    "\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"\\nDataFrame with Cloud Focus Classification:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2025-04-13\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "# Get today's date\n",
    "today = date.today()\n",
    "print(\"Today's date:\", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export to CSV ---\n",
    "df.write_csv(f'joblist_{today}_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('joblist_2025-04-13_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (31, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_description</th><th>cloud_focus</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;En Lisit, nos dedicamos a crea‚Ä¶</td><td>&quot;OTHER&quot;</td></tr><tr><td>&quot;Somos una FinTech que busca de‚Ä¶</td><td>&quot;GCP&quot;</td></tr><tr><td>&quot;Could not find Job Description&quot;</td><td>&quot;OTHER&quot;</td></tr><tr><td>&quot;2Brains es una empresa dedicad‚Ä¶</td><td>&quot;OTHER&quot;</td></tr><tr><td>&quot;Descripci√≥n Empresa\n",
       "Somos m√°s ‚Ä¶</td><td>&quot;GCP&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Who are we?\n",
       "Amaris Consulting ‚Ä¶</td><td>&quot;OTHER&quot;</td></tr><tr><td>&quot;Company Description: axity\n",
       "Job‚Ä¶</td><td>&quot;GCP&quot;</td></tr><tr><td>&quot;Company Description: axity\n",
       "Job‚Ä¶</td><td>&quot;AWS&quot;</td></tr><tr><td>&quot;Resumen del Cargo:\n",
       "Busco Ingen‚Ä¶</td><td>&quot;AZURE&quot;</td></tr><tr><td>&quot;Descripci√≥n Empresa\n",
       "Somos m√°s ‚Ä¶</td><td>&quot;GCP&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (31, 2)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ job_description                 ‚îÜ cloud_focus ‚îÇ\n",
       "‚îÇ ---                             ‚îÜ ---         ‚îÇ\n",
       "‚îÇ str                             ‚îÜ str         ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ En Lisit, nos dedicamos a crea‚Ä¶ ‚îÜ OTHER       ‚îÇ\n",
       "‚îÇ Somos una FinTech que busca de‚Ä¶ ‚îÜ GCP         ‚îÇ\n",
       "‚îÇ Could not find Job Description  ‚îÜ OTHER       ‚îÇ\n",
       "‚îÇ 2Brains es una empresa dedicad‚Ä¶ ‚îÜ OTHER       ‚îÇ\n",
       "‚îÇ Descripci√≥n Empresa             ‚îÜ GCP         ‚îÇ\n",
       "‚îÇ Somos m√°s ‚Ä¶                     ‚îÜ             ‚îÇ\n",
       "‚îÇ ‚Ä¶                               ‚îÜ ‚Ä¶           ‚îÇ\n",
       "‚îÇ Who are we?                     ‚îÜ OTHER       ‚îÇ\n",
       "‚îÇ Amaris Consulting ‚Ä¶             ‚îÜ             ‚îÇ\n",
       "‚îÇ Company Description: axity      ‚îÜ GCP         ‚îÇ\n",
       "‚îÇ Job‚Ä¶                            ‚îÜ             ‚îÇ\n",
       "‚îÇ Company Description: axity      ‚îÜ AWS         ‚îÇ\n",
       "‚îÇ Job‚Ä¶                            ‚îÜ             ‚îÇ\n",
       "‚îÇ Resumen del Cargo:              ‚îÜ AZURE       ‚îÇ\n",
       "‚îÇ Busco Ingen‚Ä¶                    ‚îÜ             ‚îÇ\n",
       "‚îÇ Descripci√≥n Empresa             ‚îÜ GCP         ‚îÇ\n",
       "‚îÇ Somos m√°s ‚Ä¶                     ‚îÜ             ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(pl.col('job_description'), pl.col('cloud_focus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
