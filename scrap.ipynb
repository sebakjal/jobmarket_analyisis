{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import google.generativeai as genai\n",
    "from typing import Optional\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "date_posted = 604800  # 86400 -> 1 day, 2592000 -> 1 month, 604800 -> 1 week\n",
    "job_name = 'data engineer'\n",
    "location = 'Chile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('config.json') as f:\n",
    "#     config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_format(job_name):\n",
    "    return job_name.replace(' ', '%20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    r = requests.get(url, headers={\"headers\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"}, timeout=5)\n",
    "\n",
    "    return BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobcards_soup():\n",
    "    formatted_job_name = name_format(job_name)\n",
    "    url = f\"https://linkedin.com/jobs/search?keywords={formatted_job_name}&location={location}&f_TPR=r{date_posted}\"\n",
    "    return get_data(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_jobcards(soup):\n",
    "    # Parsing the job card info (title, company, location, date, job_url) from the beautiful soup object\n",
    "    joblist = []\n",
    "    try:\n",
    "        divs = soup.find_all('div', class_='base-search-card__info')\n",
    "    except:\n",
    "        print(\"Empty page, no jobs found\")\n",
    "        return joblist\n",
    "    for item in divs:\n",
    "        title = item.find('h3').text.strip()\n",
    "        company = item.find('a', class_='hidden-nested-link')\n",
    "        location = item.find('span', class_='job-search-card__location')\n",
    "        parent_div = item.parent\n",
    "        entity_urn = parent_div['data-entity-urn']\n",
    "        job_posting_id = entity_urn.split(':')[-1]\n",
    "        job_url = 'https://www.linkedin.com/jobs/view/'+job_posting_id+'/'\n",
    "\n",
    "        date_tag_new = item.find('time', class_ = 'job-search-card__listdate--new')\n",
    "        date_tag = item.find('time', class_='job-search-card__listdate')\n",
    "        date = date_tag['datetime'] if date_tag else date_tag_new['datetime'] if date_tag_new else ''\n",
    "        job_description = ''\n",
    "        job = {\n",
    "            'title': title,\n",
    "            'company': company.text.strip().replace('\\n', ' ') if company else '',\n",
    "            'location': location.text.strip() if location else '',\n",
    "            'date': date,\n",
    "            'job_url': job_url,\n",
    "            'job_description': job_description,\n",
    "        }\n",
    "        joblist.append(job)\n",
    "\n",
    "    return joblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_info(soup):\n",
    "\n",
    "    job_info = {}\n",
    "    # Get the job description from the job page\n",
    "    desc_div = soup.find('div', class_='description__text description__text--rich')\n",
    "    if desc_div:\n",
    "        # Remove unwanted elements\n",
    "        for element in desc_div.find_all(['span', 'a']):\n",
    "            element.decompose()\n",
    "\n",
    "        # Replace bullet points\n",
    "        for ul in desc_div.find_all('ul'):\n",
    "            for li in ul.find_all('li'):\n",
    "                li.insert(0, '-')\n",
    "\n",
    "        text = desc_div.get_text(separator='\\n').strip()\n",
    "        text = text.replace('\\n\\n', '')\n",
    "        text = text.replace('::marker', '-')\n",
    "        text = text.replace('-\\n', '- ')\n",
    "        text = text.replace('Show less', '').replace('Show more', '')\n",
    "        job_info['job_description'] = text\n",
    "    else:\n",
    "        job_info['job_description'] = \"Could not find Job Description\"\n",
    "    \n",
    "    # Get the job salary from the job page\n",
    "    #TODO\n",
    "\n",
    "    # Get the job contract type from the job page\n",
    "    # Find the main list container (optional, but good practice if multiple lists exist)\n",
    "    criteria_list_ul = soup.find('ul', class_='description__job-criteria-list')\n",
    "\n",
    "\n",
    "    # Check if the main list was found\n",
    "    if criteria_list_ul:\n",
    "        # Find all list items within this specific list\n",
    "        list_items = criteria_list_ul.find_all('li', class_='description__job-criteria-item')\n",
    "\n",
    "        # Iterate through each list item\n",
    "        for item in list_items:\n",
    "            # Find the subheader (h3) for the criterion name\n",
    "            subheader_tag = item.find('h3', class_='description__job-criteria-subheader')\n",
    "            # Find the text span for the criterion value\n",
    "            # Using the more specific class 'description__job-criteria-text--criteria' is slightly safer\n",
    "            value_tag = item.find('span', class_='description__job-criteria-text--criteria')\n",
    "\n",
    "            # Ensure both tags were found before extracting text\n",
    "            if subheader_tag and value_tag:\n",
    "                # Extract text and clean whitespace (strip removes leading/trailing spaces/newlines)\n",
    "                criterion_name = subheader_tag.get_text(strip=True)\n",
    "                criterion_value = value_tag.get_text(strip=True)\n",
    "\n",
    "                # Add the key-value pair to the dictionary\n",
    "                job_info[criterion_name] = criterion_value\n",
    "            else:\n",
    "                # Optional: Print a warning if the structure is unexpected within an item\n",
    "                print(f\"Warning: Skipping item, couldn't find expected h3/span: {item.prettify()}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Could not find the 'ul' with class 'description__job-criteria-list'.\")\n",
    "\n",
    "\n",
    "    return job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"data engineer\",\n",
    "            \"data enginer\",\n",
    "            \"ingeniero de datos\",\n",
    "            \"ingeniero datos\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Obtiene el objeto soup que contiene las jobcards\n",
    "    soup = get_jobcards_soup()\n",
    "\n",
    "    # Devuelve una lista de diccionarios con la información de las jobcards (title, company, location, date, job_url)\n",
    "    joblist = get_list_of_jobcards(soup)\n",
    "    job_description = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Data Engineer Junior',\n",
       "  'company': 'LISIT',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294902/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst I',\n",
       "  'company': 'Principal Chile',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4187514059/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'Xepelin',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205474021/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'BC Tecnología',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297472/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': '2Brains',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294882/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'Falabella',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207045620/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'NeuralWorks',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205500303/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos',\n",
       "  'company': 'Devaid',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205299283/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer (GCP & DataFlow & Bigquery)',\n",
       "  'company': 'Option',\n",
       "  'location': 'Santiago Metropolitan Area',\n",
       "  'date': '2025-04-12',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4208792219/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'ICONSTRUYE',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205295718/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos ($1.400.000 líquidos)',\n",
       "  'company': 'Vector',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4203857279/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer Soluciones de Datos',\n",
       "  'company': 'LISIT',\n",
       "  'location': 'Biobío Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294845/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'Seeds',\n",
       "  'location': 'Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4189755534/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Senior Data Engineer Python',\n",
       "  'company': '23people',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294906/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de datos',\n",
       "  'company': 'Ripley Chile',\n",
       "  'location': 'Las Condes, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-08',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204266753/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Graduate 2025 Software Engineer I Backend, Chile',\n",
       "  'company': 'Uber',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205853556/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos/ Dbt',\n",
       "  'company': 'BC Tecnología',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205500332/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst',\n",
       "  'company': 'Macal Remates',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205298423/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos Maestros (Proyecto Corporativo)',\n",
       "  'company': 'Agrosuper',\n",
       "  'location': \"Rancagua, O'Higgins Region, Chile\",\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297494/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos',\n",
       "  'company': 'AyCA SpA',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206696535/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer AWS – Contrato Indefinido.',\n",
       "  'company': 'BC Tecnología',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204878459/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer – Proyecto de 6 Meses',\n",
       "  'company': 'BC Tecnología',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297473/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer',\n",
       "  'company': 'NeuralWorks',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205295705/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de Datos en GCP',\n",
       "  'company': 'BC Tecnología',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294840/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de Datos',\n",
       "  'company': 'MindCo',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205553758/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de Datos',\n",
       "  'company': 'Outlier',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207881229/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Senior Data Engineer',\n",
       "  'company': 'Grupo Falabella',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205321119/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer',\n",
       "  'company': 'Mediastream',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206504298/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer AWS',\n",
       "  'company': 'BC Tecnología',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205294910/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst',\n",
       "  'company': 'LISIT',\n",
       "  'location': 'Los Ángeles, Biobío Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297449/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer Python',\n",
       "  'company': 'Equifax',\n",
       "  'location': 'Providencia, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4165780801/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer GCP',\n",
       "  'company': 'Soluciones - Data & Analytics Consulting',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206574777/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Senior Data Engineer',\n",
       "  'company': '23people',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207846989/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer AWS',\n",
       "  'company': 'Soluciones - Data & Analytics Consulting',\n",
       "  'location': 'Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207848749/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer Senior',\n",
       "  'company': 'Equifax',\n",
       "  'location': 'Las Condes, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4144902157/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer Semisenior o Senior',\n",
       "  'company': 'LISIT',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297492/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Datos',\n",
       "  'company': 'Amaris Consulting',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206597362/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de Datos',\n",
       "  'company': 'Outlier',\n",
       "  'location': 'La Serena, Coquimbo Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207883217/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer - GCP Ssr',\n",
       "  'company': 'axity',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204875774/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero de Gobierno de Datos - Subgerencia de Gobierno de Datos',\n",
       "  'company': 'Consorcio',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-08',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204238135/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer - AWS Ssr',\n",
       "  'company': 'axity',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204874848/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Ingeniero en Gestión de Datos',\n",
       "  'company': 'Genesys',\n",
       "  'location': 'Las Condes, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206087107/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer',\n",
       "  'company': 'IGX',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205299322/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Consultor Data Analyst',\n",
       "  'company': 'LISIT',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205297448/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer',\n",
       "  'company': 'Banco Falabella',\n",
       "  'location': 'Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205421235/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Engineer Azure',\n",
       "  'company': '',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206654598/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer',\n",
       "  'company': 'ZeroFox',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4203138895/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Backoffice - Analista de datos',\n",
       "  'company': 'Infinity Ingenieria SPA',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-10',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4204075434/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista de datos de Farmacia',\n",
       "  'company': 'IQVIA',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-12',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4208763580/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst Power BI- Bigquery',\n",
       "  'company': 'Soluciones - Data & Analytics Consulting',\n",
       "  'location': 'Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4207890015/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst Senior Modelos y Datos Riesgo',\n",
       "  'company': 'Banco Bci',\n",
       "  'location': 'Las Condes, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-08',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4203767105/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Insights Specialist',\n",
       "  'company': 'Nestlé',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4202697660/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Data Analyst I - Operations',\n",
       "  'company': 'Signant Health',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4202554692/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer II, Gerencia Tecnología',\n",
       "  'company': 'Walmart Chile',\n",
       "  'location': 'Huechuraba, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206684576/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer III, Gerencia Tecnología',\n",
       "  'company': 'Walmart Chile',\n",
       "  'location': 'Huechuraba, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4206686540/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Salesforce Software Engineer',\n",
       "  'company': 'Banco Falabella',\n",
       "  'location': 'Santiago Metropolitan Area',\n",
       "  'date': '2025-04-07',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4203137306/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Analista BI',\n",
       "  'company': 'Chubb',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-11',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4208212282/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Software Engineer III',\n",
       "  'company': 'Mindbody',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-13',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4169374324/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Senior Software Engineer, Backend (Remote)',\n",
       "  'company': 'Mindbody',\n",
       "  'location': 'Chile',\n",
       "  'date': '2025-04-12',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4170144703/',\n",
       "  'job_description': ''},\n",
       " {'title': 'Senior Data Engineer',\n",
       "  'company': 'Grupo Falabella',\n",
       "  'location': 'Santiago, Santiago Metropolitan Region, Chile',\n",
       "  'date': '2025-04-09',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/4205465977/',\n",
       "  'job_description': ''}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Getting job description for Data Engineer Junior in LISIT\n",
      "Job description starts with: En Lisit, \n",
      "------------------------------\n",
      "Getting job description for Data Engineer in Xepelin\n",
      "Job description starts with: Somos una \n",
      "------------------------------\n",
      "Getting job description for Data Engineer in BC Tecnología\n",
      "Error: Could not find the 'ul' with class 'description__job-criteria-list'.\n",
      "Job description starts with: Could not \n",
      "------------------------------\n",
      "Getting job description for Data Engineer in 2Brains\n",
      "Job description starts with: 2Brains es\n",
      "------------------------------\n",
      "Getting job description for Data Engineer in Falabella\n",
      "Job description starts with: Descripció\n",
      "------------------------------\n",
      "Getting job description for Data Engineer in NeuralWorks\n",
      "Job description starts with: NeuralWork\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos in Devaid\n",
      "Job description starts with: En Devaid>\n",
      "------------------------------\n",
      "Getting job description for Data Engineer (GCP & DataFlow & Bigquery) in Option\n",
      "Job description starts with: ¿Quiénes s\n",
      "------------------------------\n",
      "Getting job description for Data Engineer in ICONSTRUYE\n",
      "Job description starts with: En ICONSTR\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos ($1.400.000 líquidos) in Vector\n",
      "Job description starts with: Somos una \n",
      "------------------------------\n",
      "Getting job description for Data Engineer Soluciones de Datos in LISIT\n",
      "Job description starts with: En *Lisit*\n",
      "------------------------------\n",
      "Getting job description for Data Engineer in Seeds\n",
      "Job description starts with: ¿Sos \n",
      "Data\n",
      "------------------------------\n",
      "Getting job description for Senior Data Engineer Python in 23people\n",
      "Job description starts with: Únete a Eq\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos/ Dbt in BC Tecnología\n",
      "Job description starts with: En BC Tecn\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos Maestros (Proyecto Corporativo) in Agrosuper\n",
      "Job description starts with: En Agrosup\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos in AyCA SpA\n",
      "Job description starts with: Company De\n",
      "------------------------------\n",
      "Getting job description for Data Engineer AWS – Contrato Indefinido. in BC Tecnología\n",
      "Job description starts with: Company De\n",
      "------------------------------\n",
      "Getting job description for Data Engineer – Proyecto de 6 Meses in BC Tecnología\n",
      "Job description starts with: En BC Tecn\n",
      "------------------------------\n",
      "Getting job description for Senior Data Engineer in Grupo Falabella\n",
      "Job description starts with: Somos más \n",
      "------------------------------\n",
      "Getting job description for Data Engineer in Mediastream\n",
      "Job description starts with: Descriptio\n",
      "------------------------------\n",
      "Getting job description for Data Engineer AWS in BC Tecnología\n",
      "Job description starts with: En \n",
      "BC Tec\n",
      "------------------------------\n",
      "Getting job description for Data Engineer GCP in Soluciones - Data & Analytics Consulting\n",
      "Job description starts with: ✔️\n",
      "¿Quiéne\n",
      "------------------------------\n",
      "Getting job description for Senior Data Engineer in 23people\n",
      "Job description starts with: ¡Hola! Est\n",
      "------------------------------\n",
      "Getting job description for Data Engineer AWS in Soluciones - Data & Analytics Consulting\n",
      "Job description starts with: ✔️\n",
      "¿Quiéne\n",
      "------------------------------\n",
      "Getting job description for Data Engineer Senior in Equifax\n",
      "Job description starts with: Como Data \n",
      "------------------------------\n",
      "Getting job description for Data Engineer Semisenior o Senior in LISIT\n",
      "Job description starts with: Lisit es u\n",
      "------------------------------\n",
      "Getting job description for Ingeniero de Datos in Amaris Consulting\n",
      "Job description starts with: Who are we\n",
      "------------------------------\n",
      "Getting job description for Data Engineer - GCP Ssr in axity\n",
      "Job description starts with: Company De\n",
      "------------------------------\n",
      "Getting job description for Data Engineer - AWS Ssr in axity\n",
      "Job description starts with: Company De\n",
      "------------------------------\n",
      "Getting job description for Data Engineer Azure in \n",
      "Job description starts with: Resumen de\n",
      "------------------------------\n",
      "Getting job description for Senior Data Engineer in Grupo Falabella\n",
      "Job description starts with: Descripció\n"
     ]
    }
   ],
   "source": [
    "# A la lista de trabajos se le agrega info extra de cada trabajo\n",
    "for job in joblist:\n",
    "    \n",
    "    # Verifica si el titulo del trabajo contiene alguna de las palabras clave\n",
    "    if any(keyword in job['title'].lower() for keyword in keywords):\n",
    "        \n",
    "        # Agregar descripción del trabajo, salario, tipo de contrato\n",
    "        try:\n",
    "            print('-' * 30)\n",
    "            print(f'Getting job description for {job[\"title\"]} in {job[\"company\"]}')\n",
    "\n",
    "            time.sleep(random.randint(2, 5))\n",
    "\n",
    "            # Acá se busca la descripcion del trabajo\n",
    "            job_info = get_job_info(get_data(job['job_url']))\n",
    "            job.update(job_info)\n",
    "            print('Job description starts with:', job_info['job_description'][:10])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Error getting job description for {job[\"title\"]} in {job[\"company\"]}: {e}')\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert joblist to JSON\n",
    "joblist_json = json.dumps(joblist, indent=4)\n",
    "\n",
    "# Export to JSON file\n",
    "with open('joblist.json', 'w') as json_file:\n",
    "    json_file.write(joblist_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "{'title': 'Data Engineer Junior', 'company': 'LISIT', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294902/', 'job_description': 'En Lisit, nos dedicamos a crear, desarrollar e implementar herramientas y servicios de software que automatizan y optimizan procesos, siempre con un fuerte enfoque en la innovación y los desafíos que se presentan. Nuestro objetivo es fomentar la eficacia operativa de nuestros clientes, ayudándoles a alcanzar sus metas de transformación mediante un acompañamiento consultivo integral. Actualmente, estamos en búsqueda de un Data Engineer Junior que se una a nuestro equipo apasionado por la tecnología y el aprendizaje continuo.\\n Funciones del Rol\\nComo Data Engineer Junior, Serás Parte Esencial Del Equipo Encargado De Manejar y Optimizar El Flujo De Datos De La Organización. Tus Principales Responsabilidades Incluirán\\n- Colaborar en la recopilación y procesamiento de datos relacionales y no relacionales.\\n- Trabajar con lenguajes de programación, especialmente Python, para crear soluciones de datos efectivas.\\n- Implementar y mantener los procesos de integración en ambientes cloud como GCP o Azure.\\n- Realizar consultas y manipulación de bases de datos utilizando SQL.\\n- Aprender y adaptarte a nuevas tecnologías y herramientas en el entorno de la nube.\\n Descripción del Perfil\\nBuscamos Un Perfil Proactivo, Con Conocimientos Intermedios En Python y Disposición Para Aprender Sobre Nuevas Tecnologías. El Candidato Ideal Deberá Tener\\n- Experiencia básica a intermedia en programación Python.\\n- Habilidades en el uso y tratamiento de datos en ambientes tanto relacionales como no relacionales.\\n- Conocimientos fundamentales en tecnologías de nube, incluyendo GCP o Azure.\\n- Experiencia en el uso del lenguaje SQL.\\n- Bajo es requisito pero se valorará el conocimiento en Power BI.\\n Habilidades Deseables\\nSería excelente contar con conocimientos adicionales en herramientas de visualización de datos como Power BI. Además, habilidad para trabajar en equipo y una mentalidad orientada al aprendizaje continuo son altamente valoradas.\\n Beneficios de Trabajar con Nosotros\\nEn Lisit, Promovemos Un Ambiente De Trabajo Excepcional\\n- Acceso a oportunidades de desarrollo profesional continuo en tecnologías emergentes.\\n- Un equipo apasionado por la innovación y el aprendizaje, donde tu entusiasmo será bienvenido.        \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst I', 'company': 'Principal Chile', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4187514059/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'Xepelin', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4205474021/', 'job_description': 'Somos una FinTech que busca democratizar los servicios financieros para todo tipo de empresas. Nos apalancamos en la mejor tecnología para crear soluciones ágiles, personalizadas y transparentes. Nuestro objetivo es ser la FinTech B2B más grande de Latam y convertirnos en el CFO digital de todas las empresas en la región.\\nXepelin nace en Chile en 2019 y, desde entonces, hemos levantado más de USD145 millones en equity y USD300 millones en asset-backed facilities para potenciar el crecimiento en toda la región, especialmente en los países donde hoy operamos, Chile y México. La última ronda de equity fue de USD111 millones, record en Chile y una de las más grandes en América Latina para una FinTech.\\n¿Por qué trabajar en Xepelin?\\n💪 Desafío\\nEstamos sacudiendo una de las industrias más poderosas y competitivas, eliminando fricciones para darle a las Pymes acceso a capital y apalancado en la última tecnología disponible. Todo esto poniendo siempre a nuestras Pymes en el centro.\\nConstruir un banco digital desde cero es un gran proyecto; el producto es complejo y no se puede romper, existen regulaciones estrictas y tendremos que ser mejores que algunas de las corporaciones más grandes y consolidadas del mundo. Pero superar estos desafíos significa que habremos construido algo duradero.\\n💥 Impacto\\nTrabajar en un equipo de clase mundial y automotivado significa autonomía, amplia experiencia en todos los proyectos y ver que tus contribuciones afectan directamente al producto e impactan a nuestras Pymes.\\nTrabajarás con todos nuestros productos, tendrás que tomar decisiones fundamentales. El correcto posicionamiento de ellos marcará su futuro.\\n✔️ Calidad\\nNuestro posicionamiento de marca y productos es algo diferenciador frente al resto del mercado por lo que invertimos mucho en crear productos de calidad que nuestras Pymes respeten y valoren.\\nNos damos el tiempo para pensar fuera de la caja y volver con propuestas innovadoras. Estamos aquí para cambiar la industria!\\n¿Qué estamos buscando? \\nEn Xepelin estamos buscando personas creativas y visionarias que piensen fuera de la caja para sumarse a nuestro equipo. Si te apasiona resolver desafíos interesantes de alto impacto y quieres ser parte de un entorno dinámico que está transformando la industria financiera, ¡Esta oportunidad es para ti!\\nEl rol se integrará a nuestro equipo de \\nData Platform\\n. Si te motiva el desafío de construir soluciones innovadoras en un entorno de rápido cambio, queremos conocerte.\\nUnete a nosotros, crezcamos juntos!\\nPrincipales responsabilidades...\\n-  Diseñar, crear y mantener pipelines de datos\\n-  Mantener y optimizar la infraestructura de datos necesaria para una extracción precisa, transformación y carga de datos de una amplia variedad de fuentes de datos\\n-  Automatizar los flujos de trabajo de datos, como la ingesta de datos, la agregación y el procesamiento de ETL o ELT\\n-  Preparar datos sin procesar en almacenes de datos en un conjunto de datos consumibles para fines técnicos y partes interesadas no técnicas\\n-  Crear, mantener e implementar productos de datos para equipos de análisis y ciencia de datos en Plataformas en la nube, preferentemente en GCP, y/o AWS\\n-  Desarrollar sistemas y arquitectura que soporten las diferentes etapas del flujo de Machine Learning\\n¿Qué necesitas para brillar?\\n- Conocimientos en alguna Nube, preferentemente GCP o AWS (en ese orden de preferencia)\\n- Conocimientos intermedio/avanzado en Python\\n- Conocimiento intermedio/avanzado de SQL\\n- Experiencia trabajando almacenamiento en la nube como GCS o AWS S3\\n- Experiencia desplegando aplicaciones en ambientes serverless como Cloud Functions o AWS Lambda\\n- Conocimientos administrando y desplegando algún orquestador, por ejemplo: Dagster, Apache Airflow, Prefect, etc\\n- Excelentes habilidades para trabajar en equipo. Ser humilde y saber colaborar, un Team Player!\\n- Saber escuchar a tus stakeholders y poder traducir eso en requerimientos y ejecutarlos con tu equipo\\n- Trabajo proactivo y responsable\\n- Conocimientos en DBT\\n- Conocimientos y manejo de lenguajes de programación y/o frameworks, NodeJS, Golang, por ejemplo\\n- Experiencia en MLOps\\n- No tener miedo a tomar decisiones y liderar proyectos\\n- Foco en impacto e historia consistente entregando resultados para usuarios y el negocio\\n- Capacidad para pensar en grande y desarrollar iniciativas con impacto real y medible\\n- Te sientes cómodo cuestionando el status-quo de los servicios financieros, adaptándose rápidamente a los cambios, y presentando claramente tus ideas y conceptos para debatirlos en equipo\\nNuestros Beneficios:\\n🌴 Xepelin Balance\\nVacaciones:\\n 15 días hábiles. Por cada año que cumplas en Xepelin, te damos un día extra de vacaciones.\\nBalance days:\\n 10 días libres adicionales al año, para disfrutar como quieras.\\nTrabajo híbrido y flexibilidad horaria según el rol. Trabajamos por objetivos.\\nBeneficios Flexibles: \\nPuntos flexibles en tu moneda local al mes para gastar en lo que quieras.\\nXepelin Fun:\\n Actividades de encuentro financiadas por Xepelin para divertirnos juntos.\\n🚀 Xepelin Performance & Career\\nPlataformas de capacitación:\\n Convenios con las mejores plataformas, como Reforge, Udemy y DataCamp.\\nKit de Bienvenida: \\ntodo lo que necesitas para comenzar tu viaje en Xepelin 😊\\n🤝 Xepelin Cares\\nCobertura de salud:\\n contamos con convenios de salud con proveedores de calidad o reembolsos según el país donde te encuentres.\\nPost Natal:\\n te damos una semana extra de licencia post natal. ¡Nos interesa que estés con tu familia y seres queridos!\\nMatrimonio plus:\\n Lleva tus planes al siguiente nivel, con una gift card y extendiendo tu permiso legal por matrimonio con dos días de regalo por Xepelin.        \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Software Development, IT Services and IT Consulting, and Biotechnology Research'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'BC Tecnología', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297472/', 'job_description': 'Could not find Job Description'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': '2Brains', 'location': 'Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294882/', 'job_description': '2Brains es una empresa dedicada a construir y desarrollar el Futuro Digital de nuestros clientes, con una visión excepcional que radica en la integración sinérgica de estrategia, diseño y tecnología, un tríptico poderoso que impulsa el crecimiento de empresas y disruptores tecnológicos.\\nContamos con un nutrido equipo de más de 200 profesionales, verdaderos artífices de la innovación digital. En el corazón de nuestra labor, destacamos como líderes indiscutibles, canalizando años de experiencia hacia la creación de plataformas tecnológicas adaptables y productos digitales de clase mundial.\\nEn 2Brains, no solo somos consultores, somos arquitectos de experiencias digitales. Aspiramos a ir más allá de las expectativas, estableciendo nuevos estándares en la industria. Descubre cómo damos vida a la innovación, cómo convertimos ideas en resultados tangibles y cómo, junto a nosotros, puedes forjar un futuro digital brillante.\\n El/la Data Engineer de 2Brains \\nSe encarga de participar en el diseño y desarrollo de los nuevos modelos de información de gestión y las mantenciones evolutivas de los existentes. Participar en las iniciativas de Analítica avanzada del área, apoyando las exploración de modelos de información internos y externos (Data Discovery). Obtener datos históricos desde múltiples fuentes de información interna para apoyar las iniciativas de analítica avanzada del equipo.\\nEl/la Data Engineer de 2Brains debe\\n- Construir y optimizar pipelines de datos para la ingesta, transformación y carga eficiente de información.\\n- Manejar infraestructuras en la nube (AWS, GCP, Azure), asegurando escalabilidad y eficiencia en costos.\\n- Automatizar y monitorear procesos mediante herramientas de DevOps como Airflow, Terraform o Kubernetes.\\n- Implementar controles de calidad y gobernanza para garantizar la integridad y disponibilidad de los datos.\\n- Colaborar con equipos de Data Science, Producto y Desarrollo para diseñar soluciones alineadas con las necesidades del negocio.\\n Qué conocimientos buscamos en/la Data Engineer\\n- Excluyente Experiencia trabajando con tecnologías de BI\\n- Experiencia en la construcción/operación de sistemas distribuidos de extracción, ingestión y procesamiento de grandes conjuntos de datos de gran disponibilidad.\\n- Capacidad demostrable en modelado de datos, desarrollo de ETL y almacenamiento de datos.\\n- Experiencia en el uso de herramientas de informes de inteligencia empresarial (Power BI)\\n- Excluyente conocimiento en consumo de microservicios de APIs Rest\\n- Excluyente conocimiento en Git , Bitbucket, Docker,Jenkins,Webhooks\\n- Programación con Python y bases sólidas de ingeniería de software.\\n- Automatización y scripting.\\n- Uso de librerías de Python para manipulación y análisis de datos y Apache Spark.\\n- Conocimientos en bases de datos SQL y NoSQL.\\n- Conocimiento en CI/CD, Dataflow\\n- Conocimiento en S3, Redshift y Glue AWS\\n Que competencias buscamos en/la Data Engineer \\n- Empatía\\n- Buena capacidad de comunicación.\\n- Colaboración y trabajo en equipo.\\n- Proactividad.\\n- Autonomía.\\n- Foco en los objetivos de proyectos.\\n Condiciones\\nTrabajar con un equipo de alto rendimiento, aprendemos y nos desarrollamos juntos\\nAcceso a grandes clientes y proyectos desafiantes\\nAprendizaje y crecimiento permanente, organizamos meetups, capacitaciones y actividades culturales\\nUn entorno de trabajo flexible y dinámico\\nBeneficios especiales: día libre para tu cumpleaños, días de descanso a convenir.\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'Falabella', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207045620/', 'job_description': 'Descripción Empresa\\nSomos más de 80 mil personas que cada día trabajamos por el firme Propósito - Simplificar y Disfrutar más la Vida. Estamos presentes en 9 países y compuestos por grandes marcas posicionadas de diversas industrias. Falabella Retail, Sodimac, Banco Falabella, Tottus, Mallplaza, Falabella.com, Falabella Inmobiliario. Cada una de éstas nos hace ser quienes somos, y es entre todos, como Un Solo Equipo, que buscamos diariamente reinventarnos y superar las experiencias de nuestros clientes.\\nSi eres trabajador de Falabella, revisa todos los cursos disponibles en la Academia Falabella, que te ayudarán a seguir impulsando tu desarrollo y preparar tu próxima aventura con nosotros!\\nSOMOS UNA EMPRESA QUE APOYA LA LEY 21015, APOYAMOS LA DIVERSIDAD Y LA INCLUSIÓN EN TODAS SUS FORMAS, SIN IMPORTAR RELIGIÓN, RAZA, GÉNERO, SITUACIÓN DE DISCAPACIDAD, NACIONALIDAD.\\nFunciones Del Cargo\\n¡Si tienes una mente inquieta y te gusta soñar en grande, este llamado es para ti!\\nEn Falabella Retail buscamos a nuestro/a próximo/a Data Engineer, con base en Santiago, Chile.\\nSomos Falabella, UN equipo diverso con más de 100 mil colaboradores compuesto por grandes marcas: Falabella Retail, Sodimac, Banco Falabella, Seguros Falabella, Tottus, Mallplaza, Open Plaza y Linio. Hoy tenemos presencia en 7 países de América Latina, además de oficinas en China e India.\\n¿Cuál es el principal objetivo del cargo?\\nLiderar la construcción y mantención de estructuras de datos, así como la arquitectura tecnológica requerida para el procesamiento de apps.\\n¿Qué harás en el día a día?\\n-  Desarrollo, implementación de procesos ETL.\\n-  Levantamiento de requerimientos funcionales y técnicos relacionados con los clientes internos.\\n-  Implementar modelos de datos automatizados para transformar datos de acuerdo a los requisitos del negocio.\\n-  Migración de datos desde entornos on-premise a entornos Cloud.\\n-  Trabajar con tecnologías Google Cloud Platform (Big Query).\\n¿Qué necesitas para postular?\\n-  Profesional: Ingeniería Civil en Computación, Informática, Sistemas o carrera afín.\\n-  Conocimiento en SQL (excluyente)\\n-  Sólidos conocimientos en Google Cloud Platform (excluyente)\\n-  Conocimiento avanzado en Python (excluyente)\\n-  Conocimiento y experiencia trabajando en GIT (excluyente)\\n-  Disponibilidad para ir a la oficina al menos 2 veces por semana (Las Condes) (excluyente)\\nEn Nuestro Equipo Encontrarás\\n-  Espacios para crear e innovar.\\n-  Serás parte de un lugar lleno de oportunidades de desarrollo.\\n-  Tener un trabajo con sentido y donde se promueve la calidad de vida.\\n-  Participar en voluntariados.\\n-  ¡Pertenecer a una empresa llena de energía!\\nSi disfrutas nuevos desafíos con alta responsabilidad y exposición en el epicentro de la transformación del retail en Latinoamérica, ¡súmate a trabajar con nosotros!\\nSomos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusión en todas sus formas, sin importar religión, raza, género, situación de discapacidad, nacionalidad.\\nRequisitos\\n- Profesional: Ingeniería Civil en Computación, Informática, Sistemas o carrera afín.\\n- Conocimiento en SQL (excluyente)\\n- Sólidos conocimientos en Google Cloud Platform (excluyente)\\n- Conocimiento avanzado en Python (excluyente)\\n- Conocimiento y experiencia trabajando en GIT (excluyente)\\n- Disponibilidad para ir a la oficina al menos 2 veces por semana (Las Condes) (excluyente)\\nCondiciones Oferta\\nDescripción proceso de selección:\\nEl proceso de selección se realiza a través de Aira - plataforma de reclutamiento diseñado para mejorar tu experiencia de postulación.\\nPara Postular Solo Necesitas\\n-  Postular a la oferta\\n-  Revisar tu email\\n-  Ingresar a Aira y contestar las preguntas y/o pruebas solicitadas\\nLuego, si vemos que tu perfil se ajusta a lo que estamos buscando, te contactaremos por email (a través de Aira) para seguir a la etapa presencial.\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Retail'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'NeuralWorks', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205500303/', 'job_description': 'NeuralWorks es una compañía de alto crecimiento fundada hace 3 años. Estamos trabajando a toda máquina en cosas que darán que hablar.\\nSomos un equipo donde se unen la creatividad, curiosidad y la pasión por hacer las cosas bien. Nos arriesgamos a explorar fronteras donde otros no llegan: un modelo predictor basado en monte carlo, una red convolucional para detección de caras, un sensor de posición bluetooth, la recreación de un espacio acústico usando finite impulse response.\\nEstos son solo algunos de los desafíos, donde aprendemos, exploramos y nos complementamos como equipo para lograr cosas impensadas.\\nTrabajamos en proyectos propios y apoyamos a corporaciones en partnerships donde codo a codo combinamos conocimiento con creatividad, donde imaginamos, diseñamos y creamos productos digitales capaces de cautivar y crear impacto.\\n👉 Conoce más sobre nosotros\\n Descripción del trabajo\\nEl equipo de Data y Analytics trabaja en diferentes proyectos que combinan volúmenes de datos enormes e IA, como detectar y predecir fallas antes que ocurran, optimizar pricing, personalizar la experiencia del cliente, optimizar uso de combustible, detectar caras y objetos usando visión por computador.\\nDentro del equipo multidisciplinario con Data Scientist, Translators, DevOps, Data Architect, tu rol será clave en construir y proveer los sistemas e infraestructura que permiten el desarrollo de estos servicios, formando los cimientos sobre los cuales se construyen los modelos que permiten generar impacto, con servicios que deben escalar, con altísima disponibilidad y tolerantes a fallas, en otras palabras, que funcionen. Además, mantendrás tu mirada en los indicadores de capacidad y performance de los sistemas.\\nEn cualquier proyecto que trabajes, esperamos que tengas un gran espíritu de colaboración, pasión por la innovación y el código y una mentalidad de automatización antes que procesos manuales.\\nComo Data Engineer, Tu Trabajo Consistirá En\\n- Participar activamente durante el ciclo de vida del software, desde inception, diseño, deploy, operación y mejora.\\n- Apoyar a los equipos de desarrollo en actividades de diseño y consultoría, desarrollando software, frameworks y capacity planning.\\n- Desarrollar y mantener arquitecturas de datos, pipelines, templates y estándares.\\n- Conectarse a través de API a otros sistemas (Python)\\n- Manejar y monitorear el desempeño de infraestructura y aplicaciones.\\n- Asegurar la escalabilidad y resiliencia.\\n Calificaciones clave\\n- Estudios de Ingeniería Civil en Computación o similar.\\n- Experiencia práctica de al menos 3 años en entornos de trabajo como Data Engineer, Software Engineer entre otros.\\n- Experiencia con Python. Entendimiento de estructuras de datos con habilidades analíticas relacionadas con el trabajo con conjuntos de datos no estructurados, conocimiento avanzado de SQL, incluida optimización de consultas.\\n- Pasión en problemáticas de procesamiento de datos.\\n- Experiencia con servidores cloud (GCP, AWS o Azure), especialmente el conjunto de servicios de procesamiento de datos.\\n- Buen manejo de inglés, sobre todo en lectura donde debes ser capaz de leer un paper, artículos o documentación de forma constante.\\n- Habilidades de comunicación y trabajo colaborativo.\\n¡En NeuralWorks nos importa la diversidad! Creemos firmemente en la creación de un ambiente laboral inclusivo, diverso y equitativo. Reconocemos y celebramos la diversidad en todas sus formas y estamos comprometidos a ofrecer igualdad de oportunidades para todos los candidatos.\\n“Los hombres postulan a un cargo cuando cumplen el 60% de las calificaciones, pero las mujeres sólo si cumplen el 100%.” D. Gaucher , J. Friesen and A. C. Kay, Journal of Personality and Social Psychology, 2011.\\nTe invitamos a postular aunque no cumplas con todos los requisitos.\\n Nice to have\\n- Agilidad para visualizar posibles mejoras, problemas y soluciones en Arquitecturas.\\n- Experiencia en Infrastructure as code, observabilidad y monitoreo.\\n- Experiencia en la construcción y optimización de data pipelines, colas de mensajes y arquitecturas big data altamente escalables.\\n- Experiencia en procesamiento distribuido utilizando servicios cloud.\\n Beneficios\\n- MacBook Air M2 o similar (con opción de compra hiper conveniente)\\n- Bono por desempeño\\n- Bono de almuerzo mensual y almuerzo de equipo los viernes\\n- Seguro complementario de salud y dental\\n- Horario flexible\\n- Flexibilidad entre oficina y home office\\n- Medio día libre el día de tu cumpleaños\\n- Financiamiento de certificaciones\\n- Inscripción en Coursera con plan de entrenamiento a medida\\n- Estacionamiento de bicicletas\\n- Vestimenta informal\\n- Programa de referidos\\n- Salida de “teambuilding” mensual        \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos', 'company': 'Devaid', 'location': 'Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205299283/', 'job_description': 'En Devaid> nos apasionan los desafíos tecnológicos y nuestros clientes lo saben. Por lo anterior, nos plantean problemáticas que nos obligan a estar constantemente probando e implementando nuevas tecnologías.\\nTrabajamos fuertemente en la nube ya que somos Partner Premier de Google Cloud en Chile, por lo que tendrás la oportunidad de formarte como un profesional cloud.\\nDependiendo de las necesidades del cliente, ofrece soluciones web, móviles, integración de sistemas, entre otros. Esto permite acceder a la herramienta sin importar el dispositivo ni el lugar dónde se encuentra. Permitimos el trabajo colaborativo entre múltiples usuarios manteniendo una base centralizada de información.\\n Funciones del cargo\\nEsperamos Que Puedas Desempeñarte En Las Siguientes Actividades\\n- Creación de pipelines de carga y transformación de datos.\\n- Modelamiento de datos y creación de Data Warehouse y Data Lakes.\\n- Integración de sistemas.\\n- Creación de modelos de machine learning con herramientas low code autoML.\\nVas a participar como ingeniero de datos en equipos de consultores que prestan servicios a empresas importantes en Chile. En estos equipos participan distintos perfiles, tales como desarrolladores de software, arquitectos de datos y data scientists. Los servicios se prestan de forma remota y son prestados por proyecto (no es outsourcing de recursos), por lo que puedes trabajar desde tu casa sin problemas. Diariamente vas a tener reuniones con tu equipo para coordinar actividades y resolver temas complejos que vayan surgiendo.\\n Requerimientos del cargo\\nLos requisitos para un buen desempeño de las funciones son:\\n- 1 año de experiencia como Data Engineer. \\n- Programación en lenguaje Python, NodeJS o Java (al menos uno de los 3). \\n- Conocimiento de soluciones de Data Warehouse y ETL. \\n- Conocimiento de plataformas de procesamiento de datos como Apache Spark, Dataflow o similares. \\n- Haber trabajado previamente con alguna nube pública (AWS, Azure o GCP).\\nSi no cumples alguno de estos puntos no te desanimes, queremos conocerte igualmente.\\nEl trabajo es 100% remoto, pero es necesario que tengas RUT y/o papeles al día en Chile.\\n Deseables\\nSuman puntos en tu postulación si cumples alguna de las siguientes habilidades, ninguno de estos son excluyentes:\\n- Conocimiento de herramientas Google Cloud, entre ellas Google BigQuery, Dataflow, Data Fusion y Pub Sub. \\n- Experiencia en plataformas de deployment de infraestructura como Terraform. \\n- Experiencia utilizando la herramienta de consola gcloud. \\n Beneficios\\nPrometemos un ambiente muy grato de trabajo, lleno de desafíos y donde podrás ver los proyectos en los que estas involucrada/o siendo utilizados en un corto tiempo activamente por nuestros clientes, lo que siempre es muy gratificante.\\nOtras Actividades\\n- Actividades mensuales (Cupones de Food delivery, juegos en línea, actividades grupales).\\n- Actividad paseo anual: La empresa se junta por 2 días en algún lugar turístico para realizar actividades grupales y unir al equipo.\\n- Día libre flexible en tu cumpleaños.\\n- Capacitaciones en lo que más te guste.\\n- Certificaciones Google Cloud: Programa de certificación en distintas ramas profesionales de GCP, gracias a que somos Partner Premier de Google Cloud en Chile.        \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer (GCP & DataFlow & Bigquery)', 'company': 'Option', 'location': 'Santiago Metropolitan Area', 'date': '2025-04-12', 'job_url': 'https://www.linkedin.com/jobs/view/4208792219/', 'job_description': '¿Quiénes somos?\\nEn \\nOption\\n, creemos en un mundo donde las soluciones tecnológicas no tienen límites. Nuestra misión es transformar los desafíos en oportunidades mediante la creación de soluciones innovadoras que potencien la Aceleración Digital. Nuestro equipo es dinámico, colaborativo y apasionado por la tecnología. Únete a una organización que está redefiniendo cómo el mundo utiliza los datos y la tecnología para resolver problemas complejos.\\n¿Qué buscamos?\\nEstamos en la búsqueda de un/a \\nIngeniero/a de Datos\\n para unirse al equipo de Data Services. Este rol será clave en el levantamiento, análisis y migración de procesos ETL desde un Data Lake mal gobernado hacia una arquitectura moderna sobre Google Cloud Platform (GCP). ¡Te estamos buscando!\\n¿Qué te ofrece este puesto?\\n- Participación en un proceso estratégico de migración a la nube.\\n- Un entorno de trabajo colaborativo y con líderes técnicos accesibles.\\n- Uso de tecnologías modernas como GCP, Dataflow y BigQuery.\\n- Trabajo conjunto con equipos de analítica, desarrollo y operación.\\n¿Cuáles serán tus principales responsabilidades?\\n- Levantar y documentar los ETLs actuales en Data Services.\\n- Analizar el ambiente de datos y planificar su migración a GCP.\\n- Tomar iniciativa en la migración de ETLs críticos.\\n- Resolver incidencias relacionadas a ETLs mediante la mesa de ayuda.\\n- Participar en el diseño del plan de migración.\\n- Colaborar con los líderes técnicos y equipos multidisciplinarios.\\n¿Qué necesitas para ser nuestro próximo Ingeniero de Datos?\\nHabilidades Técnicas Excluyentes\\n- Oracle\\n- Python\\n- Dataflow (GCP)\\n- Dataform (GCP)\\n- GitLab\\n- BigQuery (GCP)\\n- Data Modeling\\n- Composer (GCP)\\nHabilidades Técnicas Deseables\\n- Oracle Data Integrator (ODI)\\nUbicación: LATAM\\nModalidad de trabajo:\\n 100% Remoto\\n¡Únete a nuestro equipo y transforma el futuro con nosotros!\\nhttps://www.option.tech        \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'ICONSTRUYE', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205295718/', 'job_description': 'En ICONSTRUYE, hemos estado a la vanguardia de la tecnología en la construcción durante más de 20 años. Nuestra robusta plataforma tecnológica es un testimonio de nuestra experiencia y compromiso con la industria. Con más de 4,000 clientes en Chile, Colombia y Perú, nos enorgullecemos de proporcionar soluciones integrales que simplifican la cadena de abastecimiento. Buscamos un Ingeniero de Datos que se una a nosotros en la transformación de la industria de la construcción, siendo el puente entre los datos brutos y aquellos que toman decisiones críticas.\\nTus Funciones Principales\\nTu misión:\\n Ser el puente entre los datos brutos y quienes necesitan realizar análisis y/o tomar decisiones con esos datos.\\n- Garantizar la calidad, integridad y seguridad de los datos.\\n- Colaborar con diversos stakeholders para comprender sus necesidades de datos.\\n- Desarrollar procesos de extracción, transformación y carga (ETL) de datos para nuestro data lake, proporcionando información valiosa para el análisis y toma de decisiones.\\n- Implementar nuevas bases de datos y/o data warehouses para satisfacer las necesidades de la empresa.\\n- Contribuir a la definición de políticas de gobernanza de datos.\\n- Ser una autoridad en la creación, implementación y operación de soluciones escalables y de bajo costo, facilitando el flujo de datos desde sistemas de producción hasta el data lake.\\nRequerimientos Técnicos\\n- Dominio de Python o Go. \\n- Dominio de SQL. \\n- Conocimiento de base de datos relacionales y no relacionales (NoSQL). \\n- Conocimiento de AirFlow, Luigi, Dagster. \\n- Conocimientos de Kafka y/o RabbitMQ. \\n- Conocimiento en Docker y Kubernetes. \\nBeneficios Que Ofrecemos\\n- 🌴 5 días extras de descanso al año.\\n- 🍔 Tarjeta amipass para utilizar en restaurantes, delivery y supermercados.\\n- 👨\\u200d⚕️ Seguro complementario de salud, dental y de vida.\\n- 🏠 Modalidad de trabajo híbrido.\\n- 📠 Flexibilidad con permisos para trámites y asuntos familiares.\\n- 👩\\u200d👦 Jornada reducida en días de vacaciones escolares (viernes medio día).\\n- 🎂 Tarde libre en tu cumpleaños.\\n¡Únete a nosotros y sé parte de nuestra misión de transformar la industria de la construcción!\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos ($1.400.000 líquidos)', 'company': 'Vector', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4203857279/', 'job_description': 'Somos una empresa Líder en el rubro TI. Nos encontramos en la búsqueda de Ingeniero de Datos, con experiencia en extracción de datos desde los sistemas fuente de estándares industriales y eléctricos y su almacenaje en los destinos correspondientes, así como también el asegurar la continuidad del funcionamiento de aplicaciones y redes OT que proporcionan datos a PMAC y ROCC.\\nPrincipales Tareas\\n- Sistematizar el traspaso de datos desde los distintos sistemas de la compañía hacia los repositorios correspondientes para su consumo.\\n- Participar en proyectos y entregar soluciones técnicas, procesos y requisitos.\\n- Enfoque en la creación de indicadores y KPI relevantes de las diferentes aplicaciones para reportar a nivel técnico y administrativo.\\n- Realizar revisiones continuas de monitoreo para asegurarse de la continuidad del servicio.\\n- Monitorear y controlar solicitudes y requerimientos de soporte (gestión de tickets).\\n- Gestionar cualquier proceso de solicitud de cambio, asegurándose de que todas las solicitudes estén debidamente documentadas y rastreadas. \\n- Entregar soporte para que los servicios de OT se entreguen de acuerdo con los procedimientos operativos estándar y/o SLAs acordados; con enfoque en el servicio operativo, resolución de problemas y respuesta ágil para el usuario final.\\n- Escalar consultas complejas a la organización de soporte especializado correspondiente.\\n- Identificar oportunidades de mejora del servicio a partir del análisis de tendencias de datos y las necesidades y aportes de los clientes/usuarios.\\n- Involucrarse con stakeholders clave y para comprender sus requisitos y transmitir al área de resolución correspondiente. \\nConocimientos y experiencia \\n- Estudios técnicos o profesionales en Telecomunicaciones, Instrumentación, Sistemas, Computación, Informática, Electrónica o carreras afines).\\n- Instrumentista con conocimiento en programación y transferencia de datos, o Ingeniero de Datos con conocimiento en protocolos industriales y sus estándares de comunicación.\\n- Conocimientos de redes de comunicaciones y soluciones de transporte de datos.\\n- Gestión de datos y visualización usando herramientas cloud (Google, Microsoft).\\n- Conocimientos de un lenguaje de scripting, preferiblemente Python.\\n- Manejo básico de base de datos SQL.\\n- Conocimientos básicos en gestión de accesos e identidades.\\n- Conocimientos básicos en administración de servidores.\\n- Experiencia laboral de 5 años preferiblemente en empresas industriales.\\n- Deseable manejo de ingles a nivel técnico intermedio.\\nConocimientos específicos\\n- Conocimiento de protocolos industriales del sector eléctrico (IEC-60870-5-104, Modbus, DNP 3.0).\\n- Protocolos Industriales de comunicación: Modbus TCP/IP, JSON, CSV, DNP3, SQL.\\n- Conocimiento de sistemas SCADA.\\n- Conocimientos de protocolos de transición con industria 4.0 (Modbus TCP, OPC UA, MQTT, HTTP, etc.).\\nFundamentos de ciberseguridad.\\nHorario\\nLunes a viernes 08:00 a 18:00 / 08:30 a 18:30\\nBeneficios\\n-  Reajuste anual de sueldo de acuerdo a IPC\\n-  Bonificación anual por desempeño laboral.\\n-  Posibilidad de acceder a cursos de capacitación en las diversas temáticas del cargo.\\n-  Convenios de Salud, Dentales y ópticos, accesos a descuentos preferenciales y facilidades de pagos mediante descuentos por planilla sin interés.\\n-  Posibilidad de entrega de aguinaldo de fiestas patrias y Navidad conforme a cumplimiento de antigüedad.\\n-  Convenio seguro Oncológico a valor preferencial y con aporte de la organización y del colaborador.\\n-  Regalo de gift card por nacimiento de hijo (a).\\n-  Convenios bancarios (scotiabank y Banco de Chile) para planes de tarjetas de cuentas vista y corriente a valores preferenciales.        \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Contract', 'Job function': 'Information Technology', 'Industries': 'Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer Soluciones de Datos', 'company': 'LISIT', 'location': 'Biobío Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294845/', 'job_description': 'En *Lisit*, nos dedicamos a crear, desarrollar e implementar servicios de software que ofrecen herramientas de automatización y optimización. Nuestra misión es promover la eficacia en la operatividad de nuestros clientes a través de un soporte consultivo que integra diversas herramientas y prácticas. Buscamos contribuir al éxito de las transformaciones empresariales mediante estrategias integrales de acompañamiento e implementación.\\n Que estamos buscando\\n- Diseñar, desarrollar y mantener infraestructuras y pipelines de datos escalables y confiables.\\n- Optimizar el almacenamiento, procesamiento y recuperación de datos para un funcionamiento eficiente e impecable.\\n- Colaborar con equipos de diferentes departamentos para recopilar y analizar los requisitos de datos.\\n- Garantizar la calidad, integridad y seguridad de los datos durante todo el ciclo de vida de estos.\\n- Mantenerse actualizado sobre los últimos avances, desarrollos y enfoques en ingeniería de datos.\\n ¿Qué habilidades y experiencia necesitas?\\n- Fuertes habilidades analíticas y de resolución de problemas.\\n- Al menos 3 años de experiencia en ingeniería de datos.\\n- Experiencia comprobada en el diseño y desarrollo de data pipelines y procesos ETL, preferiblemente con Azure Data Factory.\\n- Amplia experiencia en SQL y dominio de al menos un lenguaje de ingeniería de datos, como Python o Scala.\\n- Experiencia con Spark, Airflow y tecnologías Big Data relacionadas.\\n- Familiaridad con plataformas de datos basadas en la nube como AWS, Azure o GCP.\\n- Excelentes habilidades de comunicación y colaboración.\\n Deseable\\nSe valorará la experiencia con herramientas de BI como Power BI y Microsoft Fabric. También es deseable contar con alguna de las siguientes certificaciones: DP-203, PL-300, DP-600 y/o DP-700.\\n Únete a nosotros\\nEn *Lisit* ofrecemos un ambiente de trabajo innovador y colaborativo. Nos aseguramos de que nuestros empleados disfruten de un equilibrio entre trabajo y vida personal, con programas de capacitación y desarrollo continuo. Valoramos tu entusiasmo y pasión por la ingeniería de datos.\\nEstamos emocionados por conocer a personas con una mentalidad abierta y dispuestas a enfrentar nuevos desafíos. ¡Si estás listo para innovar y crecer con nosotros, te queremos en nuestro equipo!\\nEn el caso de residir en Santiago, debe tener disponibilidad para viajar una o dos semanas a Los Angeles, región del BioBío\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'Seeds', 'location': 'Santiago Metropolitan Region, Chile', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4189755534/', 'job_description': '¿Sos \\nData Engineer\\n? Entonces… ¿Qué estás esperando para sumarte a nuestra comunidad de Seeders? ¡Aplica a nuestra comunidad y accede a trabajo on-demand en las empresas líderes, sumate al Present of Work!\\n¿Quiénes somos?\\nSomos una \\ncomunidad\\n que reúne al mejor talento on-demand de Latinoamérica, y lo conecta con las empresas líderes de la región. Gestionamos el match perfecto entre las necesidades de las empresas y el talento con las competencias y la experiencia buscada, fomentando flexibilidad y el desarrollo profesional de nuestra comunidad.\\nNo somos una plataforma más de freelancers, Seeds lidera un dream team de profesionales altamente calificados que eligen dónde, cómo y para quién trabajar, disfrutando así de contribuir a una misión más grande, definiendo y moldeando la forma en que trabajamos.\\nEstamos buscando sumar a nuestro Talent Pool roles de \\nData Engineer\\n para nuestra comunidad de Seeders.\\nEstas son algunas de las responsabilidades usuales del rol:\\n- Diseñar, construir y mantener arquitecturas de datos robustas y escalables.\\n- Desarrollar y optimizar pipelines de datos para recopilación, almacenamiento, procesamiento y análisis de grandes volúmenes de datos.\\n- Implementar modelos de datos y algoritmos para resolver problemas de negocio y proveer insights accionables.\\n- Trabajar en estrecha colaboración con equipos de data scientists y analistas para apoyar sus requisitos de datos y facilitar el análisis de datos.\\n- Asegurar la integridad, disponibilidad y confidencialidad de los datos a través de las mejores prácticas de seguridad y gobernanza de datos.\\n- Mantenerse al día con las últimas tecnologías y tendencias en el campo de la ingeniería de datos.\\nRequisitos\\n- Experiencia mínima de 3 años en roles de ingeniería de datos.\\n- Fuerte dominio de lenguajes de programación como Python, Java o Scala.\\n- Experiencia trabajando con grandes volúmenes de datos y herramientas de procesamiento de datos (como Hadoop, Spark).\\n- Conocimientos en bases de datos SQL y NoSQL, así como en soluciones de almacenamiento de datos en la nube (AWS, Google Cloud, Azure).\\n- Capacidad para trabajar en entornos ágiles y multidisciplinarios.\\n- Inglés intermedio (deseable).\\n¿Por qué sumarte a nuestra comunidad de Seeders?\\nElegí tus proyectos.\\nTrabajá desde donde vos quieras.\\nEventos de networking.\\nAsesoramiento personalizado.\\nSeeds Academy: Potencia tu desarrollo profesional adquiriendo nuevas skills (upskilling & reskilling), participando de webinars, Bootcamps y otras acciones exclusivas para la comunidad.\\nNo dejes de sumarte a nuestra comunidad de Seeds y aplicar a oportunidades de empresas lideres de la región. ¡Te esperamos!        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Consulting', 'Industries': 'Technology, Information and Media'}\n",
      "------------------------------\n",
      "{'title': 'Senior Data Engineer Python', 'company': '23people', 'location': 'Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294906/', 'job_description': 'Únete a Equifax Chile como Senior Data Engineer Python Somos líderes en soluciones de información y tecnología, operando globalmente para transformar el uso de la información con transparencia y seguridad. Estamos en un proyecto de migración clave que requiere revisión de pipelines de datos, creación de queries, diseño de flujos de procesos, análisis de sistemas legados y documentación técnica y de negocio. Valoramos la innovación, la colaboración y el conocimiento técnico. Si tienes habilidades analíticas excepcionales y pasión por la tecnología, ¡aplica hoy y sé parte de nuestra transformación digital!\\n Funciones del cargo\\n¿Qué harás en tu día a día?\\nEl profesional colaborará con un equipo multidisciplinario en un proyecto de expansión internacional, enfocado en la migración estratégica de la plataforma hacia nuevos mercados. Su participación será fundamental para asegurar una implementación eficiente que considere las particularidades de cada país destino, garantizando así el éxito de esta iniciativa global.\\nAlgunas De Sus Tareas Diarias Son Las Siguientes\\n- Implementar mecanismos para verificar la integridad de los datos migrados\\n- Implementar transformaciones específicas para requisitos regionales\\n- Dirigir el equipo técnico durante las fases críticas de migración\\n- Gestionar el proceso integral de ETL entre diversos sistemas, desarrollando y optimizando los esquemas de mapeo necesarios para garantizar la compatibilidad entre las estructuras de datos de origen y destino.\\n Requerimientos del cargo\\nSkills\\nTécnicas\\n- Python\\n- BigQuery/SQL\\n- GitHub\\n- Apache Beam/Spark/Google Dataflow\\nPersonales\\n- Capacidad de autogestión\\n- Buenos skills de comunicación\\n- Fortaleza en trabajo en equipo\\n- Adaptación al cambio (trabajarán en distintas geos de Latam)\\nContrato indefinido desde el inicio con 23people\\nModalidad: Home Office, Con residencia en Chile (Deberás ir a buscar el PC en primera instancia)\\nExperiencia: Desde 5 años en adelante\\nHorario: Lunes a Jueves de 8:30 a 6:30 y Viernes de 8:30 a 5:30 hrs.\\n Deseables\\n- Perfil Analítico\\n- UnitTest\\n- AirFlow\\n- PySpark\\n- CI/CD\\n- Postman\\n- Jmeter\\n Beneficios\\nAlgunos de nuestros beneficios\\n- Seguro complementario: Seguro de salud, vida y dental\\n- Curso de inglés: En nuestro programa de formación en idioma inglés, ofrecemos dos modalidades para adaptarnos a tus necesidades y objetivos.\\n- Reembolso de certificaciones internacionales: Apoyamos el crecimiento profesional, por lo que te reembolsamos el costo de un examen de certificación internacional que quieras realizar.\\n- Bono de vacaciones: Por cada semana que te tomes de vacaciones te otorgamos una compensación.\\n- Aguinaldos en fiestas patrias y Navidad: Queremos que en fechas tan especiales la pases bien junto a tu familia, por lo que te entregamos un bono en septiembre y diciembre\\n- Día libre de cumpleaños: Puedes optar por tomar tu día libre, el día previo a tu cumpleaños, el mismo día de tu cumpleaños o el día posterior.        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Analista de datos', 'company': 'Ripley Chile', 'location': 'Las Condes, Santiago Metropolitan Region, Chile', 'date': '2025-04-08', 'job_url': 'https://www.linkedin.com/jobs/view/4204266753/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Graduate 2025 Software Engineer I Backend, Chile', 'company': 'Uber', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205853556/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos/ Dbt', 'company': 'BC Tecnología', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205500332/', 'job_description': 'En BC Tecnología, somos una consultora de TI con más de seis años de experiencia, especializada en ofrecer soluciones personalizadas para nuestros clientes en sectores como servicios financieros, seguros, retail y gobierno. Nos enfocamos en consultoría, outsourcing, desarrollo de proyectos y formación de equipos, siempre con un claro compromiso hacia la satisfacción del cliente. Como parte de nuestro equipo, el ingeniero/a de datos jugará un papel clave en la creación de soluciones basadas en tecnologías de la nube, impulsando la innovación y la colaboración en un entorno de trabajo ágil.\\n Responsabilidades Clave\\nEl Ingeniero/a De Datos Será Responsable De\\n- Diseñar y mantener pipelines de datos utilizando BigQuery y DBT.\\n- Implementar tareas programadas en Google Cloud Platform (GCP) para la ingesta y procesamiento continuo de datos.\\n- Construir y documentar modelos de datos optimizados para su análisis.\\n- Validar y realizar pruebas para garantizar la precisión de los datos transformados.\\n- Realizar seguimiento y documentación de cambios en modelos y sus transformaciones.\\n Requisitos Técnicos\\nBuscamos Un Ingeniero/a De Datos Con\\n- Experiencia avanzada en BigQuery y DBT.\\n- Conocimiento práctico en Google Cloud Platform, incluyendo la programación de tareas y almacenamiento.\\n- Sólido manejo de SQL y experiencia en modelado de datos.\\n- Capacidad para documentar procesos y realizar pruebas de calidad de datos de manera eficiente.\\n Lo que ofrecemos\\nBrindamos un contrato por proyecto de 12 meses en modalidad híbrida, lo que permite combinar trabajo remoto con visitas a la oficina 2 a 3 días a la semana. También garantizamos un enfoque en la inclusión, en cumplimiento con la Ley Nº 21.015, promoviendo un entorno donde todos los empleados puedan prosperar.\\n Beneficios        \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst', 'company': 'Macal Remates', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205298423/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos Maestros (Proyecto Corporativo)', 'company': 'Agrosuper', 'location': \"Rancagua, O'Higgins Region, Chile\", 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297494/', 'job_description': 'En Agrosuper, tenemos la misión de llevar alimentos de la más alta calidad a las familias de Chile y el mundo. Nos mueve el deseo de alimentar el talento y las ganas de crecer constantemente. Buscamos mejorar y fomentar un entorno donde todos disfruten lo bueno de la vida, por lo que valoramos a las personas, que son el alma de nuestra organización. Este cargo de Ingeniero de Datos Maestros (Corporativo) es fundamental para garantizar la calidad y disponibilidad de nuestros Datos Maestros a través de la optimización de procesos y recursos en nuestras unidades de negocio.\\n Principales Funciones\\n- Gestionar los Datos Maestros en diversos Proyectos Corporativos.\\n- Identificar y proponer mejoras, optimizando y eficientando nuestros procesos internos.\\n- Gestionar la creación de códigos de distintos Datos Maestros considerados críticos por la Organización.\\n- Definir y configurar en SAP Estrategias de Liberación (Compras).\\n- Validar y autorizar Órdenes de Transportes Customizing en SAP.\\n- Validar estándares de los Datos Maestros en SAP.\\n- Evaluar y desarrollar parametrizaciones técnicas de Customizing alrededor de los Datos Maestros en SAP.\\n- Asesorar al Equipo de Datos Maestros sobre dudas y buenas prácticas en el Gobierno de Datos Maestros.\\n Requisitos\\n- Título profesional en áreas como Ingeniería Civil Industrial, Comercial, Informática o similar.\\n- Experiencia laboral mínima de 2 años en roles similares.\\n- Experiencia en SAP, específicamente en Gobierno de Datos Maestros (certificado).\\n- Conocimientos en herramientas de análisis y visualización, especialmente en Excel a nivel avanzado.\\nDesirable Skills\\nSi bien los requisitos mencionados son fundamentales, también valoramos habilidades adicionales que pueden enriquecer la experiencia en este rol. Esto incluye certificaciones adicionales en SAP, experiencia en gestión de proyectos y habilidades en liderazgo y trabajo en equipo. Además, el deseo de mantenerse al día con las tendencias en tecnología y análisis de datos será considerado un gran plus.\\n Beneficios\\nAgrosuper ofrece un entorno de trabajo inspirador donde se valora el crecimiento tanto profesional como personal. Contamos con planes de crecimiento y desarrollo, capacitación continua y becas de estudios, además de convenios con distintas instituciones. También ofrecemos bonos asociados al desempeño para incentivar el trabajo de nuestros colaboradores. Además, promovemos la inclusión de colaboradores con discapacidad, asegurando que todos tengan la oportunidad de contribuir a nuestro propósito de alimentar lo bueno de la vida.\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos', 'company': 'AyCA SpA', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4206696535/', 'job_description': 'Company Description: AyCA Spa\\nJob Description: En AyCA SPA nos encontramos en búsqueda de un Ingeniero de Datos.\\nPropósito o Misión del Cargo\\nEl Ingeniero de Datos en Mantenimiento de Planta es responsable de diseñar, implementar y gestionar la infraestructura de datos y los sistemas de análisis necesarios para optimizar las estrategias y procesos de mantenimiento. Su rol principal es transformar los datos generados por los equipos, sistemas de monitoreo y actividades de mantenimiento en información valiosa y accionable que permita mejorar la confiabilidad de los activos, reducir costos, predecir fallas y optimizar la planificación de las intervenciones.\\nPrincipales Responsabilidades\\n-  Diseño e Implementación de la Arquitectura de Datos\\n-  Colaborar con el equipo de mantenimiento y TI para comprender las necesidades de datos y diseñar una arquitectura robusta y escalable para la recopilación, almacenamiento, procesamiento y análisis de datos de mantenimiento.\\n-  Seleccionar e implementar las herramientas y tecnologías adecuadas para la gestión de datos (bases de datos, data lakes, plataformas de procesamiento en la nube, etc.).\\n-  Establecer y mantener los procesos de extracción, transformación y carga (ETL/ELT) de datos desde diversas fuentes (CMMS, sensores IoT, registros manuales, etc.).\\n-  Integración de sistemas SCADA y PLCs con tecnologías cloud (OPC UA, MQTT, REST APIs)\\n-  Garantizar la calidad, integridad y seguridad de los datos de mantenimiento.\\n-  Desarrollo de Soluciones de Análisis y Reporte\\n-  Desarrollar modelos de datos y esquemas que faciliten el análisis y la generación de insights relevantes para el mantenimiento.\\n-  Crear dashboards, informes y visualizaciones interactivas que permitan al equipo de mantenimiento monitorear KPIs, identificar tendencias, evaluar la efectividad de las estrategias y tomar decisiones informadas.\\n-  Implementar técnicas de análisis predictivo (machine learning, inteligencia artificial) para predecir fallas de equipos, optimizar la planificación de mantenimiento preventivo y proactivo.\\n-  Automatizar la generación de informes y alertas para facilitar la toma de decisiones en tiempo real.\\n-  Diseñar e implementar flujos de procesamiento de datos industriales.\\n-  Construir y entrenar modelos de ML para detección de fallas y patrones de operación.\\n-  Diseñar estrategias para la optimización y escalabilidad del sistema de IA.\\n-  Integrar modelos de IA con bases de datos y sistemas de control industriales.\\n-  Asegurar la seguridad y confiabilidad del sistema en entornos industriales.\\n-  Soporte y Optimización de Sistemas de Datos\\n-  Monitorear y mantener el rendimiento y la disponibilidad de la infraestructura de datos de mantenimiento.\\n-  Identificar y resolver problemas relacionados con la calidad, integridad y flujo de datos.\\n-  Optimizar los procesos de ETL/ELT y las consultas de datos para mejorar la eficiencia del análisis.\\n-  Mantener la documentación técnica de la arquitectura de datos, los procesos y las soluciones implementadas.\\n-  Colaboración y Comunicación\\n-  Trabajar en estrecha colaboración con el equipo de mantenimiento (planificadores, supervisores, técnicos), el departamento de TI y otros stakeholders para comprender sus necesidades de datos y ofrecer soluciones efectivas.\\n-  Comunicar de manera clara y concisa los hallazgos del análisis de datos y las recomendaciones al equipo de mantenimiento y la gerencia.\\n-  Participar en reuniones y proyectos relacionados con la mejora continua y la transformación digital del área de mantenimiento.\\n-  Capacitar al personal de mantenimiento en el uso de las herramientas y los informes de análisis de datos.\\n-  Documentar procesos y modelos.\\n-  Investigación y Desarrollo\\n-  Mantenerse actualizado sobre las últimas tendencias y tecnologías en el campo del análisis de datos, la inteligencia artificial y el mantenimiento predictivo.\\n-  Investigar y proponer nuevas herramientas y técnicas que puedan mejorar la eficiencia y efectividad del mantenimiento basado en datos.\\n-  Participar en proyectos piloto para la implementación de nuevas soluciones de análisis.\\nRequisitos\\n-  Título profesional en Ingeniería (Informática, Industrial, Mecánica, Eléctrica o carreras afines) con especialización o experiencia en análisis de datos, ciencia de datos o gestión de información.\\nExperiencia\\n-  Plataformas de nube pública: AWS (IoT Core, Lambda, S3), Azure (IoT Hub, Functions) o Google Cloud (Pub/Sub, Firestore).\\n-  Diseño o implementación de dashboards para visualización de datos industriales (Power BI, Grafana, etc.).\\n-  Haber desarrollado proyectos similares, ya sea como profesional o estudiante (tesis).\\n-  Experiencia en el desarrollo de modelos de Machine Learning.\\n-  Experiencia práctica con Python, pandas, scikit-learn, TensorFlow, XGBoost o similares.\\n-  Experiencia en arquitectura de datos: bases SQL, ETL, APIs.\\n-  Conocimientos en integración de sistemas industriales mediante APIs REST, OPC-UA o MQTT.\\n-  Capacidad para diseñar arquitecturas escalables y eficientes.\\n-  Conocimiento en ciberseguridad industrial.\\n-  Familiaridad con software industriales.\\n-  Experiencia en desarrollo de aplicaciones para entornos industriales.\\nSi crees que cumples con las competencias envíanos tu CV indicando pretensiones de renta y disponibilidad.\\nAyúdanos a compartir para llegar a mas personas !!\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Mining'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer AWS – Contrato Indefinido.', 'company': 'BC Tecnología', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4204878459/', 'job_description': 'Company Description: BC Tecnología\\nJob Description: Experiencia de 3 años en:\\n-  Explotación de datos (Tunnig)\\n-  ETL\\n-  SQL\\n-  Python\\n-  Apache Airflow (Deseable)\\n-  AWS (Glue, Lambda, S3, Redshift, Dynamodb\\n-  Trabajo Hibrido\\nInteresados o referidos favor enviar cv actualizado a [email] indicando en asunto de e-mail cargo al cual postula (Data Engineer AWS)\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer – Proyecto de 6 Meses', 'company': 'BC Tecnología', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297473/', 'job_description': 'En BC Tecnología, somos una consultora de TI comprometida con ofrecer soluciones innovadoras y adaptadas a las necesidades de nuestros clientes. Con más de 6 años de experiencia en el sector, trabajamos con empresas en diferentes industrias, incluyendo servicios financieros, seguros, retail y gobierno. En este proyecto de Data Engineering, tendrás la oportunidad de contribuir al diseño y construcción de pipelines de datos para nuestros clientes, utilizando metodologías ágiles y colaborando con equipos altamente especializados.\\n Responsabilidades del Rol\\n- Diseñar y construir pipelines de datos efectivos para cumplimentar las necesidades analíticas de nuestros clientes.\\n- Programar usando lenguajes como Python, Scala o SQL para manipulación y transformación de datos.\\n- Implementar y gestionar herramientas de orquestación de pipelines, como Airflow, Mage, NiFi o similares.\\n- Colaborar en prácticas de CI/CD, incluidos conocimientos básicos en Git y versionado de código.\\n- Integrar arquitecturas de datos, con un enfoque en Datalakes, Datawarehouses o Lakehouse.\\n- Participar en modelado de datos utilizando técnicas dimensional, estrella y copo de nieve, si es requerido.\\n Requisitos y Habilidades\\nBuscamos candidatos que cuenten con al menos 2 años de experiencia en el área de Data Engineering. Deberán tener competencias en diseño y construcción de pipelines de datos, así como experiencia con lenguajes de programación pertinentes como Python, Scala o SQL.\\nEs esencial dominar herramientas de orquestación de datos, y tener un conocimiento básico sobre integraciones de CI/CD y flujos de trabajo de versionamiento de código. Adicionalmente, es deseable contar con experiencia en arquitecturas de datos y modelado, incluidos Datalakes y técnicas de modelado específicas.\\nLa modalidad de trabajo es híbrida, lo que permitirá equilibrar la colaboración en persona con flexibilidad laboral.\\n Habilidades Deseables\\nSi bien no es un requisito, consideraremos positivamente la experiencia previa con Datalakes y Datawarehouses, así como familiaridad con técnicas de modelado como dimensional, estrella o copo de nieve. Esto contribuirá a un mejor entendimiento del contexto de las soluciones que desarrollaremos.\\n Beneficios y Condiciones\\nOfrecemos Un Contrato Por Proyecto De 6 Meses, Con Posibilidad De Extensión. Los Empleados Disfrutarán De Un Sueldo a Convenir, Además De Beneficios Adicionales Como\\n- Seguro complementario.\\n- Amipass de $4,500 por día laborado.\\n- Convenciones, actividades y bonos.\\nEstamos ubicados en Alto Las Condes, permitiendo un ambiente de trabajo funcional y moderno. ¡Nos encantaría contar contigo en nuestro equipo! 🌟\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer', 'company': 'NeuralWorks', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205295705/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Analista de Datos en GCP', 'company': 'BC Tecnología', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294840/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Analista de Datos', 'company': 'MindCo', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205553758/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Analista de Datos', 'company': 'Outlier', 'location': 'Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207881229/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Senior Data Engineer', 'company': 'Grupo Falabella', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4205321119/', 'job_description': 'Somos más de 90 mil personas que, día a día, dedicamos nuestra pasión y energía a cumplir nuestro Propósito de “Simplificar y Disfrutar Más la Vida”. Propósito que hoy vive a través de nuestro ecosistema físico y digital en todas nuestras empresas (Falabella Retail, Sodimac, IKEA, Tottus, Mallplaza, Falabella Inmobiliario, Falabella.com, Linio, Falabella Financiero, Banco Falabella, Falabella Soriana, Seguros Falabella, Fazil, Fpay y Falabella Corporativo) y países (Argentina, Brasil, Chile, China, Colombia, India, México, Perú y Uruguay).\\nSi disfrutas nuevos desafíos con alta responsabilidad y exposición en el epicentro de la transformación en Latinoamérica, esta oportunidad es para ti. Buscamos un Senior Data Engineer👨\\u200d💻 para sumarse a uno de nuestros equipo, quien sera el encargado de diseñar, construir y mantener sistemas de datos escalables, para el análisis y la toma de decisiones en la organización.\\nFunciones Del Cargo\\nDiseñar y desarrollar canalizaciones de datos (ETL/ELT) robustas y eficientes. \\nColaborar con equipos de ingeniería de datos.\\nImplementar y gestionar bases de datos y data warehouses. \\nOptimizar el rendimiento de las bases de datos y sistemas de almacenamiento de datos. \\nGarantizar la calidad, integridad y seguridad de los datos. \\nAutomatizar procesos de ingestión y transformación de datos.\\nMonitorizar y solucionar problemas relacionados con los sistemas de datos. \\nDocumentar procesos, arquitecturas y mejores prácticas relacionadas con el manejo de datos.\\nRequisitos\\nProfesional titulado en Ingeniería Civil Computación, Industrial, matemático u eléctrico.\\nExperiencia demostrable como Data Engineer\\nExperiencia en lenguajes de programación Python.\\nExperiencia con Google Cloud Platform (Composer, Cloud Functions, Bigquery, Dataproc, etc)\\nExperiencia utilizando git.\\nConocimientos profundos en SQL y en bases de datos relacionales y no relacionales\\nDeseable: Certificación Associate Engineer\\nDeseable: Nivel de Inglés intermedio (B1+)\\nDeseable: Certificaciones relevantes en tecnologías de datos y cloud.\\nSi te apasionan los desafios numerico 🚀👨\\u200d💻y buscas ser parte de un gran team, ven y postula con nosotros!!\\nSomos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusión en todas sus formas, sin importar religión, raza, género, situación de discapacidad, nacionalidad.\\nConoce más oportunidades para vivir la #ExperienciaFalabella en https://muevete.falabella.com/        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Financial Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer', 'company': 'Mediastream', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4206504298/', 'job_description': 'Description\\nMediastream is a leading streaming technology company that has been in business for over 16 years. We collaborate with major companies and broadcasters around the world to offer a quality end-to-end solution for content administration, distribution, audiovisual production, and user experience. Our goal is to connect our customers with their audience in a simple and effective way, creating new revenue streams for their businesses.\\nRole Description\\nThis is a hibrid role for a Data Egineer. The Data Engineer will be responsible for proposing advanced applications of our data, reviewing patterns, deviations to detect trends to optimize dashboards and optimize advertising strategies. Promote new strategies and technologies to process, analyze and leverage customer data and improve user engagement. With the main objective of: Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights, which serve for product roadmap, Develop and manage efficient data pipelines and ETL workflows for the integration of diverse data sources and Use machine learning models and recommendation algorithms to personalize strategies.\\nResponsibilities\\n- Create, implement and maintain the company\\'s data architecture.\\n- Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights for product roadmap.\\n- Develop and manage data pipelines and ETL workflows for the integration of diverse data sources.\\n- Use machine learning models and recommendation algorithms to personalize strategies.\\n- Create interactive visualizations and dashboards for studies to monitor performance and make data-driven decisions.\\n- Collaborate closely with the development team to integrate, create features and roadmap proposals. \\n- Have a product vision and work closely with the marketing and development teams to align strategies with business objectives.\\n\">\\nMediastream is a leading streaming technology company that has been in business for over 16 years. We collaborate with major companies and broadcasters around the world to offer a quality end-to-end solution for content administration, distribution, audiovisual production, and user experience. Our goal is to connect our customers with their audience in a simple and effective way, creating new revenue streams for their businesses.\\nRole Description\\nThis is a hibrid role for a Data Egineer. The Data Engineer will be responsible for proposing advanced applications of our data, reviewing patterns, deviations to detect trends to optimize dashboards and optimize advertising strategies. Promote new strategies and technologies to process, analyze and leverage customer data and improve user engagement. With the main objective of: Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights, which serve for product roadmap, Develop and manage efficient data pipelines and ETL workflows for the integration of diverse data sources and Use machine learning models and recommendation algorithms to personalize strategies.\\nResponsibilities\\n- Create, implement and maintain the company\\'s data architecture.\\n- Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights for product roadmap.\\n- Develop and manage data pipelines and ETL workflows for the integration of diverse data sources.\\n- Use machine learning models and recommendation algorithms to personalize strategies.\\n- Create interactive visualizations and dashboards for studies to monitor performance and make data-driven decisions.\\n- Collaborate closely with the development team to integrate, create features and roadmap proposals.\\n- Have a product vision and work closely with the marketing and development teams to align strategies with business objectives.\\nMinimum Requirements\\n- At least 3 years of experience in Data Engineer roles.\\n- Bachelor\\'s degree in computer science or related field.\\n- Knowledge in: SQL/No SQL: Advanced, Power BI, Looker, tableau or others: Intermediate, Python and development knowledge: Basic, machine learning, AI or similar technologies: Basic, Identification of cluster patterns, trends, deviations: Intermediate, cloud technologies: Intermediate.\\nSoft Skills:\\n- Teamwork\\n- Decision-making\\n- Attention to detail\\n- Adaptability \\n\">\\n- At least 3 years of experience in Data Engineer roles.\\n- Bachelor\\'s degree in computer science or related field.\\n- Knowledge in: SQL/No SQL: Advanced, Power BI, Looker, tableau or others: Intermediate, Python and development knowledge: Basic, machine learning, AI or similar technologies: Basic, Identification of cluster patterns, trends, deviations: Intermediate, cloud technologies: Intermediate.\\nSoft Skills:\\n- Teamwork\\n- Decision-making\\n- Attention to detail\\n- Adaptability        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer AWS', 'company': 'BC Tecnología', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205294910/', 'job_description': 'En \\nBC Tecnología\\n, nos especializamos en la consultoría de TI, ofreciendo un amplio rango de servicios para adaptarnos a las necesidades específicas de nuestros clientes, principalmente en finanzas, seguros, retail y gobierno. Nuestro equipo trabaja mediante metodologías ágiles, lo que nos permite diseñar e implementar soluciones tecnológicas efectivas y dirigidas al cliente. Actualmente, estamos buscando un Data Engineer con experiencia en AWS para sumarse a nuestro equipo y contribuir a proyectos innovadores en la gestión y explotación de datos.\\n Responsabilidades del Cargo\\n- Desarrollar y gestionar procesos de ETL, asegurando la calidad y fiabilidad de los datos.\\n- Optimizar la explotación de datos a través de técnicas de Tuning.\\n- Implementar soluciones utilizando herramientas de AWS, incluyendo Glue, Lambda, S3, Redshift y DynamoDB.\\n- Colaborar con los equipos de desarrollo de software para asegurar la integración de datos eficiente.\\n- Realizar análisis y visualización de datos para apoyar en la toma de decisiones.\\n- Mantener un enfoque en la innovación y la mejora continua de los procesos y herramientas utilizadas.\\n Descripción del Cargo\\nBuscamos Un Data Engineer AWS Con Un Mínimo De 3 Años De Experiencia En El Manejo De Datos. El Candidato Ideal Tendrá Conocimientos Sólidos En\\n- Explotación de datos y Tuning.\\n- Diseño e implementación de procesos ETL.\\n- Desarrollo de consultas efectivas en SQL.\\n- Programación en Python.\\n- Uso de herramientas de orquestación como Apache Airflow (deseable).\\nValoramos habilidades como el trabajo en equipo, la proactividad y la capacidad para adaptarse a nuevas tecnologías. La combinación de habilidades técnicas y soft skills es esencial para unirse a nuestro equipo dinámico.\\n Habilidades Deseables\\nAdemás de los requisitos mencionados, sería beneficioso contar con experiencia en:\\n- Integraciones y gestión de datos en múltiples fuentes.\\n- Implementación de soluciones en la nube de AWS.\\n- Conocimientos en herramientas de visualización de datos.\\nEstas habilidades ayudarán al candidato a integrarse de manera efectiva en nuestros equipos de trabajo y contribuir a proyectos futuros.\\n Beneficios de Trabajar con Nosotros\\nEn \\nBC Tecnología\\n, valoramos a nuestro equipo y ofrecemos un entorno flexible y beneficios atractivos:\\n- Contrato indefinido.\\n- Modalidad híbrida, combinando trabajo remoto y en oficina.\\n- Paquete de beneficios corporativos que incluye salud prepaga de primer nivel para el empleado y su familia.\\n- Un día de home office a la semana, junto con desayunos y un comedor en la planta.\\n- Acceso a un Sport Club y asistencia de un nutricionista.\\n¡Únete a nosotros y marca una diferencia en el mundo de la tecnología! 🎉\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst', 'company': 'LISIT', 'location': 'Los Ángeles, Biobío Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297449/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer Python', 'company': 'Equifax', 'location': 'Providencia, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4165780801/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer GCP', 'company': 'Soluciones - Data & Analytics Consulting', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4206574777/', 'job_description': '✔️\\n¿Quiénes Somos?\\nSomos una consultora enfocada en Data & Analytics y contamos con más de 20 años de experiencia y exitosa participación en implementación de proyectos de pequeña, mediana y gran envergadura. Nuestro equipo, compuesto por consultores multidisciplinarios expertos y certificados, ha entregado soluciones tecnológicas de calidad que exceden las expectativas de cada cliente. A través de una metodología flexible y adaptable, logramos entregar soluciones adecuadas a la realidad de cada organización, satisfaciendo los estándares de cada una de las empresas que confían en nosotros.\\n✔️\\n ¿Qué harás?\\n- Integración de productos de datos.\\n- Se trabajará con información para conocer a clientes y segmentarlos, para innovar en productos.\\n- Trabajará los procesos ETL de inicio a fin (ingesta, transformación, disponibilización).\\n- Conocimientos Full GCP (airflow, bigquery, cloudstorage como herramientas principales)\\n- Deberá generar el flujo completo del dato desde la ingesta, transformación y disponibilización.\\n✔️\\n ¿Qué se requiere?\\n- Experiencia en el rol o cargo de Ingeniero de Datos Google Cloud Platform (GCP)\\n✔️\\nConocimientos técnicos excluyentes:\\n- Experiencia en datos y modelo de datos\\n- Metodología agile\\n- Procesos ETL\\n- Conocimientos en Suit GCP\\n✔️ ¿Qué Ofrecemos ?\\n- Seguros complementario de salud\\n- Rutas de estudios\\n- Día libre cumpleaños\\n- Reajuste salarial anual según variación del IPC        \\n            \\n                            \\n            ', 'Seniority level': 'Associate', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Senior Data Engineer', 'company': '23people', 'location': 'Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207846989/', 'job_description': '¡Hola! Estamos buscando un Senior Data Engineer \\n🌐\\nRango salarial entre: $2.200.000 - $2.400.000 CLP\\nPaís: Residentes en Chile \\nSkills\\nTécnicas\\n- Python\\n- BigQuery/SQL\\n- GitHub\\n- Apache Beam/Spark/Google Dataflow\\nPersonales\\n- Capacidad de autogestión\\n- Buenos skills de comunicación\\n- Fortaleza en trabajo en equipo\\n- Adaptación al cambio (trabajarán en distintas geos de Latam)\\nDeseable (NO excluyente)\\n- Perfil Analítico\\n- UnitTest\\n- AirFlow\\n- PySpark\\n- CI/CD\\n- Postman\\n- Jmeter\\n¿Qué harás en tu día a día?\\nEl profesional colaborará con un equipo multidisciplinario en un proyecto de expansión internacional, enfocado en la migración estratégica de la plataforma hacia nuevos mercados. Su participación será fundamental para asegurar una implementación eficiente que considere las particularidades de cada país destino, garantizando así el éxito de esta iniciativa global.\\nAlgunas de sus tareas diarias son las siguientes:\\n- Implementar mecanismos para verificar la integridad de los datos migrados\\n- Implementar transformaciones específicas para requisitos regionales\\n- Dirigir el equipo técnico durante las fases críticas de migración\\n- Gestionar el proceso integral de ETL entre diversos sistemas, desarrollando y optimizando los esquemas de mapeo necesarios para garantizar la compatibilidad entre las estructuras de datos de origen y destino.\\nContrato indefinido desde el inicio con 23people\\nModalidad: Home Office, Con residencia en Chile (Deberás ir a buscar el PC en primera instancia)\\nExperiencia: Desde 5 años en adelante\\nHorario: Lunes a Jueves de 8:30 a 6:30 y Viernes de 8:30 a 5:30 hrs.\\nAlgunos de nuestros beneficios:\\n- Seguro complementario: Seguro de salud, vida y dental\\n- Curso de inglés: En nuestro programa de formación en idioma inglés, ofrecemos dos modalidades para adaptarnos a tus necesidades y objetivos.\\n- Reembolso de certificaciones internacionales: Apoyamos el crecimiento profesional, por lo que te reembolsamos el costo de un examen de certificación internacional que quieras realizar.\\n- Bono de vacaciones: Por cada semana que te tomes de vacaciones te otorgamos una compensación.\\n- Aguinaldos en fiestas patrias y Navidad: Queremos que en fechas tan especiales la pases bien junto a tu familia, por lo que te entregamos un bono en septiembre y diciembre\\n- Día libre de cumpleaños: Puedes optar por tomar tu día libre, el día previo a tu cumpleaños, el mismo día de tu cumpleaños o el día posterior.        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer AWS', 'company': 'Soluciones - Data & Analytics Consulting', 'location': 'Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207848749/', 'job_description': '✔️\\n¿Quiénes Somos?\\nSomos una consultora enfocada en Data & Analytics y contamos con más de 20 años de experiencia y exitosa participación en implementación de proyectos de pequeña, mediana y gran envergadura. Nuestro equipo, compuesto por consultores multidisciplinarios expertos y certificados, ha entregado soluciones tecnológicas de calidad que exceden las expectativas de cada cliente. A través de una metodología flexible y adaptable, logramos entregar soluciones adecuadas a la realidad de cada organización, satisfaciendo los estándares de cada una de las empresas que confían en nosotros.\\n✔️\\n ¿Qué harás?\\n- Responsabilidades del cargo: Diseñar, construir y mantener procesos de ingesta de datos que permiten recolectar, almacenar, procesar y acceder a grandes volúmenes de datos de manera eficiente y segura. Su trabajo asegura que los datos estén disponibles, limpios y organizados para su análisis adhiriéndose a los estándares definidos por el cliente.\\n✔️\\n ¿Qué se requiere?\\n- Experiencia de al menos 3 años en el rol\\n- Conocimientos técnicos excluyentes: S3, Lambdas, Glue Jobs, DynamoDB, Redshift, StepFunctions, Python, SQS.\\n- Conocimientos técnicos deseables: API Gateway, Transfer Family.\\n✔️ ¿Qué Ofrecemos ?\\n- Seguros complementario de salud\\n- Rutas de estudios\\n- Día libre cumpleaños\\n- Reajuste salarial anual según variación del IPC        \\n            \\n                            \\n            ', 'Seniority level': 'Not Applicable', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer Senior', 'company': 'Equifax', 'location': 'Las Condes, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4144902157/', 'job_description': 'Como Data Engineer, estarás a cargo de integrar, consolidar y estructurar los datos, apoyándote en un las mejores prácticas para manejar, mantener y mejorar nuestras soluciones.\\n \\n \\n ¿Qué vas a hacer? \\n \\n \\n-  Evaluar, gestionar y resolver incidentes. \\n-  Realizar cálculos en linea utilizando Python. \\n-  Ejecución de pruebas. \\n \\n \\n ¿Qué experiencia necesita? \\n \\n \\n-  + 4 años de experiencia trabajando en Python. \\n-  + 4 años de experiencia BigQuery. \\n-  + 4 años de experiencia trabajando con Apache Beam y GitHub. \\n \\n \\n ¿Qué podría diferenciarte? \\n \\n \\n-  Poseer alguna certificación de Google en Data Engineer. \\n-  Experiencia trabajando con Airflow. \\n-  Experiencia Trabajando con Jmeter. \\n-  Experiencia trabajando con Unit Test. \\n-  Experiencia trabajando con PySpark. \\n-  Experiencia trabajando con CI/DF. \\n-  Experiencia trabajando con Postman.        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Financial Services'}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer Semisenior o Senior', 'company': 'LISIT', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297492/', 'job_description': 'Lisit es una empresa comprometida con la creación, desarrollo e implementación de soluciones de software que faciliten la automatización y optimización para nuestros clientes. Nuestra visión se centra en brindar servicios que no solo cumplan con las necesidades del mercado, sino que también transformen la operatividad de las organizaciones. Tu función como Ingeniero de Datos será fundamental para lograr un acompañamiento consultivo integral en sus procesos de transformación.\\n Responsabilidades del puesto\\nComo Ingeniero De Datos Semi-senior o Senior En Lisit, Serás Una Pieza Clave En El Diseño y Desarrollo De Soluciones De Datos Que Optimicen Nuestros Servicios y Herramientas. Tus Tareas Incluirán\\n- Generar pipelines de datos eficientes y resolver integraciones entre diversos sistemas.\\n- Modelar datos para garantizar que nuestras plataformas sean útiles y escalables.\\n- Colaborar en la implementación de herramientas de infraestructura como código (IaC) y gestionar el versionamiento a través de GitHub o GitLab.\\n- Desarrollar y ejecutar procesos ETL/ELT utilizando Azure Data Factory, asegurando la calidad y accesibilidad de los datos.\\n Descripción del puesto\\nBuscamos un Ingeniero de Datos altamente motivado, con un mínimo de 3 años de experiencia en el tratamiento de datos. Tu destreza con lenguajes de programación como Python y Spark te permitirá desempeñarte con solidez en el equipo. Se requiere un conocimiento intermedio-avanzado de herramientas de IaC (Terraform) y manejo de versionamiento de código (GitHub/GitLab), así como una sólida comprensión del lenguaje SQL y bases de datos.\\nEs esencial que tengas experiencia con plataformas en la nube como Google Cloud Platform (GCP) o Azure, y herramientas como Airflow, Cloud Run, Cloud Composer y BigQuery. Además, el dominio de Azure Data Factory para procesos ETL-ELT es un requisito excluyente. Las certificaciones en Ingeniería de Datos son valoradas, tales como Azure DP-700, AZ-203, DP-600 y Google Cloud Digital Leader.\\n Habilidades deseables\\nSi cuentas con conocimientos en Microsoft Power BI o Fabric, sería un gran plus para tu perfil. Queremos personas que no solo cumplan con los requisitos, sino que también aporten un enfoque innovador y colaborativo a nuestro equipo.\\n Beneficios de trabajar con nosotros\\nEn Lisit, Fomentamos Un Ambiente De Trabajo Excepcional, Donde La Innovación y La Pasión Por El Aprendizaje Son Clave. Te Ofrecemos\\n- Acceso a oportunidades continuas de desarrollo profesional en tecnologías emergentes.\\n- Un equipo motivado y apasionado que valora tu entusiasmo y contribuciones.\\nAquí, tendrás la oportunidad de crecer y alcanzar tus objetivos profesionales mientras colaboras en proyectos desafiantes y de alto impacto.\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Technology, Information and Internet and Information Technology & Services'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Datos', 'company': 'Amaris Consulting', 'location': 'Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4206597362/', 'job_description': 'Who are we?\\nAmaris Consulting es una firma independiente de asesoría tecnológica que ofrece servicios de orientación y soluciones para las empresas.\\nReúne a más de 7 600 personas distribuidas en 5 continentes y más de 60 países. Con más de 1 000 clientes en todo el mundo, hemos implementado soluciones en proyectos importantes durante más de una década.\\nNuestros especialistas cubren sectores que abarcan desde servicios financieros y transporte hasta atención sanitaria y tecnología.\\nAmaris es su ‘stepping stone’ para atravesar ríos de cambio, afrontar retos y realizar todos sus proyectos con éxito.\\nJob Description\\nBuscamos consultores dinámicos para hacer crecer nuestro equipo de \\nSistemas de Información y Digital\\n en\\n Chile\\n. Tu experiencia, conocimiento y compromiso nos ayudarán a enfrentar los desafíos de nuestros clientes.\\nEstarás apoyando diferentes proyectos a través de tu experiencia como \\nIngeniero de Datos.\\nSus principales responsabilidades:\\n- Asegurar que las soluciones de datos sean escalables, eficientes y alineadas con los objetivos de negocio.\\n- Diseñar, desarrollar e implementar soluciones de gestión y análisis de datos en la industria.\\n- Utilizar herramientas como Python y SQL para extraer, transformar y cargar (ETL) datos.\\n- Trabajar con bases de datos en la nube, utilizando alguna de las principales plataformas: Google Cloud Platform (GCP), Amazon Web Services (AWS) o Microsoft Azure.\\n- Desarrollar y mantener pipelines de datos para la gestión y análisis eficiente.\\n- Desarrollar APIs y plugins para integrar soluciones de datos con otras aplicaciones y sistemas.\\n- Implementar y gestionar entornos de desarrollo y pruebas para soluciones de datos.\\n- Mantenerse actualizado con las últimas tendencias y herramientas en el ámbito de la ingeniería de datos.\\nRequisitos\\n:\\n- Al menos 2 años de experiencia como Ingeniero de Datos.\\n- Al menos 2 años de experiencia con alguna de las principales nubes (GCP, AWS, Azure).\\n- Dominio de Python.\\n- Dominio de bases de datos SQL.\\n- Experiencia con procesos ETL.\\nAmaris Consulting se enorgullece de ser un lugar de trabajo con igualdad de oportunidades. Estamos comprometidos con la promoción de la diversidad dentro de la fuerza de trabajo y la creación de un ambiente de trabajo inclusivo. Para ello, damos la bienvenida a las solicitudes de todos los candidatos cualificados, independientemente de su género, orientación sexual, raza, etnia, creencias, edad, estado civil, discapacidad u otras características.        \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Analista de Datos', 'company': 'Outlier', 'location': 'La Serena, Coquimbo Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207883217/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer - GCP Ssr', 'company': 'axity', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4204875774/', 'job_description': 'Company Description: axity\\nJob Description: Axity una compañía con más de 35 años de trayectoria nuestro portafolio de servicios es uno de los más grandes en la industria: Estrategia Digital, Desarrollo de Software, Bussiness Intelligence, Big Data, Analítica Avanzada, Seguridad, IOT.\\nBuscamos Data Analyst / Data Engineer – Nivel Medio/Avanzado\\n¿Te apasiona convertir datos en información valiosa y accionable?\\nEstamos en búsqueda de un profesional con experiencia en desarrollo de productos de complejidad media a avanzada, capaz de entregar soluciones de calidad dentro de los plazos establecidos.\\nResponsabilidades\\nDesarrollar productos analíticos cumpliendo con estándares de calidad y tiempos definidos.\\nTraducir datos en información útil para la toma de decisiones.\\nTrabajar en conjunto con equipos de analítica para profundizar en el análisis y la síntesis de datos.\\nSeleccionar y aplicar técnicas analíticas adecuadas a cada requerimiento.\\nMantenerse actualizado sobre herramientas analíticas y productos de manipulación de datos.\\nRealizar procesos de recolección, clasificación, limpieza e interpretación de grandes volúmenes de datos.\\nAplicar prácticas de gobernanza y seguridad de los datos.\\nParticipar en iniciativas que involucren integración de datos para procesos como planeación de compras, demanda y gestión de inventarios.\\nRequisitos\\nExperiencia en GCP (Google Cloud Platform): BigQuery, Cloud Storage, Dataflow, Cloud Functions, Composer, Pub/Sub.\\nConocimientos básicos en Kubernetes, contenedores y consumo de APIs.\\nExperiencia en manejo de grandes volúmenes de datos.\\nConocimiento de sistemas legados, flujos de compras y demand forecasting.\\nCapacidad de interacción continua con áreas de negocio.\\nOfrecemos\\nHorario: Lunes a viernes de 9:00 a 18:30\\nContrato a plazo fijo luego a indefinido\\nOportunidad de trabajar en proyectos desafiantes con impacto directo en el negocio\\nAmbiente colaborativo e innovador\\nSi te motiva trabajar con datos, impactar decisiones estratégicas y enfrentarte a desafíos técnicos, ¡postula con nosotros!\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero de Gobierno de Datos - Subgerencia de Gobierno de Datos', 'company': 'Consorcio', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-08', 'job_url': 'https://www.linkedin.com/jobs/view/4204238135/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer - AWS Ssr', 'company': 'axity', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4204874848/', 'job_description': 'Company Description: axity\\nJob Description: Axity una compañía con más de 35 años de trayectoria nuestro portafolio de servicios es uno de los más grandes en la industria: Estrategia Digital, Desarrollo de Software, Bussiness Intelligence, Big Data, Analítica Avanzada, Seguridad, IOT.\\nResponsabilidades Principales\\n-  Diseño eficiente de almacenamiento de datos: utilizando servicios como Amazon S3, DynamoDB, RDS, entre otros, optimizando costos, rendimiento y accesibilidad.\\n-  Optimización de consultas: aplicando índices, claves de partición y patrones de acceso eficientes (Query, GetItem, etc.).\\n-  Integración y procesamiento de datos: a través de herramientas como AWS Glue, Amazon Kinesis y/o Firehose para ingesta, transformación y orquestación.\\n-  Uso de formatos optimizados: como Parquet, ORC, entre otros, para mejorar la compresión y velocidad de lectura/escritura.\\n-  Infraestructura como Código (IaC): despliegue de infraestructura en AWS mediante CloudFormation, AWS CDK o Terraform.\\n________________________________________\\n️ Conocimientos Técnicos Clave\\n-  Amplio manejo de servicios AWS: S3, DynamoDB, RDS, AWS Glue, Kinesis/Firehose.\\n-  Dominio de bases de datos SQL/NoSQL: diseño de esquemas, indexación y tuning.\\n-  Experiencia en optimización y particionamiento de grandes volúmenes de datos.\\n-  Familiaridad con automatización y orquestación de pipelines: scripting, Jenkins, Shell, entre otros.\\n-  Modalidad: Híbrido\\n-  Área: Tecnología – Cloud\\n-  Horario: Lunes a viernes de 9:00 a 18:00 hrs\\n-  Tipo de Contrato: Plazo fijo, con posibilidad de pasar a indefinido\\n________________________________________\\n¿Por qué postular?\\n-  Serás parte de una empresa con enfoque en la innovación y la transformación digital.\\n-  Trabajarás con tecnologías de vanguardia en un entorno colaborativo.\\n-  Tendrás oportunidades reales de crecimiento profesional.        \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'IT Services and IT Consulting'}\n",
      "------------------------------\n",
      "{'title': 'Ingeniero en Gestión de Datos', 'company': 'Genesys', 'location': 'Las Condes, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4206087107/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer', 'company': 'IGX', 'location': 'Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205299322/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Consultor Data Analyst', 'company': 'LISIT', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4205297448/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer', 'company': 'Banco Falabella', 'location': 'Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4205421235/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Engineer Azure', 'company': '', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4206654598/', 'job_description': 'Resumen del Cargo:\\nBusco Ingeniero de Datos  para liderar y ejecutar proyectos de Data & Analytics. \\nSerá responsable del diseño, desarrollo e implementación de soluciones de datos usando Azure Databricks, Data Factory, Python  y otros servicios en la nube, asegurando que la infraestructura de datos sea escalable, segura y optimizada para la toma de decisiones. \\nAdemás, deberá interactuar directamente con áreas de negocio para levantar requerimientos y traducirlos en soluciones técnicas eficientes.\\n\\xa0\\n\\xa0\\nResponsabilidades:\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0•\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Diseñar y desarrollar soluciones de ingestión, transformación y modelado de datos en Azure DataFactory, Databricks y otras tecnologías relacionadas.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0•\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Optimizar procesos de ETL/ELT, asegurando calidad, integridad y eficiencia en el procesamiento de datos.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0•\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Colaborar con equipos de negocio para entender necesidades, identificar oportunidades y proponer soluciones basadas en datos.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0•\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Implementar arquitecturas de datos escalables que soporten analítica avanzada, machine learning e inteligencia de negocio.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0•\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Garantizar la seguridad y el cumplimiento normativo en el manejo de datos, siguiendo estándares bancarios y regulatorios.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0•\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Desarrollar y optimizar pipelines de datos para la explotación en entornos analíticos y de reportes.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0•\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Documentar procesos, arquitecturas y modelos de datos, asegurando buenas prácticas de gobernanza.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0•\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Trabajar en conjunto con equipos de Data Science, BI y Tecnología para garantizar la disponibilidad y calidad de los datos.\\n\\xa0        \\n            \\n                            \\n            ', 'Seniority level': 'Entry level', 'Employment type': 'Full-time', 'Job function': 'Information Technology'}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer', 'company': 'ZeroFox', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4203138895/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Backoffice - Analista de datos', 'company': 'Infinity Ingenieria SPA', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-10', 'job_url': 'https://www.linkedin.com/jobs/view/4204075434/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Analista de datos de Farmacia', 'company': 'IQVIA', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-12', 'job_url': 'https://www.linkedin.com/jobs/view/4208763580/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst Power BI- Bigquery', 'company': 'Soluciones - Data & Analytics Consulting', 'location': 'Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4207890015/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst Senior Modelos y Datos Riesgo', 'company': 'Banco Bci', 'location': 'Las Condes, Santiago Metropolitan Region, Chile', 'date': '2025-04-08', 'job_url': 'https://www.linkedin.com/jobs/view/4203767105/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Insights Specialist', 'company': 'Nestlé', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4202697660/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Data Analyst I - Operations', 'company': 'Signant Health', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4202554692/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer II, Gerencia Tecnología', 'company': 'Walmart Chile', 'location': 'Huechuraba, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4206684576/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer III, Gerencia Tecnología', 'company': 'Walmart Chile', 'location': 'Huechuraba, Santiago Metropolitan Region, Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4206686540/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Salesforce Software Engineer', 'company': 'Banco Falabella', 'location': 'Santiago Metropolitan Area', 'date': '2025-04-07', 'job_url': 'https://www.linkedin.com/jobs/view/4203137306/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Analista BI', 'company': 'Chubb', 'location': 'Chile', 'date': '2025-04-11', 'job_url': 'https://www.linkedin.com/jobs/view/4208212282/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Software Engineer III', 'company': 'Mindbody', 'location': 'Chile', 'date': '2025-04-13', 'job_url': 'https://www.linkedin.com/jobs/view/4169374324/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Senior Software Engineer, Backend (Remote)', 'company': 'Mindbody', 'location': 'Chile', 'date': '2025-04-12', 'job_url': 'https://www.linkedin.com/jobs/view/4170144703/', 'job_description': ''}\n",
      "------------------------------\n",
      "{'title': 'Senior Data Engineer', 'company': 'Grupo Falabella', 'location': 'Santiago, Santiago Metropolitan Region, Chile', 'date': '2025-04-09', 'job_url': 'https://www.linkedin.com/jobs/view/4205465977/', 'job_description': 'Descripción Empresa\\nSomos más de 90 mil personas que, día a día, dedicamos nuestra pasión y energía a cumplir nuestro Propósito de “Simplificar y Disfrutar Más la Vida”. Propósito que hoy vive a través de nuestro ecosistema físico y digital en todas nuestras empresas (Falabella Retail, Sodimac, IKEA, Tottus, Mallplaza, Falabella Inmobiliario, Falabella.com, Linio, Falabella Financiero, Banco Falabella, Falabella Soriana, Seguros Falabella, Fazil, Fpay y Falabella Corporativo) y países (Argentina, Brasil, Chile, China, Colombia, India, México, Perú y Uruguay).\\nValoramos las distintas miradas porque entendemos que la diversidad es la clave de nuestra innovación. Queremos ir más allá de cualquier límite, desafiarnos constantemente, divertirnos haciendo lo que nos gusta y dejar huella en lo que hacemos. Y sabemos que existe una forma de hacerlo: como UN SOLO EQUIPO.\\nMisión Del Cargo\\n¡Únete a Falabella Retail y lleva tus habilidades de Ingeniería de Datos al próximo nivel!\\nFunciones Del Cargo\\nFormarás parte de un equipo de alto impacto que lidera la transformación digital, trabajando en proyectos críticos para optimizar y escalar nuestras operaciones en uno de los ecosistemas más dinámicos de la región.\\nMision: Responsable de diseñar, construir y mantener sistemas de datos escalables para el análisis y la toma de decisiones en la organización.\\nResponsabilidades\\nDiseñar y desarrollar canalizaciones de datos (ETL/ELT) robustas y eficientes.\\nColaborar con equipos de ingeniería de datos.\\nImplementar y gestionar bases de datos y data warehouses.\\nOptimizar el rendimiento de las bases de datos y sistemas de almacenamiento de datos.\\nGarantizar la calidad, integridad y seguridad de los datos.\\nAutomatizar procesos de ingestión y transformación de datos.\\nMonitorizar y solucionar problemas relacionados con los sistemas de datos.\\nDocumentar procesos, arquitecturas y mejores prácticas relacionadas con el manejo de datos.\\nSi disfrutas nuevos desafíos con alta responsabilidad y exposición en el epicentro de la transformación del retail en Latinoamérica, ¡súmate a trabajar con nosotros! Somos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusión en todas sus formas, sin importar religión, raza, género, situación de discapacidad, nacionalidad.\\nConoce más oportunidades para vivir la #ExperienciaFalabella en https://muevete.falabella.com/\\nRequisitos\\n- Profesional Titulado en Ingeniería Civil Computación, Industrial, matemático u eléctrico.\\n- Experiencia demostrable como Data Engineer por mas de 04 años\\n- Conocimientos en lenguajes de programación Python.\\n- Experiencia con Google Cloud Platform (Composer, Cloud Functions, Bigquery, Dataproc, etc)\\n- Experiencia utilizando git\\n- Deseable: Conocimientos profundos en SQL y en bases de datos relacionales y no relacionales\\n- Deseable: Certificaciones relevantes en tecnologías de datos y cloud.\\nCondiciones Oferta\\nDescripción proceso de selección:\\nEl proceso de selección se realiza a través de Aira - plataforma de reclutamiento diseñado para mejorar tu experiencia de postulación.\\nPara Postular Solo Necesitas\\n-  Postular a la oferta\\n-  Revisar tu email\\n-  Ingresar a Aira y contestar las preguntas y/o pruebas solicitadas\\nLuego, si vemos que tu perfil se ajusta a lo que estamos buscando, te contactaremos por email (a través de Aira) para seguir a la etapa presencial.\\n                \\n            \\n                            \\n            ', 'Seniority level': 'Mid-Senior level', 'Employment type': 'Full-time', 'Job function': 'Information Technology', 'Industries': 'Retail'}\n"
     ]
    }
   ],
   "source": [
    "for job in joblist:\n",
    "    print('-' * 30)\n",
    "    print(job)\n",
    "    # {print(v) for k, v in job.items() if job['job_description'] != ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(joblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (31, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>title</th><th>company</th><th>location</th><th>date</th><th>job_url</th><th>job_description</th><th>Seniority level</th><th>Employment type</th><th>Job function</th><th>Industries</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Data Engineer Junior&quot;</td><td>&quot;LISIT&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;En Lisit, nos dedicamos a crea…</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Technology, Information and In…</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Xepelin&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Somos una FinTech que busca de…</td><td>&quot;Not Applicable&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Software Development, IT Servi…</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;BC Tecnología&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Could not find Job Description&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;2Brains&quot;</td><td>&quot;Chile&quot;</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;2Brains es una empresa dedicad…</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Technology, Information and In…</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Falabella&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-11&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Descripción Empresa\n",
       "Somos más …</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Retail&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Ingeniero de Datos&quot;</td><td>&quot;Amaris Consulting&quot;</td><td>&quot;Chile&quot;</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Who are we?\n",
       "Amaris Consulting …</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer - GCP Ssr&quot;</td><td>&quot;axity&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Company Description: axity\n",
       "Job…</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer - AWS Ssr&quot;</td><td>&quot;axity&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Company Description: axity\n",
       "Job…</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer Azure&quot;</td><td>&quot;&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Resumen del Cargo:\n",
       "Busco Ingen…</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>null</td></tr><tr><td>&quot;Senior Data Engineer&quot;</td><td>&quot;Grupo Falabella&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Descripción Empresa\n",
       "Somos más …</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Retail&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (31, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ title     ┆ company   ┆ location  ┆ date      ┆ … ┆ Seniority ┆ Employmen ┆ Job       ┆ Industri │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ level     ┆ t type    ┆ function  ┆ es       │\n",
       "│ str       ┆ str       ┆ str       ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ str       ┆ str       ┆ str       ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Data      ┆ LISIT     ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ Entry     ┆ Full-time ┆ Informati ┆ Technolo │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 0         ┆   ┆ level     ┆           ┆ on Techno ┆ gy, Info │\n",
       "│ Junior    ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆ rmation  │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆ and In…  │\n",
       "│ Data      ┆ Xepelin   ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Not Appli ┆ Full-time ┆ Informati ┆ Software │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 9         ┆   ┆ cable     ┆           ┆ on Techno ┆ Developm │\n",
       "│           ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆ ent, IT  │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆ Servi…   │\n",
       "│ Data      ┆ BC Tecnol ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ Engineer  ┆ ogía      ┆ Santiago  ┆ 0         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Data      ┆ 2Brains   ┆ Chile     ┆ 2025-04-1 ┆ … ┆ Mid-Senio ┆ Full-time ┆ Informati ┆ Technolo │\n",
       "│ Engineer  ┆           ┆           ┆ 0         ┆   ┆ r level   ┆           ┆ on Techno ┆ gy, Info │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ logy      ┆ rmation  │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ and In…  │\n",
       "│ Data      ┆ Falabella ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ Mid-Senio ┆ Full-time ┆ Informati ┆ Retail   │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 1         ┆   ┆ r level   ┆           ┆ on Techno ┆          │\n",
       "│           ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆          │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ Ingeniero ┆ Amaris    ┆ Chile     ┆ 2025-04-1 ┆ … ┆ Entry     ┆ Full-time ┆ Informati ┆ IT       │\n",
       "│ de Datos  ┆ Consultin ┆           ┆ 0         ┆   ┆ level     ┆           ┆ on Techno ┆ Services │\n",
       "│           ┆ g         ┆           ┆           ┆   ┆           ┆           ┆ logy      ┆ and IT   │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ Consulti │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ ng       │\n",
       "│ Data      ┆ axity     ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Mid-Senio ┆ Full-time ┆ Informati ┆ IT       │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 9         ┆   ┆ r level   ┆           ┆ on Techno ┆ Services │\n",
       "│ - GCP Ssr ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆ and IT   │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆ Consulti │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ ng       │\n",
       "│ Data      ┆ axity     ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Mid-Senio ┆ Full-time ┆ Informati ┆ IT       │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 9         ┆   ┆ r level   ┆           ┆ on Techno ┆ Services │\n",
       "│ - AWS Ssr ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆ and IT   │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆ Consulti │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ ng       │\n",
       "│ Data      ┆           ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ Entry     ┆ Full-time ┆ Informati ┆ null     │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 0         ┆   ┆ level     ┆           ┆ on Techno ┆          │\n",
       "│ Azure     ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆          │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Senior    ┆ Grupo     ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Mid-Senio ┆ Full-time ┆ Informati ┆ Retail   │\n",
       "│ Data      ┆ Falabella ┆ Santiago  ┆ 9         ┆   ┆ r level   ┆           ┆ on Techno ┆          │\n",
       "│ Engineer  ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆          │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.filter(pl.col('job_description') != ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(pl.col('job_description') != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (31, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>title</th><th>company</th><th>location</th><th>date</th><th>job_url</th><th>job_description</th><th>Seniority level</th><th>Employment type</th><th>Job function</th><th>Industries</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Data Engineer Junior&quot;</td><td>&quot;LISIT&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;En Lisit, nos dedicamos a crea…</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Technology, Information and In…</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Xepelin&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Somos una FinTech que busca de…</td><td>&quot;Not Applicable&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Software Development, IT Servi…</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;BC Tecnología&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Could not find Job Description&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;2Brains&quot;</td><td>&quot;Chile&quot;</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;2Brains es una empresa dedicad…</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Technology, Information and In…</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Falabella&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-11&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Descripción Empresa\n",
       "Somos más …</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Retail&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Ingeniero de Datos&quot;</td><td>&quot;Amaris Consulting&quot;</td><td>&quot;Chile&quot;</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Who are we?\n",
       "Amaris Consulting …</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer - GCP Ssr&quot;</td><td>&quot;axity&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Company Description: axity\n",
       "Job…</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer - AWS Ssr&quot;</td><td>&quot;axity&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Company Description: axity\n",
       "Job…</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;IT Services and IT Consulting&quot;</td></tr><tr><td>&quot;Data Engineer Azure&quot;</td><td>&quot;&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-10&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Resumen del Cargo:\n",
       "Busco Ingen…</td><td>&quot;Entry level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>null</td></tr><tr><td>&quot;Senior Data Engineer&quot;</td><td>&quot;Grupo Falabella&quot;</td><td>&quot;Santiago, Santiago Metropolita…</td><td>&quot;2025-04-09&quot;</td><td>&quot;https://www.linkedin.com/jobs/…</td><td>&quot;Descripción Empresa\n",
       "Somos más …</td><td>&quot;Mid-Senior level&quot;</td><td>&quot;Full-time&quot;</td><td>&quot;Information Technology&quot;</td><td>&quot;Retail&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (31, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ title     ┆ company   ┆ location  ┆ date      ┆ … ┆ Seniority ┆ Employmen ┆ Job       ┆ Industri │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ level     ┆ t type    ┆ function  ┆ es       │\n",
       "│ str       ┆ str       ┆ str       ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ str       ┆ str       ┆ str       ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Data      ┆ LISIT     ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ Entry     ┆ Full-time ┆ Informati ┆ Technolo │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 0         ┆   ┆ level     ┆           ┆ on Techno ┆ gy, Info │\n",
       "│ Junior    ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆ rmation  │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆ and In…  │\n",
       "│ Data      ┆ Xepelin   ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Not Appli ┆ Full-time ┆ Informati ┆ Software │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 9         ┆   ┆ cable     ┆           ┆ on Techno ┆ Developm │\n",
       "│           ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆ ent, IT  │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆ Servi…   │\n",
       "│ Data      ┆ BC Tecnol ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ Engineer  ┆ ogía      ┆ Santiago  ┆ 0         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Data      ┆ 2Brains   ┆ Chile     ┆ 2025-04-1 ┆ … ┆ Mid-Senio ┆ Full-time ┆ Informati ┆ Technolo │\n",
       "│ Engineer  ┆           ┆           ┆ 0         ┆   ┆ r level   ┆           ┆ on Techno ┆ gy, Info │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ logy      ┆ rmation  │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ and In…  │\n",
       "│ Data      ┆ Falabella ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ Mid-Senio ┆ Full-time ┆ Informati ┆ Retail   │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 1         ┆   ┆ r level   ┆           ┆ on Techno ┆          │\n",
       "│           ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆          │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ Ingeniero ┆ Amaris    ┆ Chile     ┆ 2025-04-1 ┆ … ┆ Entry     ┆ Full-time ┆ Informati ┆ IT       │\n",
       "│ de Datos  ┆ Consultin ┆           ┆ 0         ┆   ┆ level     ┆           ┆ on Techno ┆ Services │\n",
       "│           ┆ g         ┆           ┆           ┆   ┆           ┆           ┆ logy      ┆ and IT   │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ Consulti │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ ng       │\n",
       "│ Data      ┆ axity     ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Mid-Senio ┆ Full-time ┆ Informati ┆ IT       │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 9         ┆   ┆ r level   ┆           ┆ on Techno ┆ Services │\n",
       "│ - GCP Ssr ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆ and IT   │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆ Consulti │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ ng       │\n",
       "│ Data      ┆ axity     ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Mid-Senio ┆ Full-time ┆ Informati ┆ IT       │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 9         ┆   ┆ r level   ┆           ┆ on Techno ┆ Services │\n",
       "│ - AWS Ssr ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆ and IT   │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆ Consulti │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ ng       │\n",
       "│ Data      ┆           ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ Entry     ┆ Full-time ┆ Informati ┆ null     │\n",
       "│ Engineer  ┆           ┆ Santiago  ┆ 0         ┆   ┆ level     ┆           ┆ on Techno ┆          │\n",
       "│ Azure     ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆          │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Senior    ┆ Grupo     ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Mid-Senio ┆ Full-time ┆ Informati ┆ Retail   │\n",
       "│ Data      ┆ Falabella ┆ Santiago  ┆ 9         ┆   ┆ r level   ┆           ┆ on Techno ┆          │\n",
       "│ Engineer  ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆ logy      ┆          │\n",
       "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENAI PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "API_KEY = 'AIzaSyCaIGQDXLA-jmSCRl7NSE64uODswGHQ9tQ'\n",
    "TEXT_COLUMN_NAME = \"text_content\" # CHANGE if your text column has a different name\n",
    "OUTPUT_COLUMN_NAME = \"cloud_focus\"\n",
    "# Optional: Add a small delay between API calls to avoid rate limits\n",
    "API_CALL_DELAY_SECONDS = 0.5 # Adjust as needed, 0 for no delay\n",
    "\n",
    "# --- Gemini Setup ---\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY environment variable not set.\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Choose a Gemini model (e.g., 'gemini-1.5-flash' or 'gemini-pro')\n",
    "# Flash is faster and cheaper, Pro might be slightly more capable.\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Define allowed classification outputs (plus handling for errors/unknown)\n",
    "ALLOWED_OUTPUTS = {\"GCP\", \"Azure\", \"AWS\", \"Other\"}\n",
    "ERROR_OUTPUT = \"API_Error\"\n",
    "UNKNOWN_OUTPUT = \"Other\" # Default if Gemini doesn't give a clear answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cloud_focus(job_description_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses the Gemini API to classify the primary cloud focus of a job description.\n",
    "\n",
    "    Args:\n",
    "        job_description_text: The text of the job description.\n",
    "\n",
    "    Returns:\n",
    "        A string indicating the classification: \"GCP\", \"Azure\", \"AWS\", \"Other\",\n",
    "        or \"Error\" if the API call fails.\n",
    "    \"\"\"\n",
    "    if not job_description_text or not isinstance(job_description_text, str) or len(job_description_text.strip()) < 20:\n",
    "         # Handle empty or very short descriptions to save API calls\n",
    "        return \"Invalid_Input\"\n",
    "\n",
    "    # --- Prompt Engineering ---\n",
    "    # Be very specific about the desired output format.\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following job description text and determine its primary cloud platform focus.\n",
    "    Possible categories are: GCP, Azure, AWS.\n",
    "\n",
    "    - If the text strongly emphasizes Google Cloud Platform skills (like BigQuery, GKE, Cloud Functions, App Engine), classify it as 'GCP'.\n",
    "    - If the text strongly emphasizes Microsoft Azure skills (like Azure Functions, AKS, Azure SQL, Cosmos DB, Entra ID), classify it as 'Azure'.\n",
    "    - If the text strongly emphasizes Amazon Web Services skills (like EC2, S3, Lambda, RDS, EKS, DynamoDB), classify it as 'AWS'.\n",
    "    - If multiple platforms are mentioned significantly without a clear primary focus, or if no cloud platform is the main focus, classify it as 'Other'.\n",
    "\n",
    "    Job Description:\n",
    "    ---\n",
    "    {job_description_text}\n",
    "    ---\n",
    "\n",
    "    Output only one word: GCP, Azure, AWS, or Other.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- API Call with Error Handling ---\n",
    "    max_retries = 3\n",
    "    retry_delay = 5 # seconds\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            # Basic cleaning and validation\n",
    "            classification = response.text.strip().upper()\n",
    "            if classification in [\"GCP\", \"AZURE\", \"AWS\", \"OTHER\"]:\n",
    "                return classification\n",
    "            else:\n",
    "                 # The model might sometimes output extra text or fail the instruction.\n",
    "                 # Let's try to find the keyword within the response as a fallback.\n",
    "                if \"GCP\" in classification: return \"GCP\"\n",
    "                if \"AZURE\" in classification: return \"Azure\" # Keep consistent casing\n",
    "                if \"AWS\" in classification: return \"AWS\"\n",
    "                if \"OTHER\" in classification: return \"Other\" # Keep consistent casing\n",
    "                print(f\"Warning: Unexpected response format: '{response.text}'. Defaulting to 'Other'.\")\n",
    "                return \"Other\" # Fallback if model output is unexpected\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"API Error: {e}. Attempt {attempt + 1}/{max_retries}. Retrying in {retry_delay}s...\")\n",
    "            if attempt < max_retries - 1:\n",
    "                 time.sleep(retry_delay) # Wait before retrying\n",
    "                 retry_delay *= 2 # Exponential backoff\n",
    "            else:\n",
    "                print(\"API Error: Max retries reached.\")\n",
    "                return \"API_Error\" # Indicate an API failure\n",
    "\n",
    "    return \"API_Error\" # Should not be reached if retries work, but good failsafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Jobs:  52%|█████▏    | 16/31 [00:11<00:09,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "]. Attempt 1/3. Retrying in 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Jobs:  55%|█████▍    | 17/31 [00:16<00:30,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]. Attempt 1/3. Retrying in 5s...\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "]. Attempt 2/3. Retrying in 10s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Jobs:  58%|█████▊    | 18/31 [00:32<01:21,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "]. Attempt 3/3. Retrying in 20s...\n",
      "API Error: Max retries reached.\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "]. Attempt 1/3. Retrying in 5s...\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "]. Attempt 2/3. Retrying in 10s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Jobs:  61%|██████▏   | 19/31 [00:48<01:49,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]. Attempt 3/3. Retrying in 20s...\n",
      "API Error: Max retries reached.\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]. Attempt 1/3. Retrying in 5s...\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 20\n",
      "}\n",
      "]. Attempt 2/3. Retrying in 10s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Jobs: 100%|██████████| 31/31 [01:10<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with Cloud Focus Classification:\n",
      "shape: (31, 11)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ title     ┆ company   ┆ location  ┆ date      ┆ … ┆ Employmen ┆ Job       ┆ Industrie ┆ cloud_fo │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ t type    ┆ function  ┆ s         ┆ cus      │\n",
      "│ str       ┆ str       ┆ str       ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆           ┆           ┆   ┆ str       ┆ str       ┆ str       ┆ str      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ Data      ┆ LISIT     ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ Full-time ┆ Informati ┆ Technolog ┆ OTHER    │\n",
      "│ Engineer  ┆           ┆ Santiago  ┆ 0         ┆   ┆           ┆ on Techno ┆ y, Inform ┆          │\n",
      "│ Junior    ┆           ┆ Metropoli ┆           ┆   ┆           ┆ logy      ┆ ation and ┆          │\n",
      "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆ In…       ┆          │\n",
      "│ Data      ┆ Xepelin   ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Full-time ┆ Informati ┆ Software  ┆ GCP      │\n",
      "│ Engineer  ┆           ┆ Santiago  ┆ 9         ┆   ┆           ┆ on Techno ┆ Developme ┆          │\n",
      "│           ┆           ┆ Metropoli ┆           ┆   ┆           ┆ logy      ┆ nt, IT    ┆          │\n",
      "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆ Servi…    ┆          │\n",
      "│ Data      ┆ BC Tecnol ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ null      ┆ null      ┆ null      ┆ OTHER    │\n",
      "│ Engineer  ┆ ogía      ┆ Santiago  ┆ 0         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ Metropoli ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ Data      ┆ 2Brains   ┆ Chile     ┆ 2025-04-1 ┆ … ┆ Full-time ┆ Informati ┆ Technolog ┆ OTHER    │\n",
      "│ Engineer  ┆           ┆           ┆ 0         ┆   ┆           ┆ on Techno ┆ y, Inform ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆ logy      ┆ ation and ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ In…       ┆          │\n",
      "│ Data      ┆ Falabella ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ Full-time ┆ Informati ┆ Retail    ┆ GCP      │\n",
      "│ Engineer  ┆           ┆ Santiago  ┆ 1         ┆   ┆           ┆ on Techno ┆           ┆          │\n",
      "│           ┆           ┆ Metropoli ┆           ┆   ┆           ┆ logy      ┆           ┆          │\n",
      "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
      "│ Ingeniero ┆ Amaris    ┆ Chile     ┆ 2025-04-1 ┆ … ┆ Full-time ┆ Informati ┆ IT        ┆ OTHER    │\n",
      "│ de Datos  ┆ Consultin ┆           ┆ 0         ┆   ┆           ┆ on Techno ┆ Services  ┆          │\n",
      "│           ┆ g         ┆           ┆           ┆   ┆           ┆ logy      ┆ and IT    ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ Consultin ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ g         ┆          │\n",
      "│ Data      ┆ axity     ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Full-time ┆ Informati ┆ IT        ┆ GCP      │\n",
      "│ Engineer  ┆           ┆ Santiago  ┆ 9         ┆   ┆           ┆ on Techno ┆ Services  ┆          │\n",
      "│ - GCP Ssr ┆           ┆ Metropoli ┆           ┆   ┆           ┆ logy      ┆ and IT    ┆          │\n",
      "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆ Consultin ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ g         ┆          │\n",
      "│ Data      ┆ axity     ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Full-time ┆ Informati ┆ IT        ┆ AWS      │\n",
      "│ Engineer  ┆           ┆ Santiago  ┆ 9         ┆   ┆           ┆ on Techno ┆ Services  ┆          │\n",
      "│ - AWS Ssr ┆           ┆ Metropoli ┆           ┆   ┆           ┆ logy      ┆ and IT    ┆          │\n",
      "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆ Consultin ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ g         ┆          │\n",
      "│ Data      ┆           ┆ Santiago, ┆ 2025-04-1 ┆ … ┆ Full-time ┆ Informati ┆ null      ┆ AZURE    │\n",
      "│ Engineer  ┆           ┆ Santiago  ┆ 0         ┆   ┆           ┆ on Techno ┆           ┆          │\n",
      "│ Azure     ┆           ┆ Metropoli ┆           ┆   ┆           ┆ logy      ┆           ┆          │\n",
      "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ Senior    ┆ Grupo     ┆ Santiago, ┆ 2025-04-0 ┆ … ┆ Full-time ┆ Informati ┆ Retail    ┆ GCP      │\n",
      "│ Data      ┆ Falabella ┆ Santiago  ┆ 9         ┆   ┆           ┆ on Techno ┆           ┆          │\n",
      "│ Engineer  ┆           ┆ Metropoli ┆           ┆   ┆           ┆ logy      ┆           ┆          │\n",
      "│           ┆           ┆ ta…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifications = []\n",
    "# Iterating with tqdm to show progress\n",
    "for desc in tqdm(df[\"job_description\"], desc=\"Classifying Jobs\"):\n",
    "    classifications.append(classify_cloud_focus(desc))\n",
    "    # Optional: Add a small delay to respect potential API rate limits\n",
    "    time.sleep(2) # Adjust delay as needed (e.g., 1 second for free tier)\n",
    "\n",
    "\n",
    "# Add the results as a new column\n",
    "df = df.with_columns(\n",
    "    pl.Series(\"cloud_focus\", classifications)\n",
    ")\n",
    "\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"\\nDataFrame with Cloud Focus Classification:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2025-04-13\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "# Get today's date\n",
    "today = date.today()\n",
    "print(\"Today's date:\", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export to CSV ---\n",
    "df.write_csv(f'joblist_{today}_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('joblist_2025-04-13_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (31, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_description</th><th>cloud_focus</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;En Lisit, nos dedicamos a crea…</td><td>&quot;OTHER&quot;</td></tr><tr><td>&quot;Somos una FinTech que busca de…</td><td>&quot;GCP&quot;</td></tr><tr><td>&quot;Could not find Job Description&quot;</td><td>&quot;OTHER&quot;</td></tr><tr><td>&quot;2Brains es una empresa dedicad…</td><td>&quot;OTHER&quot;</td></tr><tr><td>&quot;Descripción Empresa\n",
       "Somos más …</td><td>&quot;GCP&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Who are we?\n",
       "Amaris Consulting …</td><td>&quot;OTHER&quot;</td></tr><tr><td>&quot;Company Description: axity\n",
       "Job…</td><td>&quot;GCP&quot;</td></tr><tr><td>&quot;Company Description: axity\n",
       "Job…</td><td>&quot;AWS&quot;</td></tr><tr><td>&quot;Resumen del Cargo:\n",
       "Busco Ingen…</td><td>&quot;AZURE&quot;</td></tr><tr><td>&quot;Descripción Empresa\n",
       "Somos más …</td><td>&quot;GCP&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (31, 2)\n",
       "┌─────────────────────────────────┬─────────────┐\n",
       "│ job_description                 ┆ cloud_focus │\n",
       "│ ---                             ┆ ---         │\n",
       "│ str                             ┆ str         │\n",
       "╞═════════════════════════════════╪═════════════╡\n",
       "│ En Lisit, nos dedicamos a crea… ┆ OTHER       │\n",
       "│ Somos una FinTech que busca de… ┆ GCP         │\n",
       "│ Could not find Job Description  ┆ OTHER       │\n",
       "│ 2Brains es una empresa dedicad… ┆ OTHER       │\n",
       "│ Descripción Empresa             ┆ GCP         │\n",
       "│ Somos más …                     ┆             │\n",
       "│ …                               ┆ …           │\n",
       "│ Who are we?                     ┆ OTHER       │\n",
       "│ Amaris Consulting …             ┆             │\n",
       "│ Company Description: axity      ┆ GCP         │\n",
       "│ Job…                            ┆             │\n",
       "│ Company Description: axity      ┆ AWS         │\n",
       "│ Job…                            ┆             │\n",
       "│ Resumen del Cargo:              ┆ AZURE       │\n",
       "│ Busco Ingen…                    ┆             │\n",
       "│ Descripción Empresa             ┆ GCP         │\n",
       "│ Somos más …                     ┆             │\n",
       "└─────────────────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(pl.col('job_description'), pl.col('cloud_focus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
