title,company,location,date,job_url,job_description,Seniority level,Employment type,Job function,Industries,cloud_focus
Data Engineer Junior,LISIT,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205294902/,"En Lisit, nos dedicamos a crear, desarrollar e implementar herramientas y servicios de software que automatizan y optimizan procesos, siempre con un fuerte enfoque en la innovación y los desafíos que se presentan. Nuestro objetivo es fomentar la eficacia operativa de nuestros clientes, ayudándoles a alcanzar sus metas de transformación mediante un acompañamiento consultivo integral. Actualmente, estamos en búsqueda de un Data Engineer Junior que se una a nuestro equipo apasionado por la tecnología y el aprendizaje continuo.
 Funciones del Rol
Como Data Engineer Junior, Serás Parte Esencial Del Equipo Encargado De Manejar y Optimizar El Flujo De Datos De La Organización. Tus Principales Responsabilidades Incluirán
- Colaborar en la recopilación y procesamiento de datos relacionales y no relacionales.
- Trabajar con lenguajes de programación, especialmente Python, para crear soluciones de datos efectivas.
- Implementar y mantener los procesos de integración en ambientes cloud como GCP o Azure.
- Realizar consultas y manipulación de bases de datos utilizando SQL.
- Aprender y adaptarte a nuevas tecnologías y herramientas en el entorno de la nube.
 Descripción del Perfil
Buscamos Un Perfil Proactivo, Con Conocimientos Intermedios En Python y Disposición Para Aprender Sobre Nuevas Tecnologías. El Candidato Ideal Deberá Tener
- Experiencia básica a intermedia en programación Python.
- Habilidades en el uso y tratamiento de datos en ambientes tanto relacionales como no relacionales.
- Conocimientos fundamentales en tecnologías de nube, incluyendo GCP o Azure.
- Experiencia en el uso del lenguaje SQL.
- Bajo es requisito pero se valorará el conocimiento en Power BI.
 Habilidades Deseables
Sería excelente contar con conocimientos adicionales en herramientas de visualización de datos como Power BI. Además, habilidad para trabajar en equipo y una mentalidad orientada al aprendizaje continuo son altamente valoradas.
 Beneficios de Trabajar con Nosotros
En Lisit, Promovemos Un Ambiente De Trabajo Excepcional
- Acceso a oportunidades de desarrollo profesional continuo en tecnologías emergentes.
- Un equipo apasionado por la innovación y el aprendizaje, donde tu entusiasmo será bienvenido.        
            
                            
            ",Entry level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",OTHER
Data Engineer,Xepelin,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4205474021/,"Somos una FinTech que busca democratizar los servicios financieros para todo tipo de empresas. Nos apalancamos en la mejor tecnología para crear soluciones ágiles, personalizadas y transparentes. Nuestro objetivo es ser la FinTech B2B más grande de Latam y convertirnos en el CFO digital de todas las empresas en la región.
Xepelin nace en Chile en 2019 y, desde entonces, hemos levantado más de USD145 millones en equity y USD300 millones en asset-backed facilities para potenciar el crecimiento en toda la región, especialmente en los países donde hoy operamos, Chile y México. La última ronda de equity fue de USD111 millones, record en Chile y una de las más grandes en América Latina para una FinTech.
¿Por qué trabajar en Xepelin?
💪 Desafío
Estamos sacudiendo una de las industrias más poderosas y competitivas, eliminando fricciones para darle a las Pymes acceso a capital y apalancado en la última tecnología disponible. Todo esto poniendo siempre a nuestras Pymes en el centro.
Construir un banco digital desde cero es un gran proyecto; el producto es complejo y no se puede romper, existen regulaciones estrictas y tendremos que ser mejores que algunas de las corporaciones más grandes y consolidadas del mundo. Pero superar estos desafíos significa que habremos construido algo duradero.
💥 Impacto
Trabajar en un equipo de clase mundial y automotivado significa autonomía, amplia experiencia en todos los proyectos y ver que tus contribuciones afectan directamente al producto e impactan a nuestras Pymes.
Trabajarás con todos nuestros productos, tendrás que tomar decisiones fundamentales. El correcto posicionamiento de ellos marcará su futuro.
✔️ Calidad
Nuestro posicionamiento de marca y productos es algo diferenciador frente al resto del mercado por lo que invertimos mucho en crear productos de calidad que nuestras Pymes respeten y valoren.
Nos damos el tiempo para pensar fuera de la caja y volver con propuestas innovadoras. Estamos aquí para cambiar la industria!
¿Qué estamos buscando? 
En Xepelin estamos buscando personas creativas y visionarias que piensen fuera de la caja para sumarse a nuestro equipo. Si te apasiona resolver desafíos interesantes de alto impacto y quieres ser parte de un entorno dinámico que está transformando la industria financiera, ¡Esta oportunidad es para ti!
El rol se integrará a nuestro equipo de 
Data Platform
. Si te motiva el desafío de construir soluciones innovadoras en un entorno de rápido cambio, queremos conocerte.
Unete a nosotros, crezcamos juntos!
Principales responsabilidades...
-  Diseñar, crear y mantener pipelines de datos
-  Mantener y optimizar la infraestructura de datos necesaria para una extracción precisa, transformación y carga de datos de una amplia variedad de fuentes de datos
-  Automatizar los flujos de trabajo de datos, como la ingesta de datos, la agregación y el procesamiento de ETL o ELT
-  Preparar datos sin procesar en almacenes de datos en un conjunto de datos consumibles para fines técnicos y partes interesadas no técnicas
-  Crear, mantener e implementar productos de datos para equipos de análisis y ciencia de datos en Plataformas en la nube, preferentemente en GCP, y/o AWS
-  Desarrollar sistemas y arquitectura que soporten las diferentes etapas del flujo de Machine Learning
¿Qué necesitas para brillar?
- Conocimientos en alguna Nube, preferentemente GCP o AWS (en ese orden de preferencia)
- Conocimientos intermedio/avanzado en Python
- Conocimiento intermedio/avanzado de SQL
- Experiencia trabajando almacenamiento en la nube como GCS o AWS S3
- Experiencia desplegando aplicaciones en ambientes serverless como Cloud Functions o AWS Lambda
- Conocimientos administrando y desplegando algún orquestador, por ejemplo: Dagster, Apache Airflow, Prefect, etc
- Excelentes habilidades para trabajar en equipo. Ser humilde y saber colaborar, un Team Player!
- Saber escuchar a tus stakeholders y poder traducir eso en requerimientos y ejecutarlos con tu equipo
- Trabajo proactivo y responsable
- Conocimientos en DBT
- Conocimientos y manejo de lenguajes de programación y/o frameworks, NodeJS, Golang, por ejemplo
- Experiencia en MLOps
- No tener miedo a tomar decisiones y liderar proyectos
- Foco en impacto e historia consistente entregando resultados para usuarios y el negocio
- Capacidad para pensar en grande y desarrollar iniciativas con impacto real y medible
- Te sientes cómodo cuestionando el status-quo de los servicios financieros, adaptándose rápidamente a los cambios, y presentando claramente tus ideas y conceptos para debatirlos en equipo
Nuestros Beneficios:
🌴 Xepelin Balance
Vacaciones:
 15 días hábiles. Por cada año que cumplas en Xepelin, te damos un día extra de vacaciones.
Balance days:
 10 días libres adicionales al año, para disfrutar como quieras.
Trabajo híbrido y flexibilidad horaria según el rol. Trabajamos por objetivos.
Beneficios Flexibles: 
Puntos flexibles en tu moneda local al mes para gastar en lo que quieras.
Xepelin Fun:
 Actividades de encuentro financiadas por Xepelin para divertirnos juntos.
🚀 Xepelin Performance & Career
Plataformas de capacitación:
 Convenios con las mejores plataformas, como Reforge, Udemy y DataCamp.
Kit de Bienvenida: 
todo lo que necesitas para comenzar tu viaje en Xepelin 😊
🤝 Xepelin Cares
Cobertura de salud:
 contamos con convenios de salud con proveedores de calidad o reembolsos según el país donde te encuentres.
Post Natal:
 te damos una semana extra de licencia post natal. ¡Nos interesa que estés con tu familia y seres queridos!
Matrimonio plus:
 Lleva tus planes al siguiente nivel, con una gift card y extendiendo tu permiso legal por matrimonio con dos días de regalo por Xepelin.        
            
                            
            ",Not Applicable,Full-time,Information Technology,"Software Development, IT Services and IT Consulting, and Biotechnology Research",GCP
Data Engineer,BC Tecnología,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205297472/,Could not find Job Description,,,,,OTHER
Data Engineer,2Brains,Chile,2025-04-10,https://www.linkedin.com/jobs/view/4205294882/,"2Brains es una empresa dedicada a construir y desarrollar el Futuro Digital de nuestros clientes, con una visión excepcional que radica en la integración sinérgica de estrategia, diseño y tecnología, un tríptico poderoso que impulsa el crecimiento de empresas y disruptores tecnológicos.
Contamos con un nutrido equipo de más de 200 profesionales, verdaderos artífices de la innovación digital. En el corazón de nuestra labor, destacamos como líderes indiscutibles, canalizando años de experiencia hacia la creación de plataformas tecnológicas adaptables y productos digitales de clase mundial.
En 2Brains, no solo somos consultores, somos arquitectos de experiencias digitales. Aspiramos a ir más allá de las expectativas, estableciendo nuevos estándares en la industria. Descubre cómo damos vida a la innovación, cómo convertimos ideas en resultados tangibles y cómo, junto a nosotros, puedes forjar un futuro digital brillante.
 El/la Data Engineer de 2Brains 
Se encarga de participar en el diseño y desarrollo de los nuevos modelos de información de gestión y las mantenciones evolutivas de los existentes. Participar en las iniciativas de Analítica avanzada del área, apoyando las exploración de modelos de información internos y externos (Data Discovery). Obtener datos históricos desde múltiples fuentes de información interna para apoyar las iniciativas de analítica avanzada del equipo.
El/la Data Engineer de 2Brains debe
- Construir y optimizar pipelines de datos para la ingesta, transformación y carga eficiente de información.
- Manejar infraestructuras en la nube (AWS, GCP, Azure), asegurando escalabilidad y eficiencia en costos.
- Automatizar y monitorear procesos mediante herramientas de DevOps como Airflow, Terraform o Kubernetes.
- Implementar controles de calidad y gobernanza para garantizar la integridad y disponibilidad de los datos.
- Colaborar con equipos de Data Science, Producto y Desarrollo para diseñar soluciones alineadas con las necesidades del negocio.
 Qué conocimientos buscamos en/la Data Engineer
- Excluyente Experiencia trabajando con tecnologías de BI
- Experiencia en la construcción/operación de sistemas distribuidos de extracción, ingestión y procesamiento de grandes conjuntos de datos de gran disponibilidad.
- Capacidad demostrable en modelado de datos, desarrollo de ETL y almacenamiento de datos.
- Experiencia en el uso de herramientas de informes de inteligencia empresarial (Power BI)
- Excluyente conocimiento en consumo de microservicios de APIs Rest
- Excluyente conocimiento en Git , Bitbucket, Docker,Jenkins,Webhooks
- Programación con Python y bases sólidas de ingeniería de software.
- Automatización y scripting.
- Uso de librerías de Python para manipulación y análisis de datos y Apache Spark.
- Conocimientos en bases de datos SQL y NoSQL.
- Conocimiento en CI/CD, Dataflow
- Conocimiento en S3, Redshift y Glue AWS
 Que competencias buscamos en/la Data Engineer 
- Empatía
- Buena capacidad de comunicación.
- Colaboración y trabajo en equipo.
- Proactividad.
- Autonomía.
- Foco en los objetivos de proyectos.
 Condiciones
Trabajar con un equipo de alto rendimiento, aprendemos y nos desarrollamos juntos
Acceso a grandes clientes y proyectos desafiantes
Aprendizaje y crecimiento permanente, organizamos meetups, capacitaciones y actividades culturales
Un entorno de trabajo flexible y dinámico
Beneficios especiales: día libre para tu cumpleaños, días de descanso a convenir.
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",OTHER
Data Engineer,Falabella,"Santiago, Santiago Metropolitan Region, Chile",2025-04-11,https://www.linkedin.com/jobs/view/4207045620/,"Descripción Empresa
Somos más de 80 mil personas que cada día trabajamos por el firme Propósito - Simplificar y Disfrutar más la Vida. Estamos presentes en 9 países y compuestos por grandes marcas posicionadas de diversas industrias. Falabella Retail, Sodimac, Banco Falabella, Tottus, Mallplaza, Falabella.com, Falabella Inmobiliario. Cada una de éstas nos hace ser quienes somos, y es entre todos, como Un Solo Equipo, que buscamos diariamente reinventarnos y superar las experiencias de nuestros clientes.
Si eres trabajador de Falabella, revisa todos los cursos disponibles en la Academia Falabella, que te ayudarán a seguir impulsando tu desarrollo y preparar tu próxima aventura con nosotros!
SOMOS UNA EMPRESA QUE APOYA LA LEY 21015, APOYAMOS LA DIVERSIDAD Y LA INCLUSIÓN EN TODAS SUS FORMAS, SIN IMPORTAR RELIGIÓN, RAZA, GÉNERO, SITUACIÓN DE DISCAPACIDAD, NACIONALIDAD.
Funciones Del Cargo
¡Si tienes una mente inquieta y te gusta soñar en grande, este llamado es para ti!
En Falabella Retail buscamos a nuestro/a próximo/a Data Engineer, con base en Santiago, Chile.
Somos Falabella, UN equipo diverso con más de 100 mil colaboradores compuesto por grandes marcas: Falabella Retail, Sodimac, Banco Falabella, Seguros Falabella, Tottus, Mallplaza, Open Plaza y Linio. Hoy tenemos presencia en 7 países de América Latina, además de oficinas en China e India.
¿Cuál es el principal objetivo del cargo?
Liderar la construcción y mantención de estructuras de datos, así como la arquitectura tecnológica requerida para el procesamiento de apps.
¿Qué harás en el día a día?
-  Desarrollo, implementación de procesos ETL.
-  Levantamiento de requerimientos funcionales y técnicos relacionados con los clientes internos.
-  Implementar modelos de datos automatizados para transformar datos de acuerdo a los requisitos del negocio.
-  Migración de datos desde entornos on-premise a entornos Cloud.
-  Trabajar con tecnologías Google Cloud Platform (Big Query).
¿Qué necesitas para postular?
-  Profesional: Ingeniería Civil en Computación, Informática, Sistemas o carrera afín.
-  Conocimiento en SQL (excluyente)
-  Sólidos conocimientos en Google Cloud Platform (excluyente)
-  Conocimiento avanzado en Python (excluyente)
-  Conocimiento y experiencia trabajando en GIT (excluyente)
-  Disponibilidad para ir a la oficina al menos 2 veces por semana (Las Condes) (excluyente)
En Nuestro Equipo Encontrarás
-  Espacios para crear e innovar.
-  Serás parte de un lugar lleno de oportunidades de desarrollo.
-  Tener un trabajo con sentido y donde se promueve la calidad de vida.
-  Participar en voluntariados.
-  ¡Pertenecer a una empresa llena de energía!
Si disfrutas nuevos desafíos con alta responsabilidad y exposición en el epicentro de la transformación del retail en Latinoamérica, ¡súmate a trabajar con nosotros!
Somos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusión en todas sus formas, sin importar religión, raza, género, situación de discapacidad, nacionalidad.
Requisitos
- Profesional: Ingeniería Civil en Computación, Informática, Sistemas o carrera afín.
- Conocimiento en SQL (excluyente)
- Sólidos conocimientos en Google Cloud Platform (excluyente)
- Conocimiento avanzado en Python (excluyente)
- Conocimiento y experiencia trabajando en GIT (excluyente)
- Disponibilidad para ir a la oficina al menos 2 veces por semana (Las Condes) (excluyente)
Condiciones Oferta
Descripción proceso de selección:
El proceso de selección se realiza a través de Aira - plataforma de reclutamiento diseñado para mejorar tu experiencia de postulación.
Para Postular Solo Necesitas
-  Postular a la oferta
-  Revisar tu email
-  Ingresar a Aira y contestar las preguntas y/o pruebas solicitadas
Luego, si vemos que tu perfil se ajusta a lo que estamos buscando, te contactaremos por email (a través de Aira) para seguir a la etapa presencial.
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,Retail,GCP
Data Engineer,NeuralWorks,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205500303/,"NeuralWorks es una compañía de alto crecimiento fundada hace 3 años. Estamos trabajando a toda máquina en cosas que darán que hablar.
Somos un equipo donde se unen la creatividad, curiosidad y la pasión por hacer las cosas bien. Nos arriesgamos a explorar fronteras donde otros no llegan: un modelo predictor basado en monte carlo, una red convolucional para detección de caras, un sensor de posición bluetooth, la recreación de un espacio acústico usando finite impulse response.
Estos son solo algunos de los desafíos, donde aprendemos, exploramos y nos complementamos como equipo para lograr cosas impensadas.
Trabajamos en proyectos propios y apoyamos a corporaciones en partnerships donde codo a codo combinamos conocimiento con creatividad, donde imaginamos, diseñamos y creamos productos digitales capaces de cautivar y crear impacto.
👉 Conoce más sobre nosotros
 Descripción del trabajo
El equipo de Data y Analytics trabaja en diferentes proyectos que combinan volúmenes de datos enormes e IA, como detectar y predecir fallas antes que ocurran, optimizar pricing, personalizar la experiencia del cliente, optimizar uso de combustible, detectar caras y objetos usando visión por computador.
Dentro del equipo multidisciplinario con Data Scientist, Translators, DevOps, Data Architect, tu rol será clave en construir y proveer los sistemas e infraestructura que permiten el desarrollo de estos servicios, formando los cimientos sobre los cuales se construyen los modelos que permiten generar impacto, con servicios que deben escalar, con altísima disponibilidad y tolerantes a fallas, en otras palabras, que funcionen. Además, mantendrás tu mirada en los indicadores de capacidad y performance de los sistemas.
En cualquier proyecto que trabajes, esperamos que tengas un gran espíritu de colaboración, pasión por la innovación y el código y una mentalidad de automatización antes que procesos manuales.
Como Data Engineer, Tu Trabajo Consistirá En
- Participar activamente durante el ciclo de vida del software, desde inception, diseño, deploy, operación y mejora.
- Apoyar a los equipos de desarrollo en actividades de diseño y consultoría, desarrollando software, frameworks y capacity planning.
- Desarrollar y mantener arquitecturas de datos, pipelines, templates y estándares.
- Conectarse a través de API a otros sistemas (Python)
- Manejar y monitorear el desempeño de infraestructura y aplicaciones.
- Asegurar la escalabilidad y resiliencia.
 Calificaciones clave
- Estudios de Ingeniería Civil en Computación o similar.
- Experiencia práctica de al menos 3 años en entornos de trabajo como Data Engineer, Software Engineer entre otros.
- Experiencia con Python. Entendimiento de estructuras de datos con habilidades analíticas relacionadas con el trabajo con conjuntos de datos no estructurados, conocimiento avanzado de SQL, incluida optimización de consultas.
- Pasión en problemáticas de procesamiento de datos.
- Experiencia con servidores cloud (GCP, AWS o Azure), especialmente el conjunto de servicios de procesamiento de datos.
- Buen manejo de inglés, sobre todo en lectura donde debes ser capaz de leer un paper, artículos o documentación de forma constante.
- Habilidades de comunicación y trabajo colaborativo.
¡En NeuralWorks nos importa la diversidad! Creemos firmemente en la creación de un ambiente laboral inclusivo, diverso y equitativo. Reconocemos y celebramos la diversidad en todas sus formas y estamos comprometidos a ofrecer igualdad de oportunidades para todos los candidatos.
“Los hombres postulan a un cargo cuando cumplen el 60% de las calificaciones, pero las mujeres sólo si cumplen el 100%.” D. Gaucher , J. Friesen and A. C. Kay, Journal of Personality and Social Psychology, 2011.
Te invitamos a postular aunque no cumplas con todos los requisitos.
 Nice to have
- Agilidad para visualizar posibles mejoras, problemas y soluciones en Arquitecturas.
- Experiencia en Infrastructure as code, observabilidad y monitoreo.
- Experiencia en la construcción y optimización de data pipelines, colas de mensajes y arquitecturas big data altamente escalables.
- Experiencia en procesamiento distribuido utilizando servicios cloud.
 Beneficios
- MacBook Air M2 o similar (con opción de compra hiper conveniente)
- Bono por desempeño
- Bono de almuerzo mensual y almuerzo de equipo los viernes
- Seguro complementario de salud y dental
- Horario flexible
- Flexibilidad entre oficina y home office
- Medio día libre el día de tu cumpleaños
- Financiamiento de certificaciones
- Inscripción en Coursera con plan de entrenamiento a medida
- Estacionamiento de bicicletas
- Vestimenta informal
- Programa de referidos
- Salida de “teambuilding” mensual        
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",OTHER
Ingeniero de Datos,Devaid,Chile,2025-04-10,https://www.linkedin.com/jobs/view/4205299283/,"En Devaid> nos apasionan los desafíos tecnológicos y nuestros clientes lo saben. Por lo anterior, nos plantean problemáticas que nos obligan a estar constantemente probando e implementando nuevas tecnologías.
Trabajamos fuertemente en la nube ya que somos Partner Premier de Google Cloud en Chile, por lo que tendrás la oportunidad de formarte como un profesional cloud.
Dependiendo de las necesidades del cliente, ofrece soluciones web, móviles, integración de sistemas, entre otros. Esto permite acceder a la herramienta sin importar el dispositivo ni el lugar dónde se encuentra. Permitimos el trabajo colaborativo entre múltiples usuarios manteniendo una base centralizada de información.
 Funciones del cargo
Esperamos Que Puedas Desempeñarte En Las Siguientes Actividades
- Creación de pipelines de carga y transformación de datos.
- Modelamiento de datos y creación de Data Warehouse y Data Lakes.
- Integración de sistemas.
- Creación de modelos de machine learning con herramientas low code autoML.
Vas a participar como ingeniero de datos en equipos de consultores que prestan servicios a empresas importantes en Chile. En estos equipos participan distintos perfiles, tales como desarrolladores de software, arquitectos de datos y data scientists. Los servicios se prestan de forma remota y son prestados por proyecto (no es outsourcing de recursos), por lo que puedes trabajar desde tu casa sin problemas. Diariamente vas a tener reuniones con tu equipo para coordinar actividades y resolver temas complejos que vayan surgiendo.
 Requerimientos del cargo
Los requisitos para un buen desempeño de las funciones son:
- 1 año de experiencia como Data Engineer. 
- Programación en lenguaje Python, NodeJS o Java (al menos uno de los 3). 
- Conocimiento de soluciones de Data Warehouse y ETL. 
- Conocimiento de plataformas de procesamiento de datos como Apache Spark, Dataflow o similares. 
- Haber trabajado previamente con alguna nube pública (AWS, Azure o GCP).
Si no cumples alguno de estos puntos no te desanimes, queremos conocerte igualmente.
El trabajo es 100% remoto, pero es necesario que tengas RUT y/o papeles al día en Chile.
 Deseables
Suman puntos en tu postulación si cumples alguna de las siguientes habilidades, ninguno de estos son excluyentes:
- Conocimiento de herramientas Google Cloud, entre ellas Google BigQuery, Dataflow, Data Fusion y Pub Sub. 
- Experiencia en plataformas de deployment de infraestructura como Terraform. 
- Experiencia utilizando la herramienta de consola gcloud. 
 Beneficios
Prometemos un ambiente muy grato de trabajo, lleno de desafíos y donde podrás ver los proyectos en los que estas involucrada/o siendo utilizados en un corto tiempo activamente por nuestros clientes, lo que siempre es muy gratificante.
Otras Actividades
- Actividades mensuales (Cupones de Food delivery, juegos en línea, actividades grupales).
- Actividad paseo anual: La empresa se junta por 2 días en algún lugar turístico para realizar actividades grupales y unir al equipo.
- Día libre flexible en tu cumpleaños.
- Capacitaciones en lo que más te guste.
- Certificaciones Google Cloud: Programa de certificación en distintas ramas profesionales de GCP, gracias a que somos Partner Premier de Google Cloud en Chile.        
            
                            
            ",Entry level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",GCP
Data Engineer (GCP & DataFlow & Bigquery),Option,Santiago Metropolitan Area,2025-04-12,https://www.linkedin.com/jobs/view/4208792219/,"¿Quiénes somos?
En 
Option
, creemos en un mundo donde las soluciones tecnológicas no tienen límites. Nuestra misión es transformar los desafíos en oportunidades mediante la creación de soluciones innovadoras que potencien la Aceleración Digital. Nuestro equipo es dinámico, colaborativo y apasionado por la tecnología. Únete a una organización que está redefiniendo cómo el mundo utiliza los datos y la tecnología para resolver problemas complejos.
¿Qué buscamos?
Estamos en la búsqueda de un/a 
Ingeniero/a de Datos
 para unirse al equipo de Data Services. Este rol será clave en el levantamiento, análisis y migración de procesos ETL desde un Data Lake mal gobernado hacia una arquitectura moderna sobre Google Cloud Platform (GCP). ¡Te estamos buscando!
¿Qué te ofrece este puesto?
- Participación en un proceso estratégico de migración a la nube.
- Un entorno de trabajo colaborativo y con líderes técnicos accesibles.
- Uso de tecnologías modernas como GCP, Dataflow y BigQuery.
- Trabajo conjunto con equipos de analítica, desarrollo y operación.
¿Cuáles serán tus principales responsabilidades?
- Levantar y documentar los ETLs actuales en Data Services.
- Analizar el ambiente de datos y planificar su migración a GCP.
- Tomar iniciativa en la migración de ETLs críticos.
- Resolver incidencias relacionadas a ETLs mediante la mesa de ayuda.
- Participar en el diseño del plan de migración.
- Colaborar con los líderes técnicos y equipos multidisciplinarios.
¿Qué necesitas para ser nuestro próximo Ingeniero de Datos?
Habilidades Técnicas Excluyentes
- Oracle
- Python
- Dataflow (GCP)
- Dataform (GCP)
- GitLab
- BigQuery (GCP)
- Data Modeling
- Composer (GCP)
Habilidades Técnicas Deseables
- Oracle Data Integrator (ODI)
Ubicación: LATAM
Modalidad de trabajo:
 100% Remoto
¡Únete a nuestro equipo y transforma el futuro con nosotros!
https://www.option.tech        
            
                            
            ",Entry level,Full-time,Information Technology,Information Technology & Services,GCP
Data Engineer,ICONSTRUYE,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205295718/,"En ICONSTRUYE, hemos estado a la vanguardia de la tecnología en la construcción durante más de 20 años. Nuestra robusta plataforma tecnológica es un testimonio de nuestra experiencia y compromiso con la industria. Con más de 4,000 clientes en Chile, Colombia y Perú, nos enorgullecemos de proporcionar soluciones integrales que simplifican la cadena de abastecimiento. Buscamos un Ingeniero de Datos que se una a nosotros en la transformación de la industria de la construcción, siendo el puente entre los datos brutos y aquellos que toman decisiones críticas.
Tus Funciones Principales
Tu misión:
 Ser el puente entre los datos brutos y quienes necesitan realizar análisis y/o tomar decisiones con esos datos.
- Garantizar la calidad, integridad y seguridad de los datos.
- Colaborar con diversos stakeholders para comprender sus necesidades de datos.
- Desarrollar procesos de extracción, transformación y carga (ETL) de datos para nuestro data lake, proporcionando información valiosa para el análisis y toma de decisiones.
- Implementar nuevas bases de datos y/o data warehouses para satisfacer las necesidades de la empresa.
- Contribuir a la definición de políticas de gobernanza de datos.
- Ser una autoridad en la creación, implementación y operación de soluciones escalables y de bajo costo, facilitando el flujo de datos desde sistemas de producción hasta el data lake.
Requerimientos Técnicos
- Dominio de Python o Go. 
- Dominio de SQL. 
- Conocimiento de base de datos relacionales y no relacionales (NoSQL). 
- Conocimiento de AirFlow, Luigi, Dagster. 
- Conocimientos de Kafka y/o RabbitMQ. 
- Conocimiento en Docker y Kubernetes. 
Beneficios Que Ofrecemos
- 🌴 5 días extras de descanso al año.
- 🍔 Tarjeta amipass para utilizar en restaurantes, delivery y supermercados.
- 👨‍⚕️ Seguro complementario de salud, dental y de vida.
- 🏠 Modalidad de trabajo híbrido.
- 📠 Flexibilidad con permisos para trámites y asuntos familiares.
- 👩‍👦 Jornada reducida en días de vacaciones escolares (viernes medio día).
- 🎂 Tarde libre en tu cumpleaños.
¡Únete a nosotros y sé parte de nuestra misión de transformar la industria de la construcción!
                
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",OTHER
Ingeniero de Datos ($1.400.000 líquidos),Vector,"Santiago, Santiago Metropolitan Region, Chile",2025-04-07,https://www.linkedin.com/jobs/view/4203857279/,"Somos una empresa Líder en el rubro TI. Nos encontramos en la búsqueda de Ingeniero de Datos, con experiencia en extracción de datos desde los sistemas fuente de estándares industriales y eléctricos y su almacenaje en los destinos correspondientes, así como también el asegurar la continuidad del funcionamiento de aplicaciones y redes OT que proporcionan datos a PMAC y ROCC.
Principales Tareas
- Sistematizar el traspaso de datos desde los distintos sistemas de la compañía hacia los repositorios correspondientes para su consumo.
- Participar en proyectos y entregar soluciones técnicas, procesos y requisitos.
- Enfoque en la creación de indicadores y KPI relevantes de las diferentes aplicaciones para reportar a nivel técnico y administrativo.
- Realizar revisiones continuas de monitoreo para asegurarse de la continuidad del servicio.
- Monitorear y controlar solicitudes y requerimientos de soporte (gestión de tickets).
- Gestionar cualquier proceso de solicitud de cambio, asegurándose de que todas las solicitudes estén debidamente documentadas y rastreadas. 
- Entregar soporte para que los servicios de OT se entreguen de acuerdo con los procedimientos operativos estándar y/o SLAs acordados; con enfoque en el servicio operativo, resolución de problemas y respuesta ágil para el usuario final.
- Escalar consultas complejas a la organización de soporte especializado correspondiente.
- Identificar oportunidades de mejora del servicio a partir del análisis de tendencias de datos y las necesidades y aportes de los clientes/usuarios.
- Involucrarse con stakeholders clave y para comprender sus requisitos y transmitir al área de resolución correspondiente. 
Conocimientos y experiencia 
- Estudios técnicos o profesionales en Telecomunicaciones, Instrumentación, Sistemas, Computación, Informática, Electrónica o carreras afines).
- Instrumentista con conocimiento en programación y transferencia de datos, o Ingeniero de Datos con conocimiento en protocolos industriales y sus estándares de comunicación.
- Conocimientos de redes de comunicaciones y soluciones de transporte de datos.
- Gestión de datos y visualización usando herramientas cloud (Google, Microsoft).
- Conocimientos de un lenguaje de scripting, preferiblemente Python.
- Manejo básico de base de datos SQL.
- Conocimientos básicos en gestión de accesos e identidades.
- Conocimientos básicos en administración de servidores.
- Experiencia laboral de 5 años preferiblemente en empresas industriales.
- Deseable manejo de ingles a nivel técnico intermedio.
Conocimientos específicos
- Conocimiento de protocolos industriales del sector eléctrico (IEC-60870-5-104, Modbus, DNP 3.0).
- Protocolos Industriales de comunicación: Modbus TCP/IP, JSON, CSV, DNP3, SQL.
- Conocimiento de sistemas SCADA.
- Conocimientos de protocolos de transición con industria 4.0 (Modbus TCP, OPC UA, MQTT, HTTP, etc.).
Fundamentos de ciberseguridad.
Horario
Lunes a viernes 08:00 a 18:00 / 08:30 a 18:30
Beneficios
-  Reajuste anual de sueldo de acuerdo a IPC
-  Bonificación anual por desempeño laboral.
-  Posibilidad de acceder a cursos de capacitación en las diversas temáticas del cargo.
-  Convenios de Salud, Dentales y ópticos, accesos a descuentos preferenciales y facilidades de pagos mediante descuentos por planilla sin interés.
-  Posibilidad de entrega de aguinaldo de fiestas patrias y Navidad conforme a cumplimiento de antigüedad.
-  Convenio seguro Oncológico a valor preferencial y con aporte de la organización y del colaborador.
-  Regalo de gift card por nacimiento de hijo (a).
-  Convenios bancarios (scotiabank y Banco de Chile) para planes de tarjetas de cuentas vista y corriente a valores preferenciales.        
            
                            
            ",Not Applicable,Contract,Information Technology,Information Technology & Services,OTHER
Data Engineer Soluciones de Datos,LISIT,"Biobío Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205294845/,"En *Lisit*, nos dedicamos a crear, desarrollar e implementar servicios de software que ofrecen herramientas de automatización y optimización. Nuestra misión es promover la eficacia en la operatividad de nuestros clientes a través de un soporte consultivo que integra diversas herramientas y prácticas. Buscamos contribuir al éxito de las transformaciones empresariales mediante estrategias integrales de acompañamiento e implementación.
 Que estamos buscando
- Diseñar, desarrollar y mantener infraestructuras y pipelines de datos escalables y confiables.
- Optimizar el almacenamiento, procesamiento y recuperación de datos para un funcionamiento eficiente e impecable.
- Colaborar con equipos de diferentes departamentos para recopilar y analizar los requisitos de datos.
- Garantizar la calidad, integridad y seguridad de los datos durante todo el ciclo de vida de estos.
- Mantenerse actualizado sobre los últimos avances, desarrollos y enfoques en ingeniería de datos.
 ¿Qué habilidades y experiencia necesitas?
- Fuertes habilidades analíticas y de resolución de problemas.
- Al menos 3 años de experiencia en ingeniería de datos.
- Experiencia comprobada en el diseño y desarrollo de data pipelines y procesos ETL, preferiblemente con Azure Data Factory.
- Amplia experiencia en SQL y dominio de al menos un lenguaje de ingeniería de datos, como Python o Scala.
- Experiencia con Spark, Airflow y tecnologías Big Data relacionadas.
- Familiaridad con plataformas de datos basadas en la nube como AWS, Azure o GCP.
- Excelentes habilidades de comunicación y colaboración.
 Deseable
Se valorará la experiencia con herramientas de BI como Power BI y Microsoft Fabric. También es deseable contar con alguna de las siguientes certificaciones: DP-203, PL-300, DP-600 y/o DP-700.
 Únete a nosotros
En *Lisit* ofrecemos un ambiente de trabajo innovador y colaborativo. Nos aseguramos de que nuestros empleados disfruten de un equilibrio entre trabajo y vida personal, con programas de capacitación y desarrollo continuo. Valoramos tu entusiasmo y pasión por la ingeniería de datos.
Estamos emocionados por conocer a personas con una mentalidad abierta y dispuestas a enfrentar nuevos desafíos. ¡Si estás listo para innovar y crecer con nosotros, te queremos en nuestro equipo!
En el caso de residir en Santiago, debe tener disponibilidad para viajar una o dos semanas a Los Angeles, región del BioBío
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",AZURE
Data Engineer,Seeds,"Santiago Metropolitan Region, Chile",2025-04-07,https://www.linkedin.com/jobs/view/4189755534/,"¿Sos 
Data Engineer
? Entonces… ¿Qué estás esperando para sumarte a nuestra comunidad de Seeders? ¡Aplica a nuestra comunidad y accede a trabajo on-demand en las empresas líderes, sumate al Present of Work!
¿Quiénes somos?
Somos una 
comunidad
 que reúne al mejor talento on-demand de Latinoamérica, y lo conecta con las empresas líderes de la región. Gestionamos el match perfecto entre las necesidades de las empresas y el talento con las competencias y la experiencia buscada, fomentando flexibilidad y el desarrollo profesional de nuestra comunidad.
No somos una plataforma más de freelancers, Seeds lidera un dream team de profesionales altamente calificados que eligen dónde, cómo y para quién trabajar, disfrutando así de contribuir a una misión más grande, definiendo y moldeando la forma en que trabajamos.
Estamos buscando sumar a nuestro Talent Pool roles de 
Data Engineer
 para nuestra comunidad de Seeders.
Estas son algunas de las responsabilidades usuales del rol:
- Diseñar, construir y mantener arquitecturas de datos robustas y escalables.
- Desarrollar y optimizar pipelines de datos para recopilación, almacenamiento, procesamiento y análisis de grandes volúmenes de datos.
- Implementar modelos de datos y algoritmos para resolver problemas de negocio y proveer insights accionables.
- Trabajar en estrecha colaboración con equipos de data scientists y analistas para apoyar sus requisitos de datos y facilitar el análisis de datos.
- Asegurar la integridad, disponibilidad y confidencialidad de los datos a través de las mejores prácticas de seguridad y gobernanza de datos.
- Mantenerse al día con las últimas tecnologías y tendencias en el campo de la ingeniería de datos.
Requisitos
- Experiencia mínima de 3 años en roles de ingeniería de datos.
- Fuerte dominio de lenguajes de programación como Python, Java o Scala.
- Experiencia trabajando con grandes volúmenes de datos y herramientas de procesamiento de datos (como Hadoop, Spark).
- Conocimientos en bases de datos SQL y NoSQL, así como en soluciones de almacenamiento de datos en la nube (AWS, Google Cloud, Azure).
- Capacidad para trabajar en entornos ágiles y multidisciplinarios.
- Inglés intermedio (deseable).
¿Por qué sumarte a nuestra comunidad de Seeders?
Elegí tus proyectos.
Trabajá desde donde vos quieras.
Eventos de networking.
Asesoramiento personalizado.
Seeds Academy: Potencia tu desarrollo profesional adquiriendo nuevas skills (upskilling & reskilling), participando de webinars, Bootcamps y otras acciones exclusivas para la comunidad.
No dejes de sumarte a nuestra comunidad de Seeds y aplicar a oportunidades de empresas lideres de la región. ¡Te esperamos!        
            
                            
            ",Mid-Senior level,Full-time,Consulting,"Technology, Information and Media",OTHER
Senior Data Engineer Python,23people,Chile,2025-04-10,https://www.linkedin.com/jobs/view/4205294906/,"Únete a Equifax Chile como Senior Data Engineer Python Somos líderes en soluciones de información y tecnología, operando globalmente para transformar el uso de la información con transparencia y seguridad. Estamos en un proyecto de migración clave que requiere revisión de pipelines de datos, creación de queries, diseño de flujos de procesos, análisis de sistemas legados y documentación técnica y de negocio. Valoramos la innovación, la colaboración y el conocimiento técnico. Si tienes habilidades analíticas excepcionales y pasión por la tecnología, ¡aplica hoy y sé parte de nuestra transformación digital!
 Funciones del cargo
¿Qué harás en tu día a día?
El profesional colaborará con un equipo multidisciplinario en un proyecto de expansión internacional, enfocado en la migración estratégica de la plataforma hacia nuevos mercados. Su participación será fundamental para asegurar una implementación eficiente que considere las particularidades de cada país destino, garantizando así el éxito de esta iniciativa global.
Algunas De Sus Tareas Diarias Son Las Siguientes
- Implementar mecanismos para verificar la integridad de los datos migrados
- Implementar transformaciones específicas para requisitos regionales
- Dirigir el equipo técnico durante las fases críticas de migración
- Gestionar el proceso integral de ETL entre diversos sistemas, desarrollando y optimizando los esquemas de mapeo necesarios para garantizar la compatibilidad entre las estructuras de datos de origen y destino.
 Requerimientos del cargo
Skills
Técnicas
- Python
- BigQuery/SQL
- GitHub
- Apache Beam/Spark/Google Dataflow
Personales
- Capacidad de autogestión
- Buenos skills de comunicación
- Fortaleza en trabajo en equipo
- Adaptación al cambio (trabajarán en distintas geos de Latam)
Contrato indefinido desde el inicio con 23people
Modalidad: Home Office, Con residencia en Chile (Deberás ir a buscar el PC en primera instancia)
Experiencia: Desde 5 años en adelante
Horario: Lunes a Jueves de 8:30 a 6:30 y Viernes de 8:30 a 5:30 hrs.
 Deseables
- Perfil Analítico
- UnitTest
- AirFlow
- PySpark
- CI/CD
- Postman
- Jmeter
 Beneficios
Algunos de nuestros beneficios
- Seguro complementario: Seguro de salud, vida y dental
- Curso de inglés: En nuestro programa de formación en idioma inglés, ofrecemos dos modalidades para adaptarnos a tus necesidades y objetivos.
- Reembolso de certificaciones internacionales: Apoyamos el crecimiento profesional, por lo que te reembolsamos el costo de un examen de certificación internacional que quieras realizar.
- Bono de vacaciones: Por cada semana que te tomes de vacaciones te otorgamos una compensación.
- Aguinaldos en fiestas patrias y Navidad: Queremos que en fechas tan especiales la pases bien junto a tu familia, por lo que te entregamos un bono en septiembre y diciembre
- Día libre de cumpleaños: Puedes optar por tomar tu día libre, el día previo a tu cumpleaños, el mismo día de tu cumpleaños o el día posterior.        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",GCP
Ingeniero de Datos/ Dbt,BC Tecnología,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205500332/,"En BC Tecnología, somos una consultora de TI con más de seis años de experiencia, especializada en ofrecer soluciones personalizadas para nuestros clientes en sectores como servicios financieros, seguros, retail y gobierno. Nos enfocamos en consultoría, outsourcing, desarrollo de proyectos y formación de equipos, siempre con un claro compromiso hacia la satisfacción del cliente. Como parte de nuestro equipo, el ingeniero/a de datos jugará un papel clave en la creación de soluciones basadas en tecnologías de la nube, impulsando la innovación y la colaboración en un entorno de trabajo ágil.
 Responsabilidades Clave
El Ingeniero/a De Datos Será Responsable De
- Diseñar y mantener pipelines de datos utilizando BigQuery y DBT.
- Implementar tareas programadas en Google Cloud Platform (GCP) para la ingesta y procesamiento continuo de datos.
- Construir y documentar modelos de datos optimizados para su análisis.
- Validar y realizar pruebas para garantizar la precisión de los datos transformados.
- Realizar seguimiento y documentación de cambios en modelos y sus transformaciones.
 Requisitos Técnicos
Buscamos Un Ingeniero/a De Datos Con
- Experiencia avanzada en BigQuery y DBT.
- Conocimiento práctico en Google Cloud Platform, incluyendo la programación de tareas y almacenamiento.
- Sólido manejo de SQL y experiencia en modelado de datos.
- Capacidad para documentar procesos y realizar pruebas de calidad de datos de manera eficiente.
 Lo que ofrecemos
Brindamos un contrato por proyecto de 12 meses en modalidad híbrida, lo que permite combinar trabajo remoto con visitas a la oficina 2 a 3 días a la semana. También garantizamos un enfoque en la inclusión, en cumplimiento con la Ley Nº 21.015, promoviendo un entorno donde todos los empleados puedan prosperar.
 Beneficios        
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",GCP
Ingeniero de Datos Maestros (Proyecto Corporativo),Agrosuper,"Rancagua, O'Higgins Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205297494/,"En Agrosuper, tenemos la misión de llevar alimentos de la más alta calidad a las familias de Chile y el mundo. Nos mueve el deseo de alimentar el talento y las ganas de crecer constantemente. Buscamos mejorar y fomentar un entorno donde todos disfruten lo bueno de la vida, por lo que valoramos a las personas, que son el alma de nuestra organización. Este cargo de Ingeniero de Datos Maestros (Corporativo) es fundamental para garantizar la calidad y disponibilidad de nuestros Datos Maestros a través de la optimización de procesos y recursos en nuestras unidades de negocio.
 Principales Funciones
- Gestionar los Datos Maestros en diversos Proyectos Corporativos.
- Identificar y proponer mejoras, optimizando y eficientando nuestros procesos internos.
- Gestionar la creación de códigos de distintos Datos Maestros considerados críticos por la Organización.
- Definir y configurar en SAP Estrategias de Liberación (Compras).
- Validar y autorizar Órdenes de Transportes Customizing en SAP.
- Validar estándares de los Datos Maestros en SAP.
- Evaluar y desarrollar parametrizaciones técnicas de Customizing alrededor de los Datos Maestros en SAP.
- Asesorar al Equipo de Datos Maestros sobre dudas y buenas prácticas en el Gobierno de Datos Maestros.
 Requisitos
- Título profesional en áreas como Ingeniería Civil Industrial, Comercial, Informática o similar.
- Experiencia laboral mínima de 2 años en roles similares.
- Experiencia en SAP, específicamente en Gobierno de Datos Maestros (certificado).
- Conocimientos en herramientas de análisis y visualización, especialmente en Excel a nivel avanzado.
Desirable Skills
Si bien los requisitos mencionados son fundamentales, también valoramos habilidades adicionales que pueden enriquecer la experiencia en este rol. Esto incluye certificaciones adicionales en SAP, experiencia en gestión de proyectos y habilidades en liderazgo y trabajo en equipo. Además, el deseo de mantenerse al día con las tendencias en tecnología y análisis de datos será considerado un gran plus.
 Beneficios
Agrosuper ofrece un entorno de trabajo inspirador donde se valora el crecimiento tanto profesional como personal. Contamos con planes de crecimiento y desarrollo, capacitación continua y becas de estudios, además de convenios con distintas instituciones. También ofrecemos bonos asociados al desempeño para incentivar el trabajo de nuestros colaboradores. Además, promovemos la inclusión de colaboradores con discapacidad, asegurando que todos tengan la oportunidad de contribuir a nuestro propósito de alimentar lo bueno de la vida.
                
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",OTHER
Ingeniero de Datos,AyCA SpA,"Santiago, Santiago Metropolitan Region, Chile",2025-04-11,https://www.linkedin.com/jobs/view/4206696535/,"Company Description: AyCA Spa
Job Description: En AyCA SPA nos encontramos en búsqueda de un Ingeniero de Datos.
Propósito o Misión del Cargo
El Ingeniero de Datos en Mantenimiento de Planta es responsable de diseñar, implementar y gestionar la infraestructura de datos y los sistemas de análisis necesarios para optimizar las estrategias y procesos de mantenimiento. Su rol principal es transformar los datos generados por los equipos, sistemas de monitoreo y actividades de mantenimiento en información valiosa y accionable que permita mejorar la confiabilidad de los activos, reducir costos, predecir fallas y optimizar la planificación de las intervenciones.
Principales Responsabilidades
-  Diseño e Implementación de la Arquitectura de Datos
-  Colaborar con el equipo de mantenimiento y TI para comprender las necesidades de datos y diseñar una arquitectura robusta y escalable para la recopilación, almacenamiento, procesamiento y análisis de datos de mantenimiento.
-  Seleccionar e implementar las herramientas y tecnologías adecuadas para la gestión de datos (bases de datos, data lakes, plataformas de procesamiento en la nube, etc.).
-  Establecer y mantener los procesos de extracción, transformación y carga (ETL/ELT) de datos desde diversas fuentes (CMMS, sensores IoT, registros manuales, etc.).
-  Integración de sistemas SCADA y PLCs con tecnologías cloud (OPC UA, MQTT, REST APIs)
-  Garantizar la calidad, integridad y seguridad de los datos de mantenimiento.
-  Desarrollo de Soluciones de Análisis y Reporte
-  Desarrollar modelos de datos y esquemas que faciliten el análisis y la generación de insights relevantes para el mantenimiento.
-  Crear dashboards, informes y visualizaciones interactivas que permitan al equipo de mantenimiento monitorear KPIs, identificar tendencias, evaluar la efectividad de las estrategias y tomar decisiones informadas.
-  Implementar técnicas de análisis predictivo (machine learning, inteligencia artificial) para predecir fallas de equipos, optimizar la planificación de mantenimiento preventivo y proactivo.
-  Automatizar la generación de informes y alertas para facilitar la toma de decisiones en tiempo real.
-  Diseñar e implementar flujos de procesamiento de datos industriales.
-  Construir y entrenar modelos de ML para detección de fallas y patrones de operación.
-  Diseñar estrategias para la optimización y escalabilidad del sistema de IA.
-  Integrar modelos de IA con bases de datos y sistemas de control industriales.
-  Asegurar la seguridad y confiabilidad del sistema en entornos industriales.
-  Soporte y Optimización de Sistemas de Datos
-  Monitorear y mantener el rendimiento y la disponibilidad de la infraestructura de datos de mantenimiento.
-  Identificar y resolver problemas relacionados con la calidad, integridad y flujo de datos.
-  Optimizar los procesos de ETL/ELT y las consultas de datos para mejorar la eficiencia del análisis.
-  Mantener la documentación técnica de la arquitectura de datos, los procesos y las soluciones implementadas.
-  Colaboración y Comunicación
-  Trabajar en estrecha colaboración con el equipo de mantenimiento (planificadores, supervisores, técnicos), el departamento de TI y otros stakeholders para comprender sus necesidades de datos y ofrecer soluciones efectivas.
-  Comunicar de manera clara y concisa los hallazgos del análisis de datos y las recomendaciones al equipo de mantenimiento y la gerencia.
-  Participar en reuniones y proyectos relacionados con la mejora continua y la transformación digital del área de mantenimiento.
-  Capacitar al personal de mantenimiento en el uso de las herramientas y los informes de análisis de datos.
-  Documentar procesos y modelos.
-  Investigación y Desarrollo
-  Mantenerse actualizado sobre las últimas tendencias y tecnologías en el campo del análisis de datos, la inteligencia artificial y el mantenimiento predictivo.
-  Investigar y proponer nuevas herramientas y técnicas que puedan mejorar la eficiencia y efectividad del mantenimiento basado en datos.
-  Participar en proyectos piloto para la implementación de nuevas soluciones de análisis.
Requisitos
-  Título profesional en Ingeniería (Informática, Industrial, Mecánica, Eléctrica o carreras afines) con especialización o experiencia en análisis de datos, ciencia de datos o gestión de información.
Experiencia
-  Plataformas de nube pública: AWS (IoT Core, Lambda, S3), Azure (IoT Hub, Functions) o Google Cloud (Pub/Sub, Firestore).
-  Diseño o implementación de dashboards para visualización de datos industriales (Power BI, Grafana, etc.).
-  Haber desarrollado proyectos similares, ya sea como profesional o estudiante (tesis).
-  Experiencia en el desarrollo de modelos de Machine Learning.
-  Experiencia práctica con Python, pandas, scikit-learn, TensorFlow, XGBoost o similares.
-  Experiencia en arquitectura de datos: bases SQL, ETL, APIs.
-  Conocimientos en integración de sistemas industriales mediante APIs REST, OPC-UA o MQTT.
-  Capacidad para diseñar arquitecturas escalables y eficientes.
-  Conocimiento en ciberseguridad industrial.
-  Familiaridad con software industriales.
-  Experiencia en desarrollo de aplicaciones para entornos industriales.
Si crees que cumples con las competencias envíanos tu CV indicando pretensiones de renta y disponibilidad.
Ayúdanos a compartir para llegar a mas personas !!
                
            
                            
            ",Entry level,Full-time,Information Technology,Mining,OTHER
Data Engineer AWS – Contrato Indefinido.,BC Tecnología,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4204878459/,"Company Description: BC Tecnología
Job Description: Experiencia de 3 años en:
-  Explotación de datos (Tunnig)
-  ETL
-  SQL
-  Python
-  Apache Airflow (Deseable)
-  AWS (Glue, Lambda, S3, Redshift, Dynamodb
-  Trabajo Hibrido
Interesados o referidos favor enviar cv actualizado a [email] indicando en asunto de e-mail cargo al cual postula (Data Engineer AWS)
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,Information Technology & Services,AWS
Data Engineer – Proyecto de 6 Meses,BC Tecnología,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205297473/,"En BC Tecnología, somos una consultora de TI comprometida con ofrecer soluciones innovadoras y adaptadas a las necesidades de nuestros clientes. Con más de 6 años de experiencia en el sector, trabajamos con empresas en diferentes industrias, incluyendo servicios financieros, seguros, retail y gobierno. En este proyecto de Data Engineering, tendrás la oportunidad de contribuir al diseño y construcción de pipelines de datos para nuestros clientes, utilizando metodologías ágiles y colaborando con equipos altamente especializados.
 Responsabilidades del Rol
- Diseñar y construir pipelines de datos efectivos para cumplimentar las necesidades analíticas de nuestros clientes.
- Programar usando lenguajes como Python, Scala o SQL para manipulación y transformación de datos.
- Implementar y gestionar herramientas de orquestación de pipelines, como Airflow, Mage, NiFi o similares.
- Colaborar en prácticas de CI/CD, incluidos conocimientos básicos en Git y versionado de código.
- Integrar arquitecturas de datos, con un enfoque en Datalakes, Datawarehouses o Lakehouse.
- Participar en modelado de datos utilizando técnicas dimensional, estrella y copo de nieve, si es requerido.
 Requisitos y Habilidades
Buscamos candidatos que cuenten con al menos 2 años de experiencia en el área de Data Engineering. Deberán tener competencias en diseño y construcción de pipelines de datos, así como experiencia con lenguajes de programación pertinentes como Python, Scala o SQL.
Es esencial dominar herramientas de orquestación de datos, y tener un conocimiento básico sobre integraciones de CI/CD y flujos de trabajo de versionamiento de código. Adicionalmente, es deseable contar con experiencia en arquitecturas de datos y modelado, incluidos Datalakes y técnicas de modelado específicas.
La modalidad de trabajo es híbrida, lo que permitirá equilibrar la colaboración en persona con flexibilidad laboral.
 Habilidades Deseables
Si bien no es un requisito, consideraremos positivamente la experiencia previa con Datalakes y Datawarehouses, así como familiaridad con técnicas de modelado como dimensional, estrella o copo de nieve. Esto contribuirá a un mejor entendimiento del contexto de las soluciones que desarrollaremos.
 Beneficios y Condiciones
Ofrecemos Un Contrato Por Proyecto De 6 Meses, Con Posibilidad De Extensión. Los Empleados Disfrutarán De Un Sueldo a Convenir, Además De Beneficios Adicionales Como
- Seguro complementario.
- Amipass de $4,500 por día laborado.
- Convenciones, actividades y bonos.
Estamos ubicados en Alto Las Condes, permitiendo un ambiente de trabajo funcional y moderno. ¡Nos encantaría contar contigo en nuestro equipo! 🌟
                
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",API_Error
Senior Data Engineer,Grupo Falabella,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4205321119/,"Somos más de 90 mil personas que, día a día, dedicamos nuestra pasión y energía a cumplir nuestro Propósito de “Simplificar y Disfrutar Más la Vida”. Propósito que hoy vive a través de nuestro ecosistema físico y digital en todas nuestras empresas (Falabella Retail, Sodimac, IKEA, Tottus, Mallplaza, Falabella Inmobiliario, Falabella.com, Linio, Falabella Financiero, Banco Falabella, Falabella Soriana, Seguros Falabella, Fazil, Fpay y Falabella Corporativo) y países (Argentina, Brasil, Chile, China, Colombia, India, México, Perú y Uruguay).
Si disfrutas nuevos desafíos con alta responsabilidad y exposición en el epicentro de la transformación en Latinoamérica, esta oportunidad es para ti. Buscamos un Senior Data Engineer👨‍💻 para sumarse a uno de nuestros equipo, quien sera el encargado de diseñar, construir y mantener sistemas de datos escalables, para el análisis y la toma de decisiones en la organización.
Funciones Del Cargo
Diseñar y desarrollar canalizaciones de datos (ETL/ELT) robustas y eficientes. 
Colaborar con equipos de ingeniería de datos.
Implementar y gestionar bases de datos y data warehouses. 
Optimizar el rendimiento de las bases de datos y sistemas de almacenamiento de datos. 
Garantizar la calidad, integridad y seguridad de los datos. 
Automatizar procesos de ingestión y transformación de datos.
Monitorizar y solucionar problemas relacionados con los sistemas de datos. 
Documentar procesos, arquitecturas y mejores prácticas relacionadas con el manejo de datos.
Requisitos
Profesional titulado en Ingeniería Civil Computación, Industrial, matemático u eléctrico.
Experiencia demostrable como Data Engineer
Experiencia en lenguajes de programación Python.
Experiencia con Google Cloud Platform (Composer, Cloud Functions, Bigquery, Dataproc, etc)
Experiencia utilizando git.
Conocimientos profundos en SQL y en bases de datos relacionales y no relacionales
Deseable: Certificación Associate Engineer
Deseable: Nivel de Inglés intermedio (B1+)
Deseable: Certificaciones relevantes en tecnologías de datos y cloud.
Si te apasionan los desafios numerico 🚀👨‍💻y buscas ser parte de un gran team, ven y postula con nosotros!!
Somos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusión en todas sus formas, sin importar religión, raza, género, situación de discapacidad, nacionalidad.
Conoce más oportunidades para vivir la #ExperienciaFalabella en https://muevete.falabella.com/        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,Financial Services,API_Error
Data Engineer,Mediastream,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4206504298/,"Description
Mediastream is a leading streaming technology company that has been in business for over 16 years. We collaborate with major companies and broadcasters around the world to offer a quality end-to-end solution for content administration, distribution, audiovisual production, and user experience. Our goal is to connect our customers with their audience in a simple and effective way, creating new revenue streams for their businesses.
Role Description
This is a hibrid role for a Data Egineer. The Data Engineer will be responsible for proposing advanced applications of our data, reviewing patterns, deviations to detect trends to optimize dashboards and optimize advertising strategies. Promote new strategies and technologies to process, analyze and leverage customer data and improve user engagement. With the main objective of: Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights, which serve for product roadmap, Develop and manage efficient data pipelines and ETL workflows for the integration of diverse data sources and Use machine learning models and recommendation algorithms to personalize strategies.
Responsibilities
- Create, implement and maintain the company's data architecture.
- Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights for product roadmap.
- Develop and manage data pipelines and ETL workflows for the integration of diverse data sources.
- Use machine learning models and recommendation algorithms to personalize strategies.
- Create interactive visualizations and dashboards for studies to monitor performance and make data-driven decisions.
- Collaborate closely with the development team to integrate, create features and roadmap proposals. 
- Have a product vision and work closely with the marketing and development teams to align strategies with business objectives.
"">
Mediastream is a leading streaming technology company that has been in business for over 16 years. We collaborate with major companies and broadcasters around the world to offer a quality end-to-end solution for content administration, distribution, audiovisual production, and user experience. Our goal is to connect our customers with their audience in a simple and effective way, creating new revenue streams for their businesses.
Role Description
This is a hibrid role for a Data Egineer. The Data Engineer will be responsible for proposing advanced applications of our data, reviewing patterns, deviations to detect trends to optimize dashboards and optimize advertising strategies. Promote new strategies and technologies to process, analyze and leverage customer data and improve user engagement. With the main objective of: Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights, which serve for product roadmap, Develop and manage efficient data pipelines and ETL workflows for the integration of diverse data sources and Use machine learning models and recommendation algorithms to personalize strategies.
Responsibilities
- Create, implement and maintain the company's data architecture.
- Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights for product roadmap.
- Develop and manage data pipelines and ETL workflows for the integration of diverse data sources.
- Use machine learning models and recommendation algorithms to personalize strategies.
- Create interactive visualizations and dashboards for studies to monitor performance and make data-driven decisions.
- Collaborate closely with the development team to integrate, create features and roadmap proposals.
- Have a product vision and work closely with the marketing and development teams to align strategies with business objectives.
Minimum Requirements
- At least 3 years of experience in Data Engineer roles.
- Bachelor's degree in computer science or related field.
- Knowledge in: SQL/No SQL: Advanced, Power BI, Looker, tableau or others: Intermediate, Python and development knowledge: Basic, machine learning, AI or similar technologies: Basic, Identification of cluster patterns, trends, deviations: Intermediate, cloud technologies: Intermediate.
Soft Skills:
- Teamwork
- Decision-making
- Attention to detail
- Adaptability 
"">
- At least 3 years of experience in Data Engineer roles.
- Bachelor's degree in computer science or related field.
- Knowledge in: SQL/No SQL: Advanced, Power BI, Looker, tableau or others: Intermediate, Python and development knowledge: Basic, machine learning, AI or similar technologies: Basic, Identification of cluster patterns, trends, deviations: Intermediate, cloud technologies: Intermediate.
Soft Skills:
- Teamwork
- Decision-making
- Attention to detail
- Adaptability        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,OTHER
Data Engineer AWS,BC Tecnología,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205294910/,"En 
BC Tecnología
, nos especializamos en la consultoría de TI, ofreciendo un amplio rango de servicios para adaptarnos a las necesidades específicas de nuestros clientes, principalmente en finanzas, seguros, retail y gobierno. Nuestro equipo trabaja mediante metodologías ágiles, lo que nos permite diseñar e implementar soluciones tecnológicas efectivas y dirigidas al cliente. Actualmente, estamos buscando un Data Engineer con experiencia en AWS para sumarse a nuestro equipo y contribuir a proyectos innovadores en la gestión y explotación de datos.
 Responsabilidades del Cargo
- Desarrollar y gestionar procesos de ETL, asegurando la calidad y fiabilidad de los datos.
- Optimizar la explotación de datos a través de técnicas de Tuning.
- Implementar soluciones utilizando herramientas de AWS, incluyendo Glue, Lambda, S3, Redshift y DynamoDB.
- Colaborar con los equipos de desarrollo de software para asegurar la integración de datos eficiente.
- Realizar análisis y visualización de datos para apoyar en la toma de decisiones.
- Mantener un enfoque en la innovación y la mejora continua de los procesos y herramientas utilizadas.
 Descripción del Cargo
Buscamos Un Data Engineer AWS Con Un Mínimo De 3 Años De Experiencia En El Manejo De Datos. El Candidato Ideal Tendrá Conocimientos Sólidos En
- Explotación de datos y Tuning.
- Diseño e implementación de procesos ETL.
- Desarrollo de consultas efectivas en SQL.
- Programación en Python.
- Uso de herramientas de orquestación como Apache Airflow (deseable).
Valoramos habilidades como el trabajo en equipo, la proactividad y la capacidad para adaptarse a nuevas tecnologías. La combinación de habilidades técnicas y soft skills es esencial para unirse a nuestro equipo dinámico.
 Habilidades Deseables
Además de los requisitos mencionados, sería beneficioso contar con experiencia en:
- Integraciones y gestión de datos en múltiples fuentes.
- Implementación de soluciones en la nube de AWS.
- Conocimientos en herramientas de visualización de datos.
Estas habilidades ayudarán al candidato a integrarse de manera efectiva en nuestros equipos de trabajo y contribuir a proyectos futuros.
 Beneficios de Trabajar con Nosotros
En 
BC Tecnología
, valoramos a nuestro equipo y ofrecemos un entorno flexible y beneficios atractivos:
- Contrato indefinido.
- Modalidad híbrida, combinando trabajo remoto y en oficina.
- Paquete de beneficios corporativos que incluye salud prepaga de primer nivel para el empleado y su familia.
- Un día de home office a la semana, junto con desayunos y un comedor en la planta.
- Acceso a un Sport Club y asistencia de un nutricionista.
¡Únete a nosotros y marca una diferencia en el mundo de la tecnología! 🎉
                
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",AWS
Data Engineer GCP,Soluciones - Data & Analytics Consulting,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4206574777/,"✔️
¿Quiénes Somos?
Somos una consultora enfocada en Data & Analytics y contamos con más de 20 años de experiencia y exitosa participación en implementación de proyectos de pequeña, mediana y gran envergadura. Nuestro equipo, compuesto por consultores multidisciplinarios expertos y certificados, ha entregado soluciones tecnológicas de calidad que exceden las expectativas de cada cliente. A través de una metodología flexible y adaptable, logramos entregar soluciones adecuadas a la realidad de cada organización, satisfaciendo los estándares de cada una de las empresas que confían en nosotros.
✔️
 ¿Qué harás?
- Integración de productos de datos.
- Se trabajará con información para conocer a clientes y segmentarlos, para innovar en productos.
- Trabajará los procesos ETL de inicio a fin (ingesta, transformación, disponibilización).
- Conocimientos Full GCP (airflow, bigquery, cloudstorage como herramientas principales)
- Deberá generar el flujo completo del dato desde la ingesta, transformación y disponibilización.
✔️
 ¿Qué se requiere?
- Experiencia en el rol o cargo de Ingeniero de Datos Google Cloud Platform (GCP)
✔️
Conocimientos técnicos excluyentes:
- Experiencia en datos y modelo de datos
- Metodología agile
- Procesos ETL
- Conocimientos en Suit GCP
✔️ ¿Qué Ofrecemos ?
- Seguros complementario de salud
- Rutas de estudios
- Día libre cumpleaños
- Reajuste salarial anual según variación del IPC        
            
                            
            ",Associate,Full-time,Information Technology,IT Services and IT Consulting,GCP
Senior Data Engineer,23people,Chile,2025-04-11,https://www.linkedin.com/jobs/view/4207846989/,"¡Hola! Estamos buscando un Senior Data Engineer 
🌐
Rango salarial entre: $2.200.000 - $2.400.000 CLP
País: Residentes en Chile 
Skills
Técnicas
- Python
- BigQuery/SQL
- GitHub
- Apache Beam/Spark/Google Dataflow
Personales
- Capacidad de autogestión
- Buenos skills de comunicación
- Fortaleza en trabajo en equipo
- Adaptación al cambio (trabajarán en distintas geos de Latam)
Deseable (NO excluyente)
- Perfil Analítico
- UnitTest
- AirFlow
- PySpark
- CI/CD
- Postman
- Jmeter
¿Qué harás en tu día a día?
El profesional colaborará con un equipo multidisciplinario en un proyecto de expansión internacional, enfocado en la migración estratégica de la plataforma hacia nuevos mercados. Su participación será fundamental para asegurar una implementación eficiente que considere las particularidades de cada país destino, garantizando así el éxito de esta iniciativa global.
Algunas de sus tareas diarias son las siguientes:
- Implementar mecanismos para verificar la integridad de los datos migrados
- Implementar transformaciones específicas para requisitos regionales
- Dirigir el equipo técnico durante las fases críticas de migración
- Gestionar el proceso integral de ETL entre diversos sistemas, desarrollando y optimizando los esquemas de mapeo necesarios para garantizar la compatibilidad entre las estructuras de datos de origen y destino.
Contrato indefinido desde el inicio con 23people
Modalidad: Home Office, Con residencia en Chile (Deberás ir a buscar el PC en primera instancia)
Experiencia: Desde 5 años en adelante
Horario: Lunes a Jueves de 8:30 a 6:30 y Viernes de 8:30 a 5:30 hrs.
Algunos de nuestros beneficios:
- Seguro complementario: Seguro de salud, vida y dental
- Curso de inglés: En nuestro programa de formación en idioma inglés, ofrecemos dos modalidades para adaptarnos a tus necesidades y objetivos.
- Reembolso de certificaciones internacionales: Apoyamos el crecimiento profesional, por lo que te reembolsamos el costo de un examen de certificación internacional que quieras realizar.
- Bono de vacaciones: Por cada semana que te tomes de vacaciones te otorgamos una compensación.
- Aguinaldos en fiestas patrias y Navidad: Queremos que en fechas tan especiales la pases bien junto a tu familia, por lo que te entregamos un bono en septiembre y diciembre
- Día libre de cumpleaños: Puedes optar por tomar tu día libre, el día previo a tu cumpleaños, el mismo día de tu cumpleaños o el día posterior.        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,GCP
Data Engineer AWS,Soluciones - Data & Analytics Consulting,"Santiago Metropolitan Region, Chile",2025-04-11,https://www.linkedin.com/jobs/view/4207848749/,"✔️
¿Quiénes Somos?
Somos una consultora enfocada en Data & Analytics y contamos con más de 20 años de experiencia y exitosa participación en implementación de proyectos de pequeña, mediana y gran envergadura. Nuestro equipo, compuesto por consultores multidisciplinarios expertos y certificados, ha entregado soluciones tecnológicas de calidad que exceden las expectativas de cada cliente. A través de una metodología flexible y adaptable, logramos entregar soluciones adecuadas a la realidad de cada organización, satisfaciendo los estándares de cada una de las empresas que confían en nosotros.
✔️
 ¿Qué harás?
- Responsabilidades del cargo: Diseñar, construir y mantener procesos de ingesta de datos que permiten recolectar, almacenar, procesar y acceder a grandes volúmenes de datos de manera eficiente y segura. Su trabajo asegura que los datos estén disponibles, limpios y organizados para su análisis adhiriéndose a los estándares definidos por el cliente.
✔️
 ¿Qué se requiere?
- Experiencia de al menos 3 años en el rol
- Conocimientos técnicos excluyentes: S3, Lambdas, Glue Jobs, DynamoDB, Redshift, StepFunctions, Python, SQS.
- Conocimientos técnicos deseables: API Gateway, Transfer Family.
✔️ ¿Qué Ofrecemos ?
- Seguros complementario de salud
- Rutas de estudios
- Día libre cumpleaños
- Reajuste salarial anual según variación del IPC        
            
                            
            ",Not Applicable,Full-time,Information Technology,IT Services and IT Consulting,AWS
Data Engineer Senior,Equifax,"Las Condes, Santiago Metropolitan Region, Chile",2025-04-11,https://www.linkedin.com/jobs/view/4144902157/,"Como Data Engineer, estarás a cargo de integrar, consolidar y estructurar los datos, apoyándote en un las mejores prácticas para manejar, mantener y mejorar nuestras soluciones.
 
 
 ¿Qué vas a hacer? 
 
 
-  Evaluar, gestionar y resolver incidentes. 
-  Realizar cálculos en linea utilizando Python. 
-  Ejecución de pruebas. 
 
 
 ¿Qué experiencia necesita? 
 
 
-  + 4 años de experiencia trabajando en Python. 
-  + 4 años de experiencia BigQuery. 
-  + 4 años de experiencia trabajando con Apache Beam y GitHub. 
 
 
 ¿Qué podría diferenciarte? 
 
 
-  Poseer alguna certificación de Google en Data Engineer. 
-  Experiencia trabajando con Airflow. 
-  Experiencia Trabajando con Jmeter. 
-  Experiencia trabajando con Unit Test. 
-  Experiencia trabajando con PySpark. 
-  Experiencia trabajando con CI/DF. 
-  Experiencia trabajando con Postman.        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,Financial Services,GCP
Data Engineer Semisenior o Senior,LISIT,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205297492/,"Lisit es una empresa comprometida con la creación, desarrollo e implementación de soluciones de software que faciliten la automatización y optimización para nuestros clientes. Nuestra visión se centra en brindar servicios que no solo cumplan con las necesidades del mercado, sino que también transformen la operatividad de las organizaciones. Tu función como Ingeniero de Datos será fundamental para lograr un acompañamiento consultivo integral en sus procesos de transformación.
 Responsabilidades del puesto
Como Ingeniero De Datos Semi-senior o Senior En Lisit, Serás Una Pieza Clave En El Diseño y Desarrollo De Soluciones De Datos Que Optimicen Nuestros Servicios y Herramientas. Tus Tareas Incluirán
- Generar pipelines de datos eficientes y resolver integraciones entre diversos sistemas.
- Modelar datos para garantizar que nuestras plataformas sean útiles y escalables.
- Colaborar en la implementación de herramientas de infraestructura como código (IaC) y gestionar el versionamiento a través de GitHub o GitLab.
- Desarrollar y ejecutar procesos ETL/ELT utilizando Azure Data Factory, asegurando la calidad y accesibilidad de los datos.
 Descripción del puesto
Buscamos un Ingeniero de Datos altamente motivado, con un mínimo de 3 años de experiencia en el tratamiento de datos. Tu destreza con lenguajes de programación como Python y Spark te permitirá desempeñarte con solidez en el equipo. Se requiere un conocimiento intermedio-avanzado de herramientas de IaC (Terraform) y manejo de versionamiento de código (GitHub/GitLab), así como una sólida comprensión del lenguaje SQL y bases de datos.
Es esencial que tengas experiencia con plataformas en la nube como Google Cloud Platform (GCP) o Azure, y herramientas como Airflow, Cloud Run, Cloud Composer y BigQuery. Además, el dominio de Azure Data Factory para procesos ETL-ELT es un requisito excluyente. Las certificaciones en Ingeniería de Datos son valoradas, tales como Azure DP-700, AZ-203, DP-600 y Google Cloud Digital Leader.
 Habilidades deseables
Si cuentas con conocimientos en Microsoft Power BI o Fabric, sería un gran plus para tu perfil. Queremos personas que no solo cumplan con los requisitos, sino que también aporten un enfoque innovador y colaborativo a nuestro equipo.
 Beneficios de trabajar con nosotros
En Lisit, Fomentamos Un Ambiente De Trabajo Excepcional, Donde La Innovación y La Pasión Por El Aprendizaje Son Clave. Te Ofrecemos
- Acceso a oportunidades continuas de desarrollo profesional en tecnologías emergentes.
- Un equipo motivado y apasionado que valora tu entusiasmo y contribuciones.
Aquí, tendrás la oportunidad de crecer y alcanzar tus objetivos profesionales mientras colaboras en proyectos desafiantes y de alto impacto.
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",AZURE
Ingeniero de Datos,Amaris Consulting,Chile,2025-04-10,https://www.linkedin.com/jobs/view/4206597362/,"Who are we?
Amaris Consulting es una firma independiente de asesoría tecnológica que ofrece servicios de orientación y soluciones para las empresas.
Reúne a más de 7 600 personas distribuidas en 5 continentes y más de 60 países. Con más de 1 000 clientes en todo el mundo, hemos implementado soluciones en proyectos importantes durante más de una década.
Nuestros especialistas cubren sectores que abarcan desde servicios financieros y transporte hasta atención sanitaria y tecnología.
Amaris es su ‘stepping stone’ para atravesar ríos de cambio, afrontar retos y realizar todos sus proyectos con éxito.
Job Description
Buscamos consultores dinámicos para hacer crecer nuestro equipo de 
Sistemas de Información y Digital
 en
 Chile
. Tu experiencia, conocimiento y compromiso nos ayudarán a enfrentar los desafíos de nuestros clientes.
Estarás apoyando diferentes proyectos a través de tu experiencia como 
Ingeniero de Datos.
Sus principales responsabilidades:
- Asegurar que las soluciones de datos sean escalables, eficientes y alineadas con los objetivos de negocio.
- Diseñar, desarrollar e implementar soluciones de gestión y análisis de datos en la industria.
- Utilizar herramientas como Python y SQL para extraer, transformar y cargar (ETL) datos.
- Trabajar con bases de datos en la nube, utilizando alguna de las principales plataformas: Google Cloud Platform (GCP), Amazon Web Services (AWS) o Microsoft Azure.
- Desarrollar y mantener pipelines de datos para la gestión y análisis eficiente.
- Desarrollar APIs y plugins para integrar soluciones de datos con otras aplicaciones y sistemas.
- Implementar y gestionar entornos de desarrollo y pruebas para soluciones de datos.
- Mantenerse actualizado con las últimas tendencias y herramientas en el ámbito de la ingeniería de datos.
Requisitos
:
- Al menos 2 años de experiencia como Ingeniero de Datos.
- Al menos 2 años de experiencia con alguna de las principales nubes (GCP, AWS, Azure).
- Dominio de Python.
- Dominio de bases de datos SQL.
- Experiencia con procesos ETL.
Amaris Consulting se enorgullece de ser un lugar de trabajo con igualdad de oportunidades. Estamos comprometidos con la promoción de la diversidad dentro de la fuerza de trabajo y la creación de un ambiente de trabajo inclusivo. Para ello, damos la bienvenida a las solicitudes de todos los candidatos cualificados, independientemente de su género, orientación sexual, raza, etnia, creencias, edad, estado civil, discapacidad u otras características.        
            
                            
            ",Entry level,Full-time,Information Technology,IT Services and IT Consulting,OTHER
Data Engineer - GCP Ssr,axity,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4204875774/,"Company Description: axity
Job Description: Axity una compañía con más de 35 años de trayectoria nuestro portafolio de servicios es uno de los más grandes en la industria: Estrategia Digital, Desarrollo de Software, Bussiness Intelligence, Big Data, Analítica Avanzada, Seguridad, IOT.
Buscamos Data Analyst / Data Engineer – Nivel Medio/Avanzado
¿Te apasiona convertir datos en información valiosa y accionable?
Estamos en búsqueda de un profesional con experiencia en desarrollo de productos de complejidad media a avanzada, capaz de entregar soluciones de calidad dentro de los plazos establecidos.
Responsabilidades
Desarrollar productos analíticos cumpliendo con estándares de calidad y tiempos definidos.
Traducir datos en información útil para la toma de decisiones.
Trabajar en conjunto con equipos de analítica para profundizar en el análisis y la síntesis de datos.
Seleccionar y aplicar técnicas analíticas adecuadas a cada requerimiento.
Mantenerse actualizado sobre herramientas analíticas y productos de manipulación de datos.
Realizar procesos de recolección, clasificación, limpieza e interpretación de grandes volúmenes de datos.
Aplicar prácticas de gobernanza y seguridad de los datos.
Participar en iniciativas que involucren integración de datos para procesos como planeación de compras, demanda y gestión de inventarios.
Requisitos
Experiencia en GCP (Google Cloud Platform): BigQuery, Cloud Storage, Dataflow, Cloud Functions, Composer, Pub/Sub.
Conocimientos básicos en Kubernetes, contenedores y consumo de APIs.
Experiencia en manejo de grandes volúmenes de datos.
Conocimiento de sistemas legados, flujos de compras y demand forecasting.
Capacidad de interacción continua con áreas de negocio.
Ofrecemos
Horario: Lunes a viernes de 9:00 a 18:30
Contrato a plazo fijo luego a indefinido
Oportunidad de trabajar en proyectos desafiantes con impacto directo en el negocio
Ambiente colaborativo e innovador
Si te motiva trabajar con datos, impactar decisiones estratégicas y enfrentarte a desafíos técnicos, ¡postula con nosotros!
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,GCP
Data Engineer - AWS Ssr,axity,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4204874848/,"Company Description: axity
Job Description: Axity una compañía con más de 35 años de trayectoria nuestro portafolio de servicios es uno de los más grandes en la industria: Estrategia Digital, Desarrollo de Software, Bussiness Intelligence, Big Data, Analítica Avanzada, Seguridad, IOT.
Responsabilidades Principales
-  Diseño eficiente de almacenamiento de datos: utilizando servicios como Amazon S3, DynamoDB, RDS, entre otros, optimizando costos, rendimiento y accesibilidad.
-  Optimización de consultas: aplicando índices, claves de partición y patrones de acceso eficientes (Query, GetItem, etc.).
-  Integración y procesamiento de datos: a través de herramientas como AWS Glue, Amazon Kinesis y/o Firehose para ingesta, transformación y orquestación.
-  Uso de formatos optimizados: como Parquet, ORC, entre otros, para mejorar la compresión y velocidad de lectura/escritura.
-  Infraestructura como Código (IaC): despliegue de infraestructura en AWS mediante CloudFormation, AWS CDK o Terraform.
________________________________________
️ Conocimientos Técnicos Clave
-  Amplio manejo de servicios AWS: S3, DynamoDB, RDS, AWS Glue, Kinesis/Firehose.
-  Dominio de bases de datos SQL/NoSQL: diseño de esquemas, indexación y tuning.
-  Experiencia en optimización y particionamiento de grandes volúmenes de datos.
-  Familiaridad con automatización y orquestación de pipelines: scripting, Jenkins, Shell, entre otros.
-  Modalidad: Híbrido
-  Área: Tecnología – Cloud
-  Horario: Lunes a viernes de 9:00 a 18:00 hrs
-  Tipo de Contrato: Plazo fijo, con posibilidad de pasar a indefinido
________________________________________
¿Por qué postular?
-  Serás parte de una empresa con enfoque en la innovación y la transformación digital.
-  Trabajarás con tecnologías de vanguardia en un entorno colaborativo.
-  Tendrás oportunidades reales de crecimiento profesional.        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,AWS
Data Engineer Azure,"","Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4206654598/,"Resumen del Cargo:
Busco Ingeniero de Datos  para liderar y ejecutar proyectos de Data & Analytics. 
Será responsable del diseño, desarrollo e implementación de soluciones de datos usando Azure Databricks, Data Factory, Python  y otros servicios en la nube, asegurando que la infraestructura de datos sea escalable, segura y optimizada para la toma de decisiones. 
Además, deberá interactuar directamente con áreas de negocio para levantar requerimientos y traducirlos en soluciones técnicas eficientes.
 
 
Responsabilidades:
        •       Diseñar y desarrollar soluciones de ingestión, transformación y modelado de datos en Azure DataFactory, Databricks y otras tecnologías relacionadas.
        •       Optimizar procesos de ETL/ELT, asegurando calidad, integridad y eficiencia en el procesamiento de datos.
        •       Colaborar con equipos de negocio para entender necesidades, identificar oportunidades y proponer soluciones basadas en datos.
        •       Implementar arquitecturas de datos escalables que soporten analítica avanzada, machine learning e inteligencia de negocio.
        •       Garantizar la seguridad y el cumplimiento normativo en el manejo de datos, siguiendo estándares bancarios y regulatorios.
        •       Desarrollar y optimizar pipelines de datos para la explotación en entornos analíticos y de reportes.
        •       Documentar procesos, arquitecturas y modelos de datos, asegurando buenas prácticas de gobernanza.
        •       Trabajar en conjunto con equipos de Data Science, BI y Tecnología para garantizar la disponibilidad y calidad de los datos.
         
            
                            
            ",Entry level,Full-time,Information Technology,,AZURE
Senior Data Engineer,Grupo Falabella,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4205465977/,"Descripción Empresa
Somos más de 90 mil personas que, día a día, dedicamos nuestra pasión y energía a cumplir nuestro Propósito de “Simplificar y Disfrutar Más la Vida”. Propósito que hoy vive a través de nuestro ecosistema físico y digital en todas nuestras empresas (Falabella Retail, Sodimac, IKEA, Tottus, Mallplaza, Falabella Inmobiliario, Falabella.com, Linio, Falabella Financiero, Banco Falabella, Falabella Soriana, Seguros Falabella, Fazil, Fpay y Falabella Corporativo) y países (Argentina, Brasil, Chile, China, Colombia, India, México, Perú y Uruguay).
Valoramos las distintas miradas porque entendemos que la diversidad es la clave de nuestra innovación. Queremos ir más allá de cualquier límite, desafiarnos constantemente, divertirnos haciendo lo que nos gusta y dejar huella en lo que hacemos. Y sabemos que existe una forma de hacerlo: como UN SOLO EQUIPO.
Misión Del Cargo
¡Únete a Falabella Retail y lleva tus habilidades de Ingeniería de Datos al próximo nivel!
Funciones Del Cargo
Formarás parte de un equipo de alto impacto que lidera la transformación digital, trabajando en proyectos críticos para optimizar y escalar nuestras operaciones en uno de los ecosistemas más dinámicos de la región.
Mision: Responsable de diseñar, construir y mantener sistemas de datos escalables para el análisis y la toma de decisiones en la organización.
Responsabilidades
Diseñar y desarrollar canalizaciones de datos (ETL/ELT) robustas y eficientes.
Colaborar con equipos de ingeniería de datos.
Implementar y gestionar bases de datos y data warehouses.
Optimizar el rendimiento de las bases de datos y sistemas de almacenamiento de datos.
Garantizar la calidad, integridad y seguridad de los datos.
Automatizar procesos de ingestión y transformación de datos.
Monitorizar y solucionar problemas relacionados con los sistemas de datos.
Documentar procesos, arquitecturas y mejores prácticas relacionadas con el manejo de datos.
Si disfrutas nuevos desafíos con alta responsabilidad y exposición en el epicentro de la transformación del retail en Latinoamérica, ¡súmate a trabajar con nosotros! Somos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusión en todas sus formas, sin importar religión, raza, género, situación de discapacidad, nacionalidad.
Conoce más oportunidades para vivir la #ExperienciaFalabella en https://muevete.falabella.com/
Requisitos
- Profesional Titulado en Ingeniería Civil Computación, Industrial, matemático u eléctrico.
- Experiencia demostrable como Data Engineer por mas de 04 años
- Conocimientos en lenguajes de programación Python.
- Experiencia con Google Cloud Platform (Composer, Cloud Functions, Bigquery, Dataproc, etc)
- Experiencia utilizando git
- Deseable: Conocimientos profundos en SQL y en bases de datos relacionales y no relacionales
- Deseable: Certificaciones relevantes en tecnologías de datos y cloud.
Condiciones Oferta
Descripción proceso de selección:
El proceso de selección se realiza a través de Aira - plataforma de reclutamiento diseñado para mejorar tu experiencia de postulación.
Para Postular Solo Necesitas
-  Postular a la oferta
-  Revisar tu email
-  Ingresar a Aira y contestar las preguntas y/o pruebas solicitadas
Luego, si vemos que tu perfil se ajusta a lo que estamos buscando, te contactaremos por email (a través de Aira) para seguir a la etapa presencial.
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,Retail,GCP
