title,company,location,date,job_url,job_description,Seniority level,Employment type,Job function,Industries,cloud_focus
Data Engineer Junior,LISIT,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205294902/,"En Lisit, nos dedicamos a crear, desarrollar e implementar herramientas y servicios de software que automatizan y optimizan procesos, siempre con un fuerte enfoque en la innovaci√≥n y los desaf√≠os que se presentan. Nuestro objetivo es fomentar la eficacia operativa de nuestros clientes, ayud√°ndoles a alcanzar sus metas de transformaci√≥n mediante un acompa√±amiento consultivo integral. Actualmente, estamos en b√∫squeda de un Data Engineer Junior que se una a nuestro equipo apasionado por la tecnolog√≠a y el aprendizaje continuo.
 Funciones del Rol
Como Data Engineer Junior, Ser√°s Parte Esencial Del Equipo Encargado De Manejar y Optimizar El Flujo De Datos De La Organizaci√≥n. Tus Principales Responsabilidades Incluir√°n
- Colaborar en la recopilaci√≥n y procesamiento de datos relacionales y no relacionales.
- Trabajar con lenguajes de programaci√≥n, especialmente Python, para crear soluciones de datos efectivas.
- Implementar y mantener los procesos de integraci√≥n en ambientes cloud como GCP o Azure.
- Realizar consultas y manipulaci√≥n de bases de datos utilizando SQL.
- Aprender y adaptarte a nuevas tecnolog√≠as y herramientas en el entorno de la nube.
 Descripci√≥n del Perfil
Buscamos Un Perfil Proactivo, Con Conocimientos Intermedios En Python y Disposici√≥n Para Aprender Sobre Nuevas Tecnolog√≠as. El Candidato Ideal Deber√° Tener
- Experiencia b√°sica a intermedia en programaci√≥n Python.
- Habilidades en el uso y tratamiento de datos en ambientes tanto relacionales como no relacionales.
- Conocimientos fundamentales en tecnolog√≠as de nube, incluyendo GCP o Azure.
- Experiencia en el uso del lenguaje SQL.
- Bajo es requisito pero se valorar√° el conocimiento en Power BI.
 Habilidades Deseables
Ser√≠a excelente contar con conocimientos adicionales en herramientas de visualizaci√≥n de datos como Power BI. Adem√°s, habilidad para trabajar en equipo y una mentalidad orientada al aprendizaje continuo son altamente valoradas.
 Beneficios de Trabajar con Nosotros
En Lisit, Promovemos Un Ambiente De Trabajo Excepcional
- Acceso a oportunidades de desarrollo profesional continuo en tecnolog√≠as emergentes.
- Un equipo apasionado por la innovaci√≥n y el aprendizaje, donde tu entusiasmo ser√° bienvenido.        
            
                            
            ",Entry level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",OTHER
Data Engineer,Xepelin,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4205474021/,"Somos una FinTech que busca democratizar los servicios financieros para todo tipo de empresas. Nos apalancamos en la mejor tecnolog√≠a para crear soluciones √°giles, personalizadas y transparentes. Nuestro objetivo es ser la FinTech B2B m√°s grande de Latam y convertirnos en el CFO digital de todas las empresas en la regi√≥n.
Xepelin nace en Chile en 2019 y, desde entonces, hemos levantado m√°s de USD145 millones en equity y USD300 millones en asset-backed facilities para potenciar el crecimiento en toda la regi√≥n, especialmente en los pa√≠ses donde hoy operamos, Chile y M√©xico. La √∫ltima ronda de equity fue de USD111 millones, record en Chile y una de las m√°s grandes en Am√©rica Latina para una FinTech.
¬øPor qu√© trabajar en Xepelin?
üí™ Desaf√≠o
Estamos sacudiendo una de las industrias m√°s poderosas y competitivas, eliminando fricciones para darle a las Pymes acceso a capital y apalancado en la √∫ltima tecnolog√≠a disponible. Todo esto poniendo siempre a nuestras Pymes en el centro.
Construir un banco digital desde cero es un gran proyecto; el producto es complejo y no se puede romper, existen regulaciones estrictas y tendremos que ser mejores que algunas de las corporaciones m√°s grandes y consolidadas del mundo. Pero superar estos desaf√≠os significa que habremos construido algo duradero.
üí• Impacto
Trabajar en un equipo de clase mundial y automotivado significa autonom√≠a, amplia experiencia en todos los proyectos y ver que tus contribuciones afectan directamente al producto e impactan a nuestras Pymes.
Trabajar√°s con todos nuestros productos, tendr√°s que tomar decisiones fundamentales. El correcto posicionamiento de ellos marcar√° su futuro.
‚úîÔ∏è Calidad
Nuestro posicionamiento de marca y productos es algo diferenciador frente al resto del mercado por lo que invertimos mucho en crear productos de calidad que nuestras Pymes respeten y valoren.
Nos damos el tiempo para pensar fuera de la caja y volver con propuestas innovadoras. Estamos aqu√≠ para cambiar la industria!
¬øQu√© estamos buscando? 
En Xepelin estamos buscando personas creativas y visionarias que piensen fuera de la caja para sumarse a nuestro equipo. Si te apasiona resolver desaf√≠os interesantes de alto impacto y quieres ser parte de un entorno din√°mico que est√° transformando la industria financiera, ¬°Esta oportunidad es para ti!
El rol se integrar√° a nuestro equipo de 
Data Platform
. Si te motiva el desaf√≠o de construir soluciones innovadoras en un entorno de r√°pido cambio, queremos conocerte.
Unete a nosotros, crezcamos juntos!
Principales responsabilidades...
-  Dise√±ar, crear y mantener pipelines de datos
-  Mantener y optimizar la infraestructura de datos necesaria para una extracci√≥n precisa, transformaci√≥n y carga de datos de una amplia variedad de fuentes de datos
-  Automatizar los flujos de trabajo de datos, como la ingesta de datos, la agregaci√≥n y el procesamiento de ETL o ELT
-  Preparar datos sin procesar en almacenes de datos en un conjunto de datos consumibles para fines t√©cnicos y partes interesadas no t√©cnicas
-  Crear, mantener e implementar productos de datos para equipos de an√°lisis y ciencia de datos en Plataformas en la nube, preferentemente en GCP, y/o AWS
-  Desarrollar sistemas y arquitectura que soporten las diferentes etapas del flujo de Machine Learning
¬øQu√© necesitas para brillar?
- Conocimientos en alguna Nube, preferentemente GCP o AWS (en ese orden de preferencia)
- Conocimientos intermedio/avanzado en Python
- Conocimiento intermedio/avanzado de SQL
- Experiencia trabajando almacenamiento en la nube como GCS o AWS S3
- Experiencia desplegando aplicaciones en ambientes serverless como Cloud Functions o AWS Lambda
- Conocimientos administrando y desplegando alg√∫n orquestador, por ejemplo: Dagster, Apache Airflow, Prefect, etc
- Excelentes habilidades para trabajar en equipo. Ser humilde y saber colaborar, un Team Player!
- Saber escuchar a tus stakeholders y poder traducir eso en requerimientos y ejecutarlos con tu equipo
- Trabajo proactivo y responsable
- Conocimientos en DBT
- Conocimientos y manejo de lenguajes de programaci√≥n y/o frameworks, NodeJS, Golang, por ejemplo
- Experiencia en MLOps
- No tener miedo a tomar decisiones y liderar proyectos
- Foco en impacto e historia consistente entregando resultados para usuarios y el negocio
- Capacidad para pensar en grande y desarrollar iniciativas con impacto real y medible
- Te sientes c√≥modo cuestionando el status-quo de los servicios financieros, adapt√°ndose r√°pidamente a los cambios, y presentando claramente tus ideas y conceptos para debatirlos en equipo
Nuestros Beneficios:
üå¥ Xepelin Balance
Vacaciones:
 15 d√≠as h√°biles. Por cada a√±o que cumplas en Xepelin, te damos un d√≠a extra de vacaciones.
Balance days:
 10 d√≠as libres adicionales al a√±o, para disfrutar como quieras.
Trabajo h√≠brido y flexibilidad horaria seg√∫n el rol. Trabajamos por objetivos.
Beneficios Flexibles: 
Puntos flexibles en tu moneda local al mes para gastar en lo que quieras.
Xepelin Fun:
 Actividades de encuentro financiadas por Xepelin para divertirnos juntos.
üöÄ Xepelin Performance & Career
Plataformas de capacitaci√≥n:
 Convenios con las mejores plataformas, como Reforge, Udemy y DataCamp.
Kit de Bienvenida: 
todo lo que necesitas para comenzar tu viaje en Xepelin üòä
ü§ù Xepelin Cares
Cobertura de salud:
 contamos con convenios de salud con proveedores de calidad o reembolsos seg√∫n el pa√≠s donde te encuentres.
Post Natal:
 te damos una semana extra de licencia post natal. ¬°Nos interesa que est√©s con tu familia y seres queridos!
Matrimonio plus:
 Lleva tus planes al siguiente nivel, con una gift card y extendiendo tu permiso legal por matrimonio con dos d√≠as de regalo por Xepelin.        
            
                            
            ",Not Applicable,Full-time,Information Technology,"Software Development, IT Services and IT Consulting, and Biotechnology Research",GCP
Data Engineer,BC Tecnolog√≠a,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205297472/,Could not find Job Description,,,,,OTHER
Data Engineer,2Brains,Chile,2025-04-10,https://www.linkedin.com/jobs/view/4205294882/,"2Brains es una empresa dedicada a construir y desarrollar el Futuro Digital de nuestros clientes, con una visi√≥n excepcional que radica en la integraci√≥n sin√©rgica de estrategia, dise√±o y tecnolog√≠a, un tr√≠ptico poderoso que impulsa el crecimiento de empresas y disruptores tecnol√≥gicos.
Contamos con un nutrido equipo de m√°s de 200 profesionales, verdaderos art√≠fices de la innovaci√≥n digital. En el coraz√≥n de nuestra labor, destacamos como l√≠deres indiscutibles, canalizando a√±os de experiencia hacia la creaci√≥n de plataformas tecnol√≥gicas adaptables y productos digitales de clase mundial.
En 2Brains, no solo somos consultores, somos arquitectos de experiencias digitales. Aspiramos a ir m√°s all√° de las expectativas, estableciendo nuevos est√°ndares en la industria. Descubre c√≥mo damos vida a la innovaci√≥n, c√≥mo convertimos ideas en resultados tangibles y c√≥mo, junto a nosotros, puedes forjar un futuro digital brillante.
 El/la Data Engineer de 2Brains 
Se encarga de participar en el dise√±o y desarrollo de los nuevos modelos de informaci√≥n de gesti√≥n y las mantenciones evolutivas de los existentes. Participar en las iniciativas de Anal√≠tica avanzada del √°rea, apoyando las exploraci√≥n de modelos de informaci√≥n internos y externos (Data Discovery). Obtener datos hist√≥ricos desde m√∫ltiples fuentes de informaci√≥n interna para apoyar las iniciativas de anal√≠tica avanzada del equipo.
El/la Data Engineer de 2Brains debe
- Construir y optimizar pipelines de datos para la ingesta, transformaci√≥n y carga eficiente de informaci√≥n.
- Manejar infraestructuras en la nube (AWS, GCP, Azure), asegurando escalabilidad y eficiencia en costos.
- Automatizar y monitorear procesos mediante herramientas de DevOps como Airflow, Terraform o Kubernetes.
- Implementar controles de calidad y gobernanza para garantizar la integridad y disponibilidad de los datos.
- Colaborar con equipos de Data Science, Producto y Desarrollo para dise√±ar soluciones alineadas con las necesidades del negocio.
 Qu√© conocimientos buscamos en/la Data Engineer
- Excluyente Experiencia trabajando con tecnolog√≠as de BI
- Experiencia en la construcci√≥n/operaci√≥n de sistemas distribuidos de extracci√≥n, ingesti√≥n y procesamiento de grandes conjuntos de datos de gran disponibilidad.
- Capacidad demostrable en modelado de datos, desarrollo de ETL y almacenamiento de datos.
- Experiencia en el uso de herramientas de informes de inteligencia empresarial (Power BI)
- Excluyente conocimiento en consumo de microservicios de APIs Rest
- Excluyente conocimiento en Git , Bitbucket, Docker,Jenkins,Webhooks
- Programaci√≥n con Python y bases s√≥lidas de ingenier√≠a de software.
- Automatizaci√≥n y scripting.
- Uso de librer√≠as de Python para manipulaci√≥n y an√°lisis de datos y Apache Spark.
- Conocimientos en bases de datos SQL y NoSQL.
- Conocimiento en CI/CD, Dataflow
- Conocimiento en S3, Redshift y Glue AWS
 Que competencias buscamos en/la Data Engineer 
- Empat√≠a
- Buena capacidad de comunicaci√≥n.
- Colaboraci√≥n y trabajo en equipo.
- Proactividad.
- Autonom√≠a.
- Foco en los objetivos de proyectos.
 Condiciones
Trabajar con un equipo de alto rendimiento, aprendemos y nos desarrollamos juntos
Acceso a grandes clientes y proyectos desafiantes
Aprendizaje y crecimiento permanente, organizamos meetups, capacitaciones y actividades culturales
Un entorno de trabajo flexible y din√°mico
Beneficios especiales: d√≠a libre para tu cumplea√±os, d√≠as de descanso a convenir.
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",OTHER
Data Engineer,Falabella,"Santiago, Santiago Metropolitan Region, Chile",2025-04-11,https://www.linkedin.com/jobs/view/4207045620/,"Descripci√≥n Empresa
Somos m√°s de 80 mil personas que cada d√≠a trabajamos por el firme Prop√≥sito - Simplificar y Disfrutar m√°s la Vida. Estamos presentes en 9 pa√≠ses y compuestos por grandes marcas posicionadas de diversas industrias. Falabella Retail, Sodimac, Banco Falabella, Tottus, Mallplaza, Falabella.com, Falabella Inmobiliario. Cada una de √©stas nos hace ser quienes somos, y es entre todos, como Un Solo Equipo, que buscamos diariamente reinventarnos y superar las experiencias de nuestros clientes.
Si eres trabajador de Falabella, revisa todos los cursos disponibles en la Academia Falabella, que te ayudar√°n a seguir impulsando tu desarrollo y preparar tu pr√≥xima aventura con nosotros!
SOMOS UNA EMPRESA QUE APOYA LA LEY 21015, APOYAMOS LA DIVERSIDAD Y LA INCLUSI√ìN EN TODAS SUS FORMAS, SIN IMPORTAR RELIGI√ìN, RAZA, G√âNERO, SITUACI√ìN DE DISCAPACIDAD, NACIONALIDAD.
Funciones Del Cargo
¬°Si tienes una mente inquieta y te gusta so√±ar en grande, este llamado es para ti!
En Falabella Retail buscamos a nuestro/a pr√≥ximo/a Data Engineer, con base en Santiago, Chile.
Somos Falabella, UN equipo diverso con m√°s de 100 mil colaboradores compuesto por grandes marcas: Falabella Retail, Sodimac, Banco Falabella, Seguros Falabella, Tottus, Mallplaza, Open Plaza y Linio. Hoy tenemos presencia en 7 pa√≠ses de Am√©rica Latina, adem√°s de oficinas en China e India.
¬øCu√°l es el principal objetivo del cargo?
Liderar la construcci√≥n y mantenci√≥n de estructuras de datos, as√≠ como la arquitectura tecnol√≥gica requerida para el procesamiento de apps.
¬øQu√© har√°s en el d√≠a a d√≠a?
-  Desarrollo, implementaci√≥n de procesos ETL.
-  Levantamiento de requerimientos funcionales y t√©cnicos relacionados con los clientes internos.
-  Implementar modelos de datos automatizados para transformar datos de acuerdo a los requisitos del negocio.
-  Migraci√≥n de datos desde entornos on-premise a entornos Cloud.
-  Trabajar con tecnolog√≠as Google Cloud Platform (Big Query).
¬øQu√© necesitas para postular?
-  Profesional: Ingenier√≠a Civil en Computaci√≥n, Inform√°tica, Sistemas o carrera af√≠n.
-  Conocimiento en SQL (excluyente)
-  S√≥lidos conocimientos en Google Cloud Platform (excluyente)
-  Conocimiento avanzado en Python (excluyente)
-  Conocimiento y experiencia trabajando en GIT (excluyente)
-  Disponibilidad para ir a la oficina al menos 2 veces por semana (Las Condes) (excluyente)
En Nuestro Equipo Encontrar√°s
-  Espacios para crear e innovar.
-  Ser√°s parte de un lugar lleno de oportunidades de desarrollo.
-  Tener un trabajo con sentido y donde se promueve la calidad de vida.
-  Participar en voluntariados.
-  ¬°Pertenecer a una empresa llena de energ√≠a!
Si disfrutas nuevos desaf√≠os con alta responsabilidad y exposici√≥n en el epicentro de la transformaci√≥n del retail en Latinoam√©rica, ¬°s√∫mate a trabajar con nosotros!
Somos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusi√≥n en todas sus formas, sin importar religi√≥n, raza, g√©nero, situaci√≥n de discapacidad, nacionalidad.
Requisitos
- Profesional: Ingenier√≠a Civil en Computaci√≥n, Inform√°tica, Sistemas o carrera af√≠n.
- Conocimiento en SQL (excluyente)
- S√≥lidos conocimientos en Google Cloud Platform (excluyente)
- Conocimiento avanzado en Python (excluyente)
- Conocimiento y experiencia trabajando en GIT (excluyente)
- Disponibilidad para ir a la oficina al menos 2 veces por semana (Las Condes) (excluyente)
Condiciones Oferta
Descripci√≥n proceso de selecci√≥n:
El proceso de selecci√≥n se realiza a trav√©s de Aira - plataforma de reclutamiento dise√±ado para mejorar tu experiencia de postulaci√≥n.
Para Postular Solo Necesitas
-  Postular a la oferta
-  Revisar tu email
-  Ingresar a Aira y contestar las preguntas y/o pruebas solicitadas
Luego, si vemos que tu perfil se ajusta a lo que estamos buscando, te contactaremos por email (a trav√©s de Aira) para seguir a la etapa presencial.
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,Retail,GCP
Data Engineer,NeuralWorks,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205500303/,"NeuralWorks es una compa√±√≠a de alto crecimiento fundada hace 3 a√±os. Estamos trabajando a toda m√°quina en cosas que dar√°n que hablar.
Somos un equipo donde se unen la creatividad, curiosidad y la pasi√≥n por hacer las cosas bien. Nos arriesgamos a explorar fronteras donde otros no llegan: un modelo predictor basado en monte carlo, una red convolucional para detecci√≥n de caras, un sensor de posici√≥n bluetooth, la recreaci√≥n de un espacio ac√∫stico usando finite impulse response.
Estos son solo algunos de los desaf√≠os, donde aprendemos, exploramos y nos complementamos como equipo para lograr cosas impensadas.
Trabajamos en proyectos propios y apoyamos a corporaciones en partnerships donde codo a codo combinamos conocimiento con creatividad, donde imaginamos, dise√±amos y creamos productos digitales capaces de cautivar y crear impacto.
üëâ Conoce m√°s sobre nosotros
 Descripci√≥n del trabajo
El equipo de Data y Analytics trabaja en diferentes proyectos que combinan vol√∫menes de datos enormes e IA, como detectar y predecir fallas antes que ocurran, optimizar pricing, personalizar la experiencia del cliente, optimizar uso de combustible, detectar caras y objetos usando visi√≥n por computador.
Dentro del equipo multidisciplinario con Data Scientist, Translators, DevOps, Data Architect, tu rol ser√° clave en construir y proveer los sistemas e infraestructura que permiten el desarrollo de estos servicios, formando los cimientos sobre los cuales se construyen los modelos que permiten generar impacto, con servicios que deben escalar, con alt√≠sima disponibilidad y tolerantes a fallas, en otras palabras, que funcionen. Adem√°s, mantendr√°s tu mirada en los indicadores de capacidad y performance de los sistemas.
En cualquier proyecto que trabajes, esperamos que tengas un gran esp√≠ritu de colaboraci√≥n, pasi√≥n por la innovaci√≥n y el c√≥digo y una mentalidad de automatizaci√≥n antes que procesos manuales.
Como Data Engineer, Tu Trabajo Consistir√° En
- Participar activamente durante el ciclo de vida del software, desde inception, dise√±o, deploy, operaci√≥n y mejora.
- Apoyar a los equipos de desarrollo en actividades de dise√±o y consultor√≠a, desarrollando software, frameworks y capacity planning.
- Desarrollar y mantener arquitecturas de datos, pipelines, templates y est√°ndares.
- Conectarse a trav√©s de API a otros sistemas (Python)
- Manejar y monitorear el desempe√±o de infraestructura y aplicaciones.
- Asegurar la escalabilidad y resiliencia.
 Calificaciones clave
- Estudios de Ingenier√≠a Civil en Computaci√≥n o similar.
- Experiencia pr√°ctica de al menos 3 a√±os en entornos de trabajo como Data Engineer, Software Engineer entre otros.
- Experiencia con Python. Entendimiento de estructuras de datos con habilidades anal√≠ticas relacionadas con el trabajo con conjuntos de datos no estructurados, conocimiento avanzado de SQL, incluida optimizaci√≥n de consultas.
- Pasi√≥n en problem√°ticas de procesamiento de datos.
- Experiencia con servidores cloud (GCP, AWS o Azure), especialmente el conjunto de servicios de procesamiento de datos.
- Buen manejo de ingl√©s, sobre todo en lectura donde debes ser capaz de leer un paper, art√≠culos o documentaci√≥n de forma constante.
- Habilidades de comunicaci√≥n y trabajo colaborativo.
¬°En NeuralWorks nos importa la diversidad! Creemos firmemente en la creaci√≥n de un ambiente laboral inclusivo, diverso y equitativo. Reconocemos y celebramos la diversidad en todas sus formas y estamos comprometidos a ofrecer igualdad de oportunidades para todos los candidatos.
‚ÄúLos hombres postulan a un cargo cuando cumplen el 60% de las calificaciones, pero las mujeres s√≥lo si cumplen el 100%.‚Äù D. Gaucher , J. Friesen and A. C. Kay, Journal of Personality and Social Psychology, 2011.
Te invitamos a postular aunque no cumplas con todos los requisitos.
 Nice to have
- Agilidad para visualizar posibles mejoras, problemas y soluciones en Arquitecturas.
- Experiencia en Infrastructure as code, observabilidad y monitoreo.
- Experiencia en la construcci√≥n y optimizaci√≥n de data pipelines, colas de mensajes y arquitecturas big data altamente escalables.
- Experiencia en procesamiento distribuido utilizando servicios cloud.
 Beneficios
- MacBook Air M2 o similar (con opci√≥n de compra hiper conveniente)
- Bono por desempe√±o
- Bono de almuerzo mensual y almuerzo de equipo los viernes
- Seguro complementario de salud y dental
- Horario flexible
- Flexibilidad entre oficina y home office
- Medio d√≠a libre el d√≠a de tu cumplea√±os
- Financiamiento de certificaciones
- Inscripci√≥n en Coursera con plan de entrenamiento a medida
- Estacionamiento de bicicletas
- Vestimenta informal
- Programa de referidos
- Salida de ‚Äúteambuilding‚Äù mensual        
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",OTHER
Ingeniero de Datos,Devaid,Chile,2025-04-10,https://www.linkedin.com/jobs/view/4205299283/,"En Devaid> nos apasionan los desaf√≠os tecnol√≥gicos y nuestros clientes lo saben. Por lo anterior, nos plantean problem√°ticas que nos obligan a estar constantemente probando e implementando nuevas tecnolog√≠as.
Trabajamos fuertemente en la nube ya que somos Partner Premier de Google Cloud en Chile, por lo que tendr√°s la oportunidad de formarte como un profesional cloud.
Dependiendo de las necesidades del cliente, ofrece soluciones web, m√≥viles, integraci√≥n de sistemas, entre otros. Esto permite acceder a la herramienta sin importar el dispositivo ni el lugar d√≥nde se encuentra. Permitimos el trabajo colaborativo entre m√∫ltiples usuarios manteniendo una base centralizada de informaci√≥n.
 Funciones del cargo
Esperamos Que Puedas Desempe√±arte En Las Siguientes Actividades
- Creaci√≥n de pipelines de carga y transformaci√≥n de datos.
- Modelamiento de datos y creaci√≥n de Data Warehouse y Data Lakes.
- Integraci√≥n de sistemas.
- Creaci√≥n de modelos de machine learning con herramientas low code autoML.
Vas a participar como ingeniero de datos en equipos de consultores que prestan servicios a empresas importantes en Chile. En estos equipos participan distintos perfiles, tales como desarrolladores de software, arquitectos de datos y data scientists. Los servicios se prestan de forma remota y son prestados por proyecto (no es outsourcing de recursos), por lo que puedes trabajar desde tu casa sin problemas. Diariamente vas a tener reuniones con tu equipo para coordinar actividades y resolver temas complejos que vayan surgiendo.
 Requerimientos del cargo
Los requisitos para un buen desempe√±o de las funciones son:
- 1 a√±o de experiencia como Data Engineer. 
- Programaci√≥n en lenguaje Python, NodeJS o Java (al menos uno de los 3). 
- Conocimiento de soluciones de Data Warehouse y ETL. 
- Conocimiento de plataformas de procesamiento de datos como Apache Spark, Dataflow o similares. 
- Haber trabajado previamente con alguna nube p√∫blica (AWS, Azure o GCP).
Si no cumples alguno de estos puntos no te desanimes, queremos conocerte igualmente.
El trabajo es 100% remoto, pero es necesario que tengas RUT y/o papeles al d√≠a en Chile.
 Deseables
Suman puntos en tu postulaci√≥n si cumples alguna de las siguientes habilidades, ninguno de estos son excluyentes:
- Conocimiento de herramientas Google Cloud, entre ellas Google BigQuery, Dataflow, Data Fusion y Pub Sub. 
- Experiencia en plataformas de deployment de infraestructura como Terraform. 
- Experiencia utilizando la herramienta de consola gcloud. 
 Beneficios
Prometemos un ambiente muy grato de trabajo, lleno de desaf√≠os y donde podr√°s ver los proyectos en los que estas involucrada/o siendo utilizados en un corto tiempo activamente por nuestros clientes, lo que siempre es muy gratificante.
Otras Actividades
- Actividades mensuales (Cupones de Food delivery, juegos en l√≠nea, actividades grupales).
- Actividad paseo anual: La empresa se junta por 2 d√≠as en alg√∫n lugar tur√≠stico para realizar actividades grupales y unir al equipo.
- D√≠a libre flexible en tu cumplea√±os.
- Capacitaciones en lo que m√°s te guste.
- Certificaciones Google Cloud: Programa de certificaci√≥n en distintas ramas profesionales de GCP, gracias a que somos Partner Premier de Google Cloud en Chile.        
            
                            
            ",Entry level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",GCP
Data Engineer (GCP & DataFlow & Bigquery),Option,Santiago Metropolitan Area,2025-04-12,https://www.linkedin.com/jobs/view/4208792219/,"¬øQui√©nes somos?
En 
Option
, creemos en un mundo donde las soluciones tecnol√≥gicas no tienen l√≠mites. Nuestra misi√≥n es transformar los desaf√≠os en oportunidades mediante la creaci√≥n de soluciones innovadoras que potencien la Aceleraci√≥n Digital. Nuestro equipo es din√°mico, colaborativo y apasionado por la tecnolog√≠a. √önete a una organizaci√≥n que est√° redefiniendo c√≥mo el mundo utiliza los datos y la tecnolog√≠a para resolver problemas complejos.
¬øQu√© buscamos?
Estamos en la b√∫squeda de un/a 
Ingeniero/a de Datos
 para unirse al equipo de Data Services. Este rol ser√° clave en el levantamiento, an√°lisis y migraci√≥n de procesos ETL desde un Data Lake mal gobernado hacia una arquitectura moderna sobre Google Cloud Platform (GCP). ¬°Te estamos buscando!
¬øQu√© te ofrece este puesto?
- Participaci√≥n en un proceso estrat√©gico de migraci√≥n a la nube.
- Un entorno de trabajo colaborativo y con l√≠deres t√©cnicos accesibles.
- Uso de tecnolog√≠as modernas como GCP, Dataflow y BigQuery.
- Trabajo conjunto con equipos de anal√≠tica, desarrollo y operaci√≥n.
¬øCu√°les ser√°n tus principales responsabilidades?
- Levantar y documentar los ETLs actuales en Data Services.
- Analizar el ambiente de datos y planificar su migraci√≥n a GCP.
- Tomar iniciativa en la migraci√≥n de ETLs cr√≠ticos.
- Resolver incidencias relacionadas a ETLs mediante la mesa de ayuda.
- Participar en el dise√±o del plan de migraci√≥n.
- Colaborar con los l√≠deres t√©cnicos y equipos multidisciplinarios.
¬øQu√© necesitas para ser nuestro pr√≥ximo Ingeniero de Datos?
Habilidades T√©cnicas Excluyentes
- Oracle
- Python
- Dataflow (GCP)
- Dataform (GCP)
- GitLab
- BigQuery (GCP)
- Data Modeling
- Composer (GCP)
Habilidades T√©cnicas Deseables
- Oracle Data Integrator (ODI)
Ubicaci√≥n: LATAM
Modalidad de trabajo:
 100% Remoto
¬°√önete a nuestro equipo y transforma el futuro con nosotros!
https://www.option.tech        
            
                            
            ",Entry level,Full-time,Information Technology,Information Technology & Services,GCP
Data Engineer,ICONSTRUYE,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205295718/,"En ICONSTRUYE, hemos estado a la vanguardia de la tecnolog√≠a en la construcci√≥n durante m√°s de 20 a√±os. Nuestra robusta plataforma tecnol√≥gica es un testimonio de nuestra experiencia y compromiso con la industria. Con m√°s de 4,000 clientes en Chile, Colombia y Per√∫, nos enorgullecemos de proporcionar soluciones integrales que simplifican la cadena de abastecimiento. Buscamos un Ingeniero de Datos que se una a nosotros en la transformaci√≥n de la industria de la construcci√≥n, siendo el puente entre los datos brutos y aquellos que toman decisiones cr√≠ticas.
Tus Funciones Principales
Tu misi√≥n:
 Ser el puente entre los datos brutos y quienes necesitan realizar an√°lisis y/o tomar decisiones con esos datos.
- Garantizar la calidad, integridad y seguridad de los datos.
- Colaborar con diversos stakeholders para comprender sus necesidades de datos.
- Desarrollar procesos de extracci√≥n, transformaci√≥n y carga (ETL) de datos para nuestro data lake, proporcionando informaci√≥n valiosa para el an√°lisis y toma de decisiones.
- Implementar nuevas bases de datos y/o data warehouses para satisfacer las necesidades de la empresa.
- Contribuir a la definici√≥n de pol√≠ticas de gobernanza de datos.
- Ser una autoridad en la creaci√≥n, implementaci√≥n y operaci√≥n de soluciones escalables y de bajo costo, facilitando el flujo de datos desde sistemas de producci√≥n hasta el data lake.
Requerimientos T√©cnicos
- Dominio de Python o Go. 
- Dominio de SQL. 
- Conocimiento de base de datos relacionales y no relacionales (NoSQL). 
- Conocimiento de AirFlow, Luigi, Dagster. 
- Conocimientos de Kafka y/o RabbitMQ. 
- Conocimiento en Docker y Kubernetes. 
Beneficios Que Ofrecemos
- üå¥ 5 d√≠as extras de descanso al a√±o.
- üçî Tarjeta amipass para utilizar en restaurantes, delivery y supermercados.
- üë®‚Äç‚öïÔ∏è Seguro complementario de salud, dental y de vida.
- üè† Modalidad de trabajo h√≠brido.
- üì† Flexibilidad con permisos para tr√°mites y asuntos familiares.
- üë©‚Äçüë¶ Jornada reducida en d√≠as de vacaciones escolares (viernes medio d√≠a).
- üéÇ Tarde libre en tu cumplea√±os.
¬°√önete a nosotros y s√© parte de nuestra misi√≥n de transformar la industria de la construcci√≥n!
                
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",OTHER
Ingeniero de Datos ($1.400.000 l√≠quidos),Vector,"Santiago, Santiago Metropolitan Region, Chile",2025-04-07,https://www.linkedin.com/jobs/view/4203857279/,"Somos una empresa L√≠der en el rubro TI. Nos encontramos en la b√∫squeda de Ingeniero de Datos, con experiencia en extracci√≥n de datos desde los sistemas fuente de est√°ndares industriales y el√©ctricos y su almacenaje en los destinos correspondientes, as√≠ como tambi√©n el asegurar la continuidad del funcionamiento de aplicaciones y redes OT que proporcionan datos a PMAC y ROCC.
Principales Tareas
- Sistematizar el traspaso de datos desde los distintos sistemas de la compa√±√≠a hacia los repositorios correspondientes para su consumo.
- Participar en proyectos y entregar soluciones t√©cnicas, procesos y requisitos.
- Enfoque en la creaci√≥n de indicadores y KPI relevantes de las diferentes aplicaciones para reportar a nivel t√©cnico y administrativo.
- Realizar revisiones continuas de monitoreo para asegurarse de la continuidad del servicio.
- Monitorear y controlar solicitudes y requerimientos de soporte (gesti√≥n de tickets).
- Gestionar cualquier proceso de solicitud de cambio, asegur√°ndose de que todas las solicitudes est√©n debidamente documentadas y rastreadas. 
- Entregar soporte para que los servicios de OT se entreguen de acuerdo con los procedimientos operativos est√°ndar y/o SLAs acordados; con enfoque en el servicio operativo, resoluci√≥n de problemas y respuesta √°gil para el usuario final.
- Escalar consultas complejas a la organizaci√≥n de soporte especializado correspondiente.
- Identificar oportunidades de mejora del servicio a partir del an√°lisis de tendencias de datos y las necesidades y aportes de los clientes/usuarios.
- Involucrarse con stakeholders clave y para comprender sus requisitos y transmitir al √°rea de resoluci√≥n correspondiente. 
Conocimientos y experiencia 
- Estudios t√©cnicos o profesionales en Telecomunicaciones, Instrumentaci√≥n, Sistemas, Computaci√≥n, Inform√°tica, Electr√≥nica o carreras afines).
- Instrumentista con conocimiento en programaci√≥n y transferencia de datos, o Ingeniero de Datos con conocimiento en protocolos industriales y sus est√°ndares de comunicaci√≥n.
- Conocimientos de redes de comunicaciones y soluciones de transporte de datos.
- Gesti√≥n de datos y visualizaci√≥n usando herramientas cloud (Google, Microsoft).
- Conocimientos de un lenguaje de scripting, preferiblemente Python.
- Manejo b√°sico de base de datos SQL.
- Conocimientos b√°sicos en gesti√≥n de accesos e identidades.
- Conocimientos b√°sicos en administraci√≥n de servidores.
- Experiencia laboral de 5 a√±os preferiblemente en empresas industriales.
- Deseable manejo de ingles a nivel t√©cnico intermedio.
Conocimientos espec√≠ficos
- Conocimiento de protocolos industriales del sector el√©ctrico (IEC-60870-5-104, Modbus, DNP 3.0).
- Protocolos Industriales de comunicaci√≥n: Modbus TCP/IP, JSON, CSV, DNP3, SQL.
- Conocimiento de sistemas SCADA.
- Conocimientos de protocolos de transici√≥n con industria 4.0 (Modbus TCP, OPC UA, MQTT, HTTP, etc.).
Fundamentos de ciberseguridad.
Horario
Lunes a viernes 08:00 a 18:00 / 08:30 a 18:30
Beneficios
-  Reajuste anual de sueldo de acuerdo a IPC
-  Bonificaci√≥n anual por desempe√±o laboral.
-  Posibilidad de acceder a cursos de capacitaci√≥n en las diversas tem√°ticas del cargo.
-  Convenios de Salud, Dentales y √≥pticos, accesos a descuentos preferenciales y facilidades de pagos mediante descuentos por planilla sin inter√©s.
-  Posibilidad de entrega de aguinaldo de fiestas patrias y Navidad conforme a cumplimiento de antig√ºedad.
-  Convenio seguro Oncol√≥gico a valor preferencial y con aporte de la organizaci√≥n y del colaborador.
-  Regalo de gift card por nacimiento de hijo (a).
-  Convenios bancarios (scotiabank y Banco de Chile) para planes de tarjetas de cuentas vista y corriente a valores preferenciales.        
            
                            
            ",Not Applicable,Contract,Information Technology,Information Technology & Services,OTHER
Data Engineer Soluciones de Datos,LISIT,"Biob√≠o Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205294845/,"En *Lisit*, nos dedicamos a crear, desarrollar e implementar servicios de software que ofrecen herramientas de automatizaci√≥n y optimizaci√≥n. Nuestra misi√≥n es promover la eficacia en la operatividad de nuestros clientes a trav√©s de un soporte consultivo que integra diversas herramientas y pr√°cticas. Buscamos contribuir al √©xito de las transformaciones empresariales mediante estrategias integrales de acompa√±amiento e implementaci√≥n.
 Que estamos buscando
- Dise√±ar, desarrollar y mantener infraestructuras y pipelines de datos escalables y confiables.
- Optimizar el almacenamiento, procesamiento y recuperaci√≥n de datos para un funcionamiento eficiente e impecable.
- Colaborar con equipos de diferentes departamentos para recopilar y analizar los requisitos de datos.
- Garantizar la calidad, integridad y seguridad de los datos durante todo el ciclo de vida de estos.
- Mantenerse actualizado sobre los √∫ltimos avances, desarrollos y enfoques en ingenier√≠a de datos.
 ¬øQu√© habilidades y experiencia necesitas?
- Fuertes habilidades anal√≠ticas y de resoluci√≥n de problemas.
- Al menos 3 a√±os de experiencia en ingenier√≠a de datos.
- Experiencia comprobada en el dise√±o y desarrollo de data pipelines y procesos ETL, preferiblemente con Azure Data Factory.
- Amplia experiencia en SQL y dominio de al menos un lenguaje de ingenier√≠a de datos, como Python o Scala.
- Experiencia con Spark, Airflow y tecnolog√≠as Big Data relacionadas.
- Familiaridad con plataformas de datos basadas en la nube como AWS, Azure o GCP.
- Excelentes habilidades de comunicaci√≥n y colaboraci√≥n.
 Deseable
Se valorar√° la experiencia con herramientas de BI como Power BI y Microsoft Fabric. Tambi√©n es deseable contar con alguna de las siguientes certificaciones: DP-203, PL-300, DP-600 y/o DP-700.
 √önete a nosotros
En *Lisit* ofrecemos un ambiente de trabajo innovador y colaborativo. Nos aseguramos de que nuestros empleados disfruten de un equilibrio entre trabajo y vida personal, con programas de capacitaci√≥n y desarrollo continuo. Valoramos tu entusiasmo y pasi√≥n por la ingenier√≠a de datos.
Estamos emocionados por conocer a personas con una mentalidad abierta y dispuestas a enfrentar nuevos desaf√≠os. ¬°Si est√°s listo para innovar y crecer con nosotros, te queremos en nuestro equipo!
En el caso de residir en Santiago, debe tener disponibilidad para viajar una o dos semanas a Los Angeles, regi√≥n del BioB√≠o
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",AZURE
Data Engineer,Seeds,"Santiago Metropolitan Region, Chile",2025-04-07,https://www.linkedin.com/jobs/view/4189755534/,"¬øSos 
Data Engineer
? Entonces‚Ä¶ ¬øQu√© est√°s esperando para sumarte a nuestra comunidad de Seeders? ¬°Aplica a nuestra comunidad y accede a trabajo on-demand en las empresas l√≠deres, sumate al Present of Work!
¬øQui√©nes somos?
Somos una 
comunidad
 que re√∫ne al mejor talento on-demand de Latinoam√©rica, y lo conecta con las empresas l√≠deres de la regi√≥n. Gestionamos el match perfecto entre las necesidades de las empresas y el talento con las competencias y la experiencia buscada, fomentando flexibilidad y el desarrollo profesional de nuestra comunidad.
No somos una plataforma m√°s de freelancers, Seeds lidera un dream team de profesionales altamente calificados que eligen d√≥nde, c√≥mo y para qui√©n trabajar, disfrutando as√≠ de contribuir a una misi√≥n m√°s grande, definiendo y moldeando la forma en que trabajamos.
Estamos buscando sumar a nuestro Talent Pool roles de 
Data Engineer
 para nuestra comunidad de Seeders.
Estas son algunas de las responsabilidades usuales del rol:
- Dise√±ar, construir y mantener arquitecturas de datos robustas y escalables.
- Desarrollar y optimizar pipelines de datos para recopilaci√≥n, almacenamiento, procesamiento y an√°lisis de grandes vol√∫menes de datos.
- Implementar modelos de datos y algoritmos para resolver problemas de negocio y proveer insights accionables.
- Trabajar en estrecha colaboraci√≥n con equipos de data scientists y analistas para apoyar sus requisitos de datos y facilitar el an√°lisis de datos.
- Asegurar la integridad, disponibilidad y confidencialidad de los datos a trav√©s de las mejores pr√°cticas de seguridad y gobernanza de datos.
- Mantenerse al d√≠a con las √∫ltimas tecnolog√≠as y tendencias en el campo de la ingenier√≠a de datos.
Requisitos
- Experiencia m√≠nima de 3 a√±os en roles de ingenier√≠a de datos.
- Fuerte dominio de lenguajes de programaci√≥n como Python, Java o Scala.
- Experiencia trabajando con grandes vol√∫menes de datos y herramientas de procesamiento de datos (como Hadoop, Spark).
- Conocimientos en bases de datos SQL y NoSQL, as√≠ como en soluciones de almacenamiento de datos en la nube (AWS, Google Cloud, Azure).
- Capacidad para trabajar en entornos √°giles y multidisciplinarios.
- Ingl√©s intermedio (deseable).
¬øPor qu√© sumarte a nuestra comunidad de Seeders?
Eleg√≠ tus proyectos.
Trabaj√° desde donde vos quieras.
Eventos de networking.
Asesoramiento personalizado.
Seeds Academy: Potencia tu desarrollo profesional adquiriendo nuevas skills (upskilling & reskilling), participando de webinars, Bootcamps y otras acciones exclusivas para la comunidad.
No dejes de sumarte a nuestra comunidad de Seeds y aplicar a oportunidades de empresas lideres de la regi√≥n. ¬°Te esperamos!        
            
                            
            ",Mid-Senior level,Full-time,Consulting,"Technology, Information and Media",OTHER
Senior Data Engineer Python,23people,Chile,2025-04-10,https://www.linkedin.com/jobs/view/4205294906/,"√önete a Equifax Chile como Senior Data Engineer Python Somos l√≠deres en soluciones de informaci√≥n y tecnolog√≠a, operando globalmente para transformar el uso de la informaci√≥n con transparencia y seguridad. Estamos en un proyecto de migraci√≥n clave que requiere revisi√≥n de pipelines de datos, creaci√≥n de queries, dise√±o de flujos de procesos, an√°lisis de sistemas legados y documentaci√≥n t√©cnica y de negocio. Valoramos la innovaci√≥n, la colaboraci√≥n y el conocimiento t√©cnico. Si tienes habilidades anal√≠ticas excepcionales y pasi√≥n por la tecnolog√≠a, ¬°aplica hoy y s√© parte de nuestra transformaci√≥n digital!
 Funciones del cargo
¬øQu√© har√°s en tu d√≠a a d√≠a?
El profesional colaborar√° con un equipo multidisciplinario en un proyecto de expansi√≥n internacional, enfocado en la migraci√≥n estrat√©gica de la plataforma hacia nuevos mercados. Su participaci√≥n ser√° fundamental para asegurar una implementaci√≥n eficiente que considere las particularidades de cada pa√≠s destino, garantizando as√≠ el √©xito de esta iniciativa global.
Algunas De Sus Tareas Diarias Son Las Siguientes
- Implementar mecanismos para verificar la integridad de los datos migrados
- Implementar transformaciones espec√≠ficas para requisitos regionales
- Dirigir el equipo t√©cnico durante las fases cr√≠ticas de migraci√≥n
- Gestionar el proceso integral de ETL entre diversos sistemas, desarrollando y optimizando los esquemas de mapeo necesarios para garantizar la compatibilidad entre las estructuras de datos de origen y destino.
 Requerimientos del cargo
Skills
T√©cnicas
- Python
- BigQuery/SQL
- GitHub
- Apache Beam/Spark/Google Dataflow
Personales
- Capacidad de autogesti√≥n
- Buenos skills de comunicaci√≥n
- Fortaleza en trabajo en equipo
- Adaptaci√≥n al cambio (trabajar√°n en distintas geos de Latam)
Contrato indefinido desde el inicio con 23people
Modalidad: Home Office, Con residencia en Chile (Deber√°s ir a buscar el PC en primera instancia)
Experiencia: Desde 5 a√±os en adelante
Horario: Lunes a Jueves de 8:30 a 6:30 y Viernes de 8:30 a 5:30 hrs.
 Deseables
- Perfil Anal√≠tico
- UnitTest
- AirFlow
- PySpark
- CI/CD
- Postman
- Jmeter
 Beneficios
Algunos de nuestros beneficios
- Seguro complementario: Seguro de salud, vida y dental
- Curso de ingl√©s: En nuestro programa de formaci√≥n en idioma ingl√©s, ofrecemos dos modalidades para adaptarnos a tus necesidades y objetivos.
- Reembolso de certificaciones internacionales: Apoyamos el crecimiento profesional, por lo que te reembolsamos el costo de un examen de certificaci√≥n internacional que quieras realizar.
- Bono de vacaciones: Por cada semana que te tomes de vacaciones te otorgamos una compensaci√≥n.
- Aguinaldos en fiestas patrias y Navidad: Queremos que en fechas tan especiales la pases bien junto a tu familia, por lo que te entregamos un bono en septiembre y diciembre
- D√≠a libre de cumplea√±os: Puedes optar por tomar tu d√≠a libre, el d√≠a previo a tu cumplea√±os, el mismo d√≠a de tu cumplea√±os o el d√≠a posterior.        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",GCP
Ingeniero de Datos/ Dbt,BC Tecnolog√≠a,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205500332/,"En BC Tecnolog√≠a, somos una consultora de TI con m√°s de seis a√±os de experiencia, especializada en ofrecer soluciones personalizadas para nuestros clientes en sectores como servicios financieros, seguros, retail y gobierno. Nos enfocamos en consultor√≠a, outsourcing, desarrollo de proyectos y formaci√≥n de equipos, siempre con un claro compromiso hacia la satisfacci√≥n del cliente. Como parte de nuestro equipo, el ingeniero/a de datos jugar√° un papel clave en la creaci√≥n de soluciones basadas en tecnolog√≠as de la nube, impulsando la innovaci√≥n y la colaboraci√≥n en un entorno de trabajo √°gil.
 Responsabilidades Clave
El Ingeniero/a De Datos Ser√° Responsable De
- Dise√±ar y mantener pipelines de datos utilizando BigQuery y DBT.
- Implementar tareas programadas en Google Cloud Platform (GCP) para la ingesta y procesamiento continuo de datos.
- Construir y documentar modelos de datos optimizados para su an√°lisis.
- Validar y realizar pruebas para garantizar la precisi√≥n de los datos transformados.
- Realizar seguimiento y documentaci√≥n de cambios en modelos y sus transformaciones.
 Requisitos T√©cnicos
Buscamos Un Ingeniero/a De Datos Con
- Experiencia avanzada en BigQuery y DBT.
- Conocimiento pr√°ctico en Google Cloud Platform, incluyendo la programaci√≥n de tareas y almacenamiento.
- S√≥lido manejo de SQL y experiencia en modelado de datos.
- Capacidad para documentar procesos y realizar pruebas de calidad de datos de manera eficiente.
 Lo que ofrecemos
Brindamos un contrato por proyecto de 12 meses en modalidad h√≠brida, lo que permite combinar trabajo remoto con visitas a la oficina 2 a 3 d√≠as a la semana. Tambi√©n garantizamos un enfoque en la inclusi√≥n, en cumplimiento con la Ley N¬∫ 21.015, promoviendo un entorno donde todos los empleados puedan prosperar.
 Beneficios        
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",GCP
Ingeniero de Datos Maestros (Proyecto Corporativo),Agrosuper,"Rancagua, O'Higgins Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205297494/,"En Agrosuper, tenemos la misi√≥n de llevar alimentos de la m√°s alta calidad a las familias de Chile y el mundo. Nos mueve el deseo de alimentar el talento y las ganas de crecer constantemente. Buscamos mejorar y fomentar un entorno donde todos disfruten lo bueno de la vida, por lo que valoramos a las personas, que son el alma de nuestra organizaci√≥n. Este cargo de Ingeniero de Datos Maestros (Corporativo) es fundamental para garantizar la calidad y disponibilidad de nuestros Datos Maestros a trav√©s de la optimizaci√≥n de procesos y recursos en nuestras unidades de negocio.
 Principales Funciones
- Gestionar los Datos Maestros en diversos Proyectos Corporativos.
- Identificar y proponer mejoras, optimizando y eficientando nuestros procesos internos.
- Gestionar la creaci√≥n de c√≥digos de distintos Datos Maestros considerados cr√≠ticos por la Organizaci√≥n.
- Definir y configurar en SAP Estrategias de Liberaci√≥n (Compras).
- Validar y autorizar √ìrdenes de Transportes Customizing en SAP.
- Validar est√°ndares de los Datos Maestros en SAP.
- Evaluar y desarrollar parametrizaciones t√©cnicas de Customizing alrededor de los Datos Maestros en SAP.
- Asesorar al Equipo de Datos Maestros sobre dudas y buenas pr√°cticas en el Gobierno de Datos Maestros.
 Requisitos
- T√≠tulo profesional en √°reas como Ingenier√≠a Civil Industrial, Comercial, Inform√°tica o similar.
- Experiencia laboral m√≠nima de 2 a√±os en roles similares.
- Experiencia en SAP, espec√≠ficamente en Gobierno de Datos Maestros (certificado).
- Conocimientos en herramientas de an√°lisis y visualizaci√≥n, especialmente en Excel a nivel avanzado.
Desirable Skills
Si bien los requisitos mencionados son fundamentales, tambi√©n valoramos habilidades adicionales que pueden enriquecer la experiencia en este rol. Esto incluye certificaciones adicionales en SAP, experiencia en gesti√≥n de proyectos y habilidades en liderazgo y trabajo en equipo. Adem√°s, el deseo de mantenerse al d√≠a con las tendencias en tecnolog√≠a y an√°lisis de datos ser√° considerado un gran plus.
 Beneficios
Agrosuper ofrece un entorno de trabajo inspirador donde se valora el crecimiento tanto profesional como personal. Contamos con planes de crecimiento y desarrollo, capacitaci√≥n continua y becas de estudios, adem√°s de convenios con distintas instituciones. Tambi√©n ofrecemos bonos asociados al desempe√±o para incentivar el trabajo de nuestros colaboradores. Adem√°s, promovemos la inclusi√≥n de colaboradores con discapacidad, asegurando que todos tengan la oportunidad de contribuir a nuestro prop√≥sito de alimentar lo bueno de la vida.
                
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",OTHER
Ingeniero de Datos,AyCA SpA,"Santiago, Santiago Metropolitan Region, Chile",2025-04-11,https://www.linkedin.com/jobs/view/4206696535/,"Company Description: AyCA Spa
Job Description: En AyCA SPA nos encontramos en b√∫squeda de un Ingeniero de Datos.
Prop√≥sito o Misi√≥n del Cargo
El Ingeniero de Datos en Mantenimiento de Planta es responsable de dise√±ar, implementar y gestionar la infraestructura de datos y los sistemas de an√°lisis necesarios para optimizar las estrategias y procesos de mantenimiento. Su rol principal es transformar los datos generados por los equipos, sistemas de monitoreo y actividades de mantenimiento en informaci√≥n valiosa y accionable que permita mejorar la confiabilidad de los activos, reducir costos, predecir fallas y optimizar la planificaci√≥n de las intervenciones.
Principales Responsabilidades
-  Dise√±o e Implementaci√≥n de la Arquitectura de Datos
-  Colaborar con el equipo de mantenimiento y TI para comprender las necesidades de datos y dise√±ar una arquitectura robusta y escalable para la recopilaci√≥n, almacenamiento, procesamiento y an√°lisis de datos de mantenimiento.
-  Seleccionar e implementar las herramientas y tecnolog√≠as adecuadas para la gesti√≥n de datos (bases de datos, data lakes, plataformas de procesamiento en la nube, etc.).
-  Establecer y mantener los procesos de extracci√≥n, transformaci√≥n y carga (ETL/ELT) de datos desde diversas fuentes (CMMS, sensores IoT, registros manuales, etc.).
-  Integraci√≥n de sistemas SCADA y PLCs con tecnolog√≠as cloud (OPC UA, MQTT, REST APIs)
-  Garantizar la calidad, integridad y seguridad de los datos de mantenimiento.
-  Desarrollo de Soluciones de An√°lisis y Reporte
-  Desarrollar modelos de datos y esquemas que faciliten el an√°lisis y la generaci√≥n de insights relevantes para el mantenimiento.
-  Crear dashboards, informes y visualizaciones interactivas que permitan al equipo de mantenimiento monitorear KPIs, identificar tendencias, evaluar la efectividad de las estrategias y tomar decisiones informadas.
-  Implementar t√©cnicas de an√°lisis predictivo (machine learning, inteligencia artificial) para predecir fallas de equipos, optimizar la planificaci√≥n de mantenimiento preventivo y proactivo.
-  Automatizar la generaci√≥n de informes y alertas para facilitar la toma de decisiones en tiempo real.
-  Dise√±ar e implementar flujos de procesamiento de datos industriales.
-  Construir y entrenar modelos de ML para detecci√≥n de fallas y patrones de operaci√≥n.
-  Dise√±ar estrategias para la optimizaci√≥n y escalabilidad del sistema de IA.
-  Integrar modelos de IA con bases de datos y sistemas de control industriales.
-  Asegurar la seguridad y confiabilidad del sistema en entornos industriales.
-  Soporte y Optimizaci√≥n de Sistemas de Datos
-  Monitorear y mantener el rendimiento y la disponibilidad de la infraestructura de datos de mantenimiento.
-  Identificar y resolver problemas relacionados con la calidad, integridad y flujo de datos.
-  Optimizar los procesos de ETL/ELT y las consultas de datos para mejorar la eficiencia del an√°lisis.
-  Mantener la documentaci√≥n t√©cnica de la arquitectura de datos, los procesos y las soluciones implementadas.
-  Colaboraci√≥n y Comunicaci√≥n
-  Trabajar en estrecha colaboraci√≥n con el equipo de mantenimiento (planificadores, supervisores, t√©cnicos), el departamento de TI y otros stakeholders para comprender sus necesidades de datos y ofrecer soluciones efectivas.
-  Comunicar de manera clara y concisa los hallazgos del an√°lisis de datos y las recomendaciones al equipo de mantenimiento y la gerencia.
-  Participar en reuniones y proyectos relacionados con la mejora continua y la transformaci√≥n digital del √°rea de mantenimiento.
-  Capacitar al personal de mantenimiento en el uso de las herramientas y los informes de an√°lisis de datos.
-  Documentar procesos y modelos.
-  Investigaci√≥n y Desarrollo
-  Mantenerse actualizado sobre las √∫ltimas tendencias y tecnolog√≠as en el campo del an√°lisis de datos, la inteligencia artificial y el mantenimiento predictivo.
-  Investigar y proponer nuevas herramientas y t√©cnicas que puedan mejorar la eficiencia y efectividad del mantenimiento basado en datos.
-  Participar en proyectos piloto para la implementaci√≥n de nuevas soluciones de an√°lisis.
Requisitos
-  T√≠tulo profesional en Ingenier√≠a (Inform√°tica, Industrial, Mec√°nica, El√©ctrica o carreras afines) con especializaci√≥n o experiencia en an√°lisis de datos, ciencia de datos o gesti√≥n de informaci√≥n.
Experiencia
-  Plataformas de nube p√∫blica: AWS (IoT Core, Lambda, S3), Azure (IoT Hub, Functions) o Google Cloud (Pub/Sub, Firestore).
-  Dise√±o o implementaci√≥n de dashboards para visualizaci√≥n de datos industriales (Power BI, Grafana, etc.).
-  Haber desarrollado proyectos similares, ya sea como profesional o estudiante (tesis).
-  Experiencia en el desarrollo de modelos de Machine Learning.
-  Experiencia pr√°ctica con Python, pandas, scikit-learn, TensorFlow, XGBoost o similares.
-  Experiencia en arquitectura de datos: bases SQL, ETL, APIs.
-  Conocimientos en integraci√≥n de sistemas industriales mediante APIs REST, OPC-UA o MQTT.
-  Capacidad para dise√±ar arquitecturas escalables y eficientes.
-  Conocimiento en ciberseguridad industrial.
-  Familiaridad con software industriales.
-  Experiencia en desarrollo de aplicaciones para entornos industriales.
Si crees que cumples con las competencias env√≠anos tu CV indicando pretensiones de renta y disponibilidad.
Ay√∫danos a compartir para llegar a mas personas !!
                
            
                            
            ",Entry level,Full-time,Information Technology,Mining,OTHER
Data Engineer AWS ‚Äì Contrato Indefinido.,BC Tecnolog√≠a,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4204878459/,"Company Description: BC Tecnolog√≠a
Job Description: Experiencia de 3 a√±os en:
-  Explotaci√≥n de datos (Tunnig)
-  ETL
-  SQL
-  Python
-  Apache Airflow (Deseable)
-  AWS (Glue, Lambda, S3, Redshift, Dynamodb
-  Trabajo Hibrido
Interesados o referidos favor enviar cv actualizado a [email] indicando en asunto de e-mail cargo al cual postula (Data Engineer AWS)
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,Information Technology & Services,AWS
Data Engineer ‚Äì Proyecto de 6 Meses,BC Tecnolog√≠a,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205297473/,"En BC Tecnolog√≠a, somos una consultora de TI comprometida con ofrecer soluciones innovadoras y adaptadas a las necesidades de nuestros clientes. Con m√°s de 6 a√±os de experiencia en el sector, trabajamos con empresas en diferentes industrias, incluyendo servicios financieros, seguros, retail y gobierno. En este proyecto de Data Engineering, tendr√°s la oportunidad de contribuir al dise√±o y construcci√≥n de pipelines de datos para nuestros clientes, utilizando metodolog√≠as √°giles y colaborando con equipos altamente especializados.
 Responsabilidades del Rol
- Dise√±ar y construir pipelines de datos efectivos para cumplimentar las necesidades anal√≠ticas de nuestros clientes.
- Programar usando lenguajes como Python, Scala o SQL para manipulaci√≥n y transformaci√≥n de datos.
- Implementar y gestionar herramientas de orquestaci√≥n de pipelines, como Airflow, Mage, NiFi o similares.
- Colaborar en pr√°cticas de CI/CD, incluidos conocimientos b√°sicos en Git y versionado de c√≥digo.
- Integrar arquitecturas de datos, con un enfoque en Datalakes, Datawarehouses o Lakehouse.
- Participar en modelado de datos utilizando t√©cnicas dimensional, estrella y copo de nieve, si es requerido.
 Requisitos y Habilidades
Buscamos candidatos que cuenten con al menos 2 a√±os de experiencia en el √°rea de Data Engineering. Deber√°n tener competencias en dise√±o y construcci√≥n de pipelines de datos, as√≠ como experiencia con lenguajes de programaci√≥n pertinentes como Python, Scala o SQL.
Es esencial dominar herramientas de orquestaci√≥n de datos, y tener un conocimiento b√°sico sobre integraciones de CI/CD y flujos de trabajo de versionamiento de c√≥digo. Adicionalmente, es deseable contar con experiencia en arquitecturas de datos y modelado, incluidos Datalakes y t√©cnicas de modelado espec√≠ficas.
La modalidad de trabajo es h√≠brida, lo que permitir√° equilibrar la colaboraci√≥n en persona con flexibilidad laboral.
 Habilidades Deseables
Si bien no es un requisito, consideraremos positivamente la experiencia previa con Datalakes y Datawarehouses, as√≠ como familiaridad con t√©cnicas de modelado como dimensional, estrella o copo de nieve. Esto contribuir√° a un mejor entendimiento del contexto de las soluciones que desarrollaremos.
 Beneficios y Condiciones
Ofrecemos Un Contrato Por Proyecto De 6 Meses, Con Posibilidad De Extensi√≥n. Los Empleados Disfrutar√°n De Un Sueldo a Convenir, Adem√°s De Beneficios Adicionales Como
- Seguro complementario.
- Amipass de $4,500 por d√≠a laborado.
- Convenciones, actividades y bonos.
Estamos ubicados en Alto Las Condes, permitiendo un ambiente de trabajo funcional y moderno. ¬°Nos encantar√≠a contar contigo en nuestro equipo! üåü
                
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",API_Error
Senior Data Engineer,Grupo Falabella,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4205321119/,"Somos m√°s de 90 mil personas que, d√≠a a d√≠a, dedicamos nuestra pasi√≥n y energ√≠a a cumplir nuestro Prop√≥sito de ‚ÄúSimplificar y Disfrutar M√°s la Vida‚Äù. Prop√≥sito que hoy vive a trav√©s de nuestro ecosistema f√≠sico y digital en todas nuestras empresas (Falabella Retail, Sodimac, IKEA, Tottus, Mallplaza, Falabella Inmobiliario, Falabella.com, Linio, Falabella Financiero, Banco Falabella, Falabella Soriana, Seguros Falabella, Fazil, Fpay y Falabella Corporativo) y pa√≠ses (Argentina, Brasil, Chile, China, Colombia, India, M√©xico, Per√∫ y Uruguay).
Si disfrutas nuevos desaf√≠os con alta responsabilidad y exposici√≥n en el epicentro de la transformaci√≥n en Latinoam√©rica, esta oportunidad es para ti. Buscamos un Senior Data Engineerüë®‚Äçüíª para sumarse a uno de nuestros equipo, quien sera el encargado de dise√±ar, construir y mantener sistemas de datos escalables, para el an√°lisis y la toma de decisiones en la organizaci√≥n.
Funciones Del Cargo
Dise√±ar y desarrollar canalizaciones de datos (ETL/ELT) robustas y eficientes. 
Colaborar con equipos de ingenier√≠a de datos.
Implementar y gestionar bases de datos y data warehouses. 
Optimizar el rendimiento de las bases de datos y sistemas de almacenamiento de datos. 
Garantizar la calidad, integridad y seguridad de los datos. 
Automatizar procesos de ingesti√≥n y transformaci√≥n de datos.
Monitorizar y solucionar problemas relacionados con los sistemas de datos. 
Documentar procesos, arquitecturas y mejores pr√°cticas relacionadas con el manejo de datos.
Requisitos
Profesional titulado en Ingenier√≠a Civil Computaci√≥n, Industrial, matem√°tico u el√©ctrico.
Experiencia demostrable como Data Engineer
Experiencia en lenguajes de programaci√≥n Python.
Experiencia con Google Cloud Platform (Composer, Cloud Functions, Bigquery, Dataproc, etc)
Experiencia utilizando git.
Conocimientos profundos en SQL y en bases de datos relacionales y no relacionales
Deseable: Certificaci√≥n Associate Engineer
Deseable: Nivel de Ingl√©s intermedio (B1+)
Deseable: Certificaciones relevantes en tecnolog√≠as de datos y cloud.
Si te apasionan los desafios numerico üöÄüë®‚Äçüíªy buscas ser parte de un gran team, ven y postula con nosotros!!
Somos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusi√≥n en todas sus formas, sin importar religi√≥n, raza, g√©nero, situaci√≥n de discapacidad, nacionalidad.
Conoce m√°s oportunidades para vivir la #ExperienciaFalabella en https://muevete.falabella.com/        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,Financial Services,API_Error
Data Engineer,Mediastream,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4206504298/,"Description
Mediastream is a leading streaming technology company that has been in business for over 16 years. We collaborate with major companies and broadcasters around the world to offer a quality end-to-end solution for content administration, distribution, audiovisual production, and user experience. Our goal is to connect our customers with their audience in a simple and effective way, creating new revenue streams for their businesses.
Role Description
This is a hibrid role for a Data Egineer. The Data Engineer will be responsible for proposing advanced applications of our data, reviewing patterns, deviations to detect trends to optimize dashboards and optimize advertising strategies. Promote new strategies and technologies to process, analyze and leverage customer data and improve user engagement. With the main objective of: Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights, which serve for product roadmap, Develop and manage efficient data pipelines and ETL workflows for the integration of diverse data sources and Use machine learning models and recommendation algorithms to personalize strategies.
Responsibilities
- Create, implement and maintain the company's data architecture.
- Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights for product roadmap.
- Develop and manage data pipelines and ETL workflows for the integration of diverse data sources.
- Use machine learning models and recommendation algorithms to personalize strategies.
- Create interactive visualizations and dashboards for studies to monitor performance and make data-driven decisions.
- Collaborate closely with the development team to integrate, create features and roadmap proposals. 
- Have a product vision and work closely with the marketing and development teams to align strategies with business objectives.
"">
Mediastream is a leading streaming technology company that has been in business for over 16 years. We collaborate with major companies and broadcasters around the world to offer a quality end-to-end solution for content administration, distribution, audiovisual production, and user experience. Our goal is to connect our customers with their audience in a simple and effective way, creating new revenue streams for their businesses.
Role Description
This is a hibrid role for a Data Egineer. The Data Engineer will be responsible for proposing advanced applications of our data, reviewing patterns, deviations to detect trends to optimize dashboards and optimize advertising strategies. Promote new strategies and technologies to process, analyze and leverage customer data and improve user engagement. With the main objective of: Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights, which serve for product roadmap, Develop and manage efficient data pipelines and ETL workflows for the integration of diverse data sources and Use machine learning models and recommendation algorithms to personalize strategies.
Responsibilities
- Create, implement and maintain the company's data architecture.
- Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights for product roadmap.
- Develop and manage data pipelines and ETL workflows for the integration of diverse data sources.
- Use machine learning models and recommendation algorithms to personalize strategies.
- Create interactive visualizations and dashboards for studies to monitor performance and make data-driven decisions.
- Collaborate closely with the development team to integrate, create features and roadmap proposals.
- Have a product vision and work closely with the marketing and development teams to align strategies with business objectives.
Minimum Requirements
- At least 3 years of experience in Data Engineer roles.
- Bachelor's degree in computer science or related field.
- Knowledge in: SQL/No SQL: Advanced, Power BI, Looker, tableau or others: Intermediate, Python and development knowledge: Basic, machine learning, AI or similar technologies: Basic, Identification of cluster patterns, trends, deviations: Intermediate, cloud technologies: Intermediate.
Soft Skills:
- Teamwork
- Decision-making
- Attention to detail
- Adaptability 
"">
- At least 3 years of experience in Data Engineer roles.
- Bachelor's degree in computer science or related field.
- Knowledge in: SQL/No SQL: Advanced, Power BI, Looker, tableau or others: Intermediate, Python and development knowledge: Basic, machine learning, AI or similar technologies: Basic, Identification of cluster patterns, trends, deviations: Intermediate, cloud technologies: Intermediate.
Soft Skills:
- Teamwork
- Decision-making
- Attention to detail
- Adaptability        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,OTHER
Data Engineer AWS,BC Tecnolog√≠a,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205294910/,"En 
BC Tecnolog√≠a
, nos especializamos en la consultor√≠a de TI, ofreciendo un amplio rango de servicios para adaptarnos a las necesidades espec√≠ficas de nuestros clientes, principalmente en finanzas, seguros, retail y gobierno. Nuestro equipo trabaja mediante metodolog√≠as √°giles, lo que nos permite dise√±ar e implementar soluciones tecnol√≥gicas efectivas y dirigidas al cliente. Actualmente, estamos buscando un Data Engineer con experiencia en AWS para sumarse a nuestro equipo y contribuir a proyectos innovadores en la gesti√≥n y explotaci√≥n de datos.
 Responsabilidades del Cargo
- Desarrollar y gestionar procesos de ETL, asegurando la calidad y fiabilidad de los datos.
- Optimizar la explotaci√≥n de datos a trav√©s de t√©cnicas de Tuning.
- Implementar soluciones utilizando herramientas de AWS, incluyendo Glue, Lambda, S3, Redshift y DynamoDB.
- Colaborar con los equipos de desarrollo de software para asegurar la integraci√≥n de datos eficiente.
- Realizar an√°lisis y visualizaci√≥n de datos para apoyar en la toma de decisiones.
- Mantener un enfoque en la innovaci√≥n y la mejora continua de los procesos y herramientas utilizadas.
 Descripci√≥n del Cargo
Buscamos Un Data Engineer AWS Con Un M√≠nimo De 3 A√±os De Experiencia En El Manejo De Datos. El Candidato Ideal Tendr√° Conocimientos S√≥lidos En
- Explotaci√≥n de datos y Tuning.
- Dise√±o e implementaci√≥n de procesos ETL.
- Desarrollo de consultas efectivas en SQL.
- Programaci√≥n en Python.
- Uso de herramientas de orquestaci√≥n como Apache Airflow (deseable).
Valoramos habilidades como el trabajo en equipo, la proactividad y la capacidad para adaptarse a nuevas tecnolog√≠as. La combinaci√≥n de habilidades t√©cnicas y soft skills es esencial para unirse a nuestro equipo din√°mico.
 Habilidades Deseables
Adem√°s de los requisitos mencionados, ser√≠a beneficioso contar con experiencia en:
- Integraciones y gesti√≥n de datos en m√∫ltiples fuentes.
- Implementaci√≥n de soluciones en la nube de AWS.
- Conocimientos en herramientas de visualizaci√≥n de datos.
Estas habilidades ayudar√°n al candidato a integrarse de manera efectiva en nuestros equipos de trabajo y contribuir a proyectos futuros.
 Beneficios de Trabajar con Nosotros
En 
BC Tecnolog√≠a
, valoramos a nuestro equipo y ofrecemos un entorno flexible y beneficios atractivos:
- Contrato indefinido.
- Modalidad h√≠brida, combinando trabajo remoto y en oficina.
- Paquete de beneficios corporativos que incluye salud prepaga de primer nivel para el empleado y su familia.
- Un d√≠a de home office a la semana, junto con desayunos y un comedor en la planta.
- Acceso a un Sport Club y asistencia de un nutricionista.
¬°√önete a nosotros y marca una diferencia en el mundo de la tecnolog√≠a! üéâ
                
            
                            
            ",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",AWS
Data Engineer GCP,Soluciones - Data & Analytics Consulting,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4206574777/,"‚úîÔ∏è
¬øQui√©nes Somos?
Somos una consultora enfocada en Data & Analytics y contamos con m√°s de 20 a√±os de experiencia y exitosa participaci√≥n en implementaci√≥n de proyectos de peque√±a, mediana y gran envergadura. Nuestro equipo, compuesto por consultores multidisciplinarios expertos y certificados, ha entregado soluciones tecnol√≥gicas de calidad que exceden las expectativas de cada cliente. A trav√©s de una metodolog√≠a flexible y adaptable, logramos entregar soluciones adecuadas a la realidad de cada organizaci√≥n, satisfaciendo los est√°ndares de cada una de las empresas que conf√≠an en nosotros.
‚úîÔ∏è
 ¬øQu√© har√°s?
- Integraci√≥n de productos de datos.
- Se trabajar√° con informaci√≥n para conocer a clientes y segmentarlos, para innovar en productos.
- Trabajar√° los procesos ETL de inicio a fin (ingesta, transformaci√≥n, disponibilizaci√≥n).
- Conocimientos Full GCP (airflow, bigquery, cloudstorage como herramientas principales)
- Deber√° generar el flujo completo del dato desde la ingesta, transformaci√≥n y disponibilizaci√≥n.
‚úîÔ∏è
 ¬øQu√© se requiere?
- Experiencia en el rol o cargo de Ingeniero de Datos Google Cloud Platform (GCP)
‚úîÔ∏è
Conocimientos t√©cnicos excluyentes:
- Experiencia en datos y modelo de datos
- Metodolog√≠a agile
- Procesos ETL
- Conocimientos en Suit GCP
‚úîÔ∏è ¬øQu√© Ofrecemos ?
- Seguros complementario de salud
- Rutas de estudios
- D√≠a libre cumplea√±os
- Reajuste salarial anual seg√∫n variaci√≥n del IPC        
            
                            
            ",Associate,Full-time,Information Technology,IT Services and IT Consulting,GCP
Senior Data Engineer,23people,Chile,2025-04-11,https://www.linkedin.com/jobs/view/4207846989/,"¬°Hola! Estamos buscando un Senior Data Engineer 
üåê
Rango salarial entre: $2.200.000 - $2.400.000 CLP
Pa√≠s: Residentes en Chile 
Skills
T√©cnicas
- Python
- BigQuery/SQL
- GitHub
- Apache Beam/Spark/Google Dataflow
Personales
- Capacidad de autogesti√≥n
- Buenos skills de comunicaci√≥n
- Fortaleza en trabajo en equipo
- Adaptaci√≥n al cambio (trabajar√°n en distintas geos de Latam)
Deseable (NO excluyente)
- Perfil Anal√≠tico
- UnitTest
- AirFlow
- PySpark
- CI/CD
- Postman
- Jmeter
¬øQu√© har√°s en tu d√≠a a d√≠a?
El profesional colaborar√° con un equipo multidisciplinario en un proyecto de expansi√≥n internacional, enfocado en la migraci√≥n estrat√©gica de la plataforma hacia nuevos mercados. Su participaci√≥n ser√° fundamental para asegurar una implementaci√≥n eficiente que considere las particularidades de cada pa√≠s destino, garantizando as√≠ el √©xito de esta iniciativa global.
Algunas de sus tareas diarias son las siguientes:
- Implementar mecanismos para verificar la integridad de los datos migrados
- Implementar transformaciones espec√≠ficas para requisitos regionales
- Dirigir el equipo t√©cnico durante las fases cr√≠ticas de migraci√≥n
- Gestionar el proceso integral de ETL entre diversos sistemas, desarrollando y optimizando los esquemas de mapeo necesarios para garantizar la compatibilidad entre las estructuras de datos de origen y destino.
Contrato indefinido desde el inicio con 23people
Modalidad: Home Office, Con residencia en Chile (Deber√°s ir a buscar el PC en primera instancia)
Experiencia: Desde 5 a√±os en adelante
Horario: Lunes a Jueves de 8:30 a 6:30 y Viernes de 8:30 a 5:30 hrs.
Algunos de nuestros beneficios:
- Seguro complementario: Seguro de salud, vida y dental
- Curso de ingl√©s: En nuestro programa de formaci√≥n en idioma ingl√©s, ofrecemos dos modalidades para adaptarnos a tus necesidades y objetivos.
- Reembolso de certificaciones internacionales: Apoyamos el crecimiento profesional, por lo que te reembolsamos el costo de un examen de certificaci√≥n internacional que quieras realizar.
- Bono de vacaciones: Por cada semana que te tomes de vacaciones te otorgamos una compensaci√≥n.
- Aguinaldos en fiestas patrias y Navidad: Queremos que en fechas tan especiales la pases bien junto a tu familia, por lo que te entregamos un bono en septiembre y diciembre
- D√≠a libre de cumplea√±os: Puedes optar por tomar tu d√≠a libre, el d√≠a previo a tu cumplea√±os, el mismo d√≠a de tu cumplea√±os o el d√≠a posterior.        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,GCP
Data Engineer AWS,Soluciones - Data & Analytics Consulting,"Santiago Metropolitan Region, Chile",2025-04-11,https://www.linkedin.com/jobs/view/4207848749/,"‚úîÔ∏è
¬øQui√©nes Somos?
Somos una consultora enfocada en Data & Analytics y contamos con m√°s de 20 a√±os de experiencia y exitosa participaci√≥n en implementaci√≥n de proyectos de peque√±a, mediana y gran envergadura. Nuestro equipo, compuesto por consultores multidisciplinarios expertos y certificados, ha entregado soluciones tecnol√≥gicas de calidad que exceden las expectativas de cada cliente. A trav√©s de una metodolog√≠a flexible y adaptable, logramos entregar soluciones adecuadas a la realidad de cada organizaci√≥n, satisfaciendo los est√°ndares de cada una de las empresas que conf√≠an en nosotros.
‚úîÔ∏è
 ¬øQu√© har√°s?
- Responsabilidades del cargo: Dise√±ar, construir y mantener procesos de ingesta de datos que permiten recolectar, almacenar, procesar y acceder a grandes vol√∫menes de datos de manera eficiente y segura. Su trabajo asegura que los datos est√©n disponibles, limpios y organizados para su an√°lisis adhiri√©ndose a los est√°ndares definidos por el cliente.
‚úîÔ∏è
 ¬øQu√© se requiere?
- Experiencia de al menos 3 a√±os en el rol
- Conocimientos t√©cnicos excluyentes: S3, Lambdas, Glue Jobs, DynamoDB, Redshift, StepFunctions, Python, SQS.
- Conocimientos t√©cnicos deseables: API Gateway, Transfer Family.
‚úîÔ∏è ¬øQu√© Ofrecemos ?
- Seguros complementario de salud
- Rutas de estudios
- D√≠a libre cumplea√±os
- Reajuste salarial anual seg√∫n variaci√≥n del IPC        
            
                            
            ",Not Applicable,Full-time,Information Technology,IT Services and IT Consulting,AWS
Data Engineer Senior,Equifax,"Las Condes, Santiago Metropolitan Region, Chile",2025-04-11,https://www.linkedin.com/jobs/view/4144902157/,"Como Data Engineer, estar√°s a cargo de integrar, consolidar y estructurar los datos, apoy√°ndote en un las mejores pr√°cticas para manejar, mantener y mejorar nuestras soluciones.
 
 
 ¬øQu√© vas a hacer? 
 
 
-  Evaluar, gestionar y resolver incidentes. 
-  Realizar c√°lculos en linea utilizando Python. 
-  Ejecuci√≥n de pruebas. 
 
 
 ¬øQu√© experiencia necesita? 
 
 
-  + 4 a√±os de experiencia trabajando en Python. 
-  + 4 a√±os de experiencia BigQuery. 
-  + 4 a√±os de experiencia trabajando con Apache Beam y GitHub. 
 
 
 ¬øQu√© podr√≠a diferenciarte? 
 
 
-  Poseer alguna certificaci√≥n de Google en Data Engineer. 
-  Experiencia trabajando con Airflow. 
-  Experiencia Trabajando con Jmeter. 
-  Experiencia trabajando con Unit Test. 
-  Experiencia trabajando con PySpark. 
-  Experiencia trabajando con CI/DF. 
-  Experiencia trabajando con Postman.        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,Financial Services,GCP
Data Engineer Semisenior o Senior,LISIT,"Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4205297492/,"Lisit es una empresa comprometida con la creaci√≥n, desarrollo e implementaci√≥n de soluciones de software que faciliten la automatizaci√≥n y optimizaci√≥n para nuestros clientes. Nuestra visi√≥n se centra en brindar servicios que no solo cumplan con las necesidades del mercado, sino que tambi√©n transformen la operatividad de las organizaciones. Tu funci√≥n como Ingeniero de Datos ser√° fundamental para lograr un acompa√±amiento consultivo integral en sus procesos de transformaci√≥n.
 Responsabilidades del puesto
Como Ingeniero De Datos Semi-senior o Senior En Lisit, Ser√°s Una Pieza Clave En El Dise√±o y Desarrollo De Soluciones De Datos Que Optimicen Nuestros Servicios y Herramientas. Tus Tareas Incluir√°n
- Generar pipelines de datos eficientes y resolver integraciones entre diversos sistemas.
- Modelar datos para garantizar que nuestras plataformas sean √∫tiles y escalables.
- Colaborar en la implementaci√≥n de herramientas de infraestructura como c√≥digo (IaC) y gestionar el versionamiento a trav√©s de GitHub o GitLab.
- Desarrollar y ejecutar procesos ETL/ELT utilizando Azure Data Factory, asegurando la calidad y accesibilidad de los datos.
 Descripci√≥n del puesto
Buscamos un Ingeniero de Datos altamente motivado, con un m√≠nimo de 3 a√±os de experiencia en el tratamiento de datos. Tu destreza con lenguajes de programaci√≥n como Python y Spark te permitir√° desempe√±arte con solidez en el equipo. Se requiere un conocimiento intermedio-avanzado de herramientas de IaC (Terraform) y manejo de versionamiento de c√≥digo (GitHub/GitLab), as√≠ como una s√≥lida comprensi√≥n del lenguaje SQL y bases de datos.
Es esencial que tengas experiencia con plataformas en la nube como Google Cloud Platform (GCP) o Azure, y herramientas como Airflow, Cloud Run, Cloud Composer y BigQuery. Adem√°s, el dominio de Azure Data Factory para procesos ETL-ELT es un requisito excluyente. Las certificaciones en Ingenier√≠a de Datos son valoradas, tales como Azure DP-700, AZ-203, DP-600 y Google Cloud Digital Leader.
 Habilidades deseables
Si cuentas con conocimientos en Microsoft Power BI o Fabric, ser√≠a un gran plus para tu perfil. Queremos personas que no solo cumplan con los requisitos, sino que tambi√©n aporten un enfoque innovador y colaborativo a nuestro equipo.
 Beneficios de trabajar con nosotros
En Lisit, Fomentamos Un Ambiente De Trabajo Excepcional, Donde La Innovaci√≥n y La Pasi√≥n Por El Aprendizaje Son Clave. Te Ofrecemos
- Acceso a oportunidades continuas de desarrollo profesional en tecnolog√≠as emergentes.
- Un equipo motivado y apasionado que valora tu entusiasmo y contribuciones.
Aqu√≠, tendr√°s la oportunidad de crecer y alcanzar tus objetivos profesionales mientras colaboras en proyectos desafiantes y de alto impacto.
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,"Technology, Information and Internet and Information Technology & Services",AZURE
Ingeniero de Datos,Amaris Consulting,Chile,2025-04-10,https://www.linkedin.com/jobs/view/4206597362/,"Who are we?
Amaris Consulting es una firma independiente de asesor√≠a tecnol√≥gica que ofrece servicios de orientaci√≥n y soluciones para las empresas.
Re√∫ne a m√°s de 7 600 personas distribuidas en 5 continentes y m√°s de 60 pa√≠ses. Con m√°s de 1 000 clientes en todo el mundo, hemos implementado soluciones en proyectos importantes durante m√°s de una d√©cada.
Nuestros especialistas cubren sectores que abarcan desde servicios financieros y transporte hasta atenci√≥n sanitaria y tecnolog√≠a.
Amaris es su ‚Äòstepping stone‚Äô para atravesar r√≠os de cambio, afrontar retos y realizar todos sus proyectos con √©xito.
Job Description
Buscamos consultores din√°micos para hacer crecer nuestro equipo de 
Sistemas de Informaci√≥n y Digital
 en
 Chile
. Tu experiencia, conocimiento y compromiso nos ayudar√°n a enfrentar los desaf√≠os de nuestros clientes.
Estar√°s apoyando diferentes proyectos a trav√©s de tu experiencia como 
Ingeniero de Datos.
Sus principales responsabilidades:
- Asegurar que las soluciones de datos sean escalables, eficientes y alineadas con los objetivos de negocio.
- Dise√±ar, desarrollar e implementar soluciones de gesti√≥n y an√°lisis de datos en la industria.
- Utilizar herramientas como Python y SQL para extraer, transformar y cargar (ETL) datos.
- Trabajar con bases de datos en la nube, utilizando alguna de las principales plataformas: Google Cloud Platform (GCP), Amazon Web Services (AWS) o Microsoft Azure.
- Desarrollar y mantener pipelines de datos para la gesti√≥n y an√°lisis eficiente.
- Desarrollar APIs y plugins para integrar soluciones de datos con otras aplicaciones y sistemas.
- Implementar y gestionar entornos de desarrollo y pruebas para soluciones de datos.
- Mantenerse actualizado con las √∫ltimas tendencias y herramientas en el √°mbito de la ingenier√≠a de datos.
Requisitos
:
- Al menos 2 a√±os de experiencia como Ingeniero de Datos.
- Al menos 2 a√±os de experiencia con alguna de las principales nubes (GCP, AWS, Azure).
- Dominio de Python.
- Dominio de bases de datos SQL.
- Experiencia con procesos ETL.
Amaris Consulting se enorgullece de ser un lugar de trabajo con igualdad de oportunidades. Estamos comprometidos con la promoci√≥n de la diversidad dentro de la fuerza de trabajo y la creaci√≥n de un ambiente de trabajo inclusivo. Para ello, damos la bienvenida a las solicitudes de todos los candidatos cualificados, independientemente de su g√©nero, orientaci√≥n sexual, raza, etnia, creencias, edad, estado civil, discapacidad u otras caracter√≠sticas.        
            
                            
            ",Entry level,Full-time,Information Technology,IT Services and IT Consulting,OTHER
Data Engineer - GCP Ssr,axity,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4204875774/,"Company Description: axity
Job Description: Axity una compa√±√≠a con m√°s de 35 a√±os de trayectoria nuestro portafolio de servicios es uno de los m√°s grandes en la industria: Estrategia Digital, Desarrollo de Software, Bussiness Intelligence, Big Data, Anal√≠tica Avanzada, Seguridad, IOT.
Buscamos Data Analyst / Data Engineer ‚Äì Nivel Medio/Avanzado
¬øTe apasiona convertir datos en informaci√≥n valiosa y accionable?
Estamos en b√∫squeda de un profesional con experiencia en desarrollo de productos de complejidad media a avanzada, capaz de entregar soluciones de calidad dentro de los plazos establecidos.
Responsabilidades
Desarrollar productos anal√≠ticos cumpliendo con est√°ndares de calidad y tiempos definidos.
Traducir datos en informaci√≥n √∫til para la toma de decisiones.
Trabajar en conjunto con equipos de anal√≠tica para profundizar en el an√°lisis y la s√≠ntesis de datos.
Seleccionar y aplicar t√©cnicas anal√≠ticas adecuadas a cada requerimiento.
Mantenerse actualizado sobre herramientas anal√≠ticas y productos de manipulaci√≥n de datos.
Realizar procesos de recolecci√≥n, clasificaci√≥n, limpieza e interpretaci√≥n de grandes vol√∫menes de datos.
Aplicar pr√°cticas de gobernanza y seguridad de los datos.
Participar en iniciativas que involucren integraci√≥n de datos para procesos como planeaci√≥n de compras, demanda y gesti√≥n de inventarios.
Requisitos
Experiencia en GCP (Google Cloud Platform): BigQuery, Cloud Storage, Dataflow, Cloud Functions, Composer, Pub/Sub.
Conocimientos b√°sicos en Kubernetes, contenedores y consumo de APIs.
Experiencia en manejo de grandes vol√∫menes de datos.
Conocimiento de sistemas legados, flujos de compras y demand forecasting.
Capacidad de interacci√≥n continua con √°reas de negocio.
Ofrecemos
Horario: Lunes a viernes de 9:00 a 18:30
Contrato a plazo fijo luego a indefinido
Oportunidad de trabajar en proyectos desafiantes con impacto directo en el negocio
Ambiente colaborativo e innovador
Si te motiva trabajar con datos, impactar decisiones estrat√©gicas y enfrentarte a desaf√≠os t√©cnicos, ¬°postula con nosotros!
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,GCP
Data Engineer - AWS Ssr,axity,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4204874848/,"Company Description: axity
Job Description: Axity una compa√±√≠a con m√°s de 35 a√±os de trayectoria nuestro portafolio de servicios es uno de los m√°s grandes en la industria: Estrategia Digital, Desarrollo de Software, Bussiness Intelligence, Big Data, Anal√≠tica Avanzada, Seguridad, IOT.
Responsabilidades Principales
-  Dise√±o eficiente de almacenamiento de datos: utilizando servicios como Amazon S3, DynamoDB, RDS, entre otros, optimizando costos, rendimiento y accesibilidad.
-  Optimizaci√≥n de consultas: aplicando √≠ndices, claves de partici√≥n y patrones de acceso eficientes (Query, GetItem, etc.).
-  Integraci√≥n y procesamiento de datos: a trav√©s de herramientas como AWS Glue, Amazon Kinesis y/o Firehose para ingesta, transformaci√≥n y orquestaci√≥n.
-  Uso de formatos optimizados: como Parquet, ORC, entre otros, para mejorar la compresi√≥n y velocidad de lectura/escritura.
-  Infraestructura como C√≥digo (IaC): despliegue de infraestructura en AWS mediante CloudFormation, AWS CDK o Terraform.
________________________________________
Ô∏è Conocimientos T√©cnicos Clave
-  Amplio manejo de servicios AWS: S3, DynamoDB, RDS, AWS Glue, Kinesis/Firehose.
-  Dominio de bases de datos SQL/NoSQL: dise√±o de esquemas, indexaci√≥n y tuning.
-  Experiencia en optimizaci√≥n y particionamiento de grandes vol√∫menes de datos.
-  Familiaridad con automatizaci√≥n y orquestaci√≥n de pipelines: scripting, Jenkins, Shell, entre otros.
-  Modalidad: H√≠brido
-  √Årea: Tecnolog√≠a ‚Äì Cloud
-  Horario: Lunes a viernes de 9:00 a 18:00 hrs
-  Tipo de Contrato: Plazo fijo, con posibilidad de pasar a indefinido
________________________________________
¬øPor qu√© postular?
-  Ser√°s parte de una empresa con enfoque en la innovaci√≥n y la transformaci√≥n digital.
-  Trabajar√°s con tecnolog√≠as de vanguardia en un entorno colaborativo.
-  Tendr√°s oportunidades reales de crecimiento profesional.        
            
                            
            ",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,AWS
Data Engineer Azure,"","Santiago, Santiago Metropolitan Region, Chile",2025-04-10,https://www.linkedin.com/jobs/view/4206654598/,"Resumen del Cargo:
Busco Ingeniero de Datos  para liderar y ejecutar proyectos de Data & Analytics. 
Ser√° responsable del dise√±o, desarrollo e implementaci√≥n de soluciones de datos usando Azure Databricks, Data Factory, Python  y otros servicios en la nube, asegurando que la infraestructura de datos sea escalable, segura y optimizada para la toma de decisiones. 
Adem√°s, deber√° interactuar directamente con √°reas de negocio para levantar requerimientos y traducirlos en soluciones t√©cnicas eficientes.
¬†
¬†
Responsabilidades:
¬†¬†¬†¬†¬†¬†¬†¬†‚Ä¢¬†¬†¬†¬†¬†¬†¬†Dise√±ar y desarrollar soluciones de ingesti√≥n, transformaci√≥n y modelado de datos en Azure DataFactory, Databricks y otras tecnolog√≠as relacionadas.
¬†¬†¬†¬†¬†¬†¬†¬†‚Ä¢¬†¬†¬†¬†¬†¬†¬†Optimizar procesos de ETL/ELT, asegurando calidad, integridad y eficiencia en el procesamiento de datos.
¬†¬†¬†¬†¬†¬†¬†¬†‚Ä¢¬†¬†¬†¬†¬†¬†¬†Colaborar con equipos de negocio para entender necesidades, identificar oportunidades y proponer soluciones basadas en datos.
¬†¬†¬†¬†¬†¬†¬†¬†‚Ä¢¬†¬†¬†¬†¬†¬†¬†Implementar arquitecturas de datos escalables que soporten anal√≠tica avanzada, machine learning e inteligencia de negocio.
¬†¬†¬†¬†¬†¬†¬†¬†‚Ä¢¬†¬†¬†¬†¬†¬†¬†Garantizar la seguridad y el cumplimiento normativo en el manejo de datos, siguiendo est√°ndares bancarios y regulatorios.
¬†¬†¬†¬†¬†¬†¬†¬†‚Ä¢¬†¬†¬†¬†¬†¬†¬†Desarrollar y optimizar pipelines de datos para la explotaci√≥n en entornos anal√≠ticos y de reportes.
¬†¬†¬†¬†¬†¬†¬†¬†‚Ä¢¬†¬†¬†¬†¬†¬†¬†Documentar procesos, arquitecturas y modelos de datos, asegurando buenas pr√°cticas de gobernanza.
¬†¬†¬†¬†¬†¬†¬†¬†‚Ä¢¬†¬†¬†¬†¬†¬†¬†Trabajar en conjunto con equipos de Data Science, BI y Tecnolog√≠a para garantizar la disponibilidad y calidad de los datos.
¬†        
            
                            
            ",Entry level,Full-time,Information Technology,,AZURE
Senior Data Engineer,Grupo Falabella,"Santiago, Santiago Metropolitan Region, Chile",2025-04-09,https://www.linkedin.com/jobs/view/4205465977/,"Descripci√≥n Empresa
Somos m√°s de 90 mil personas que, d√≠a a d√≠a, dedicamos nuestra pasi√≥n y energ√≠a a cumplir nuestro Prop√≥sito de ‚ÄúSimplificar y Disfrutar M√°s la Vida‚Äù. Prop√≥sito que hoy vive a trav√©s de nuestro ecosistema f√≠sico y digital en todas nuestras empresas (Falabella Retail, Sodimac, IKEA, Tottus, Mallplaza, Falabella Inmobiliario, Falabella.com, Linio, Falabella Financiero, Banco Falabella, Falabella Soriana, Seguros Falabella, Fazil, Fpay y Falabella Corporativo) y pa√≠ses (Argentina, Brasil, Chile, China, Colombia, India, M√©xico, Per√∫ y Uruguay).
Valoramos las distintas miradas porque entendemos que la diversidad es la clave de nuestra innovaci√≥n. Queremos ir m√°s all√° de cualquier l√≠mite, desafiarnos constantemente, divertirnos haciendo lo que nos gusta y dejar huella en lo que hacemos. Y sabemos que existe una forma de hacerlo: como UN SOLO EQUIPO.
Misi√≥n Del Cargo
¬°√önete a Falabella Retail y lleva tus habilidades de Ingenier√≠a de Datos al pr√≥ximo nivel!
Funciones Del Cargo
Formar√°s parte de un equipo de alto impacto que lidera la transformaci√≥n digital, trabajando en proyectos cr√≠ticos para optimizar y escalar nuestras operaciones en uno de los ecosistemas m√°s din√°micos de la regi√≥n.
Mision: Responsable de dise√±ar, construir y mantener sistemas de datos escalables para el an√°lisis y la toma de decisiones en la organizaci√≥n.
Responsabilidades
Dise√±ar y desarrollar canalizaciones de datos (ETL/ELT) robustas y eficientes.
Colaborar con equipos de ingenier√≠a de datos.
Implementar y gestionar bases de datos y data warehouses.
Optimizar el rendimiento de las bases de datos y sistemas de almacenamiento de datos.
Garantizar la calidad, integridad y seguridad de los datos.
Automatizar procesos de ingesti√≥n y transformaci√≥n de datos.
Monitorizar y solucionar problemas relacionados con los sistemas de datos.
Documentar procesos, arquitecturas y mejores pr√°cticas relacionadas con el manejo de datos.
Si disfrutas nuevos desaf√≠os con alta responsabilidad y exposici√≥n en el epicentro de la transformaci√≥n del retail en Latinoam√©rica, ¬°s√∫mate a trabajar con nosotros! Somos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusi√≥n en todas sus formas, sin importar religi√≥n, raza, g√©nero, situaci√≥n de discapacidad, nacionalidad.
Conoce m√°s oportunidades para vivir la #ExperienciaFalabella en https://muevete.falabella.com/
Requisitos
- Profesional Titulado en Ingenier√≠a Civil Computaci√≥n, Industrial, matem√°tico u el√©ctrico.
- Experiencia demostrable como Data Engineer por mas de 04 a√±os
- Conocimientos en lenguajes de programaci√≥n Python.
- Experiencia con Google Cloud Platform (Composer, Cloud Functions, Bigquery, Dataproc, etc)
- Experiencia utilizando git
- Deseable: Conocimientos profundos en SQL y en bases de datos relacionales y no relacionales
- Deseable: Certificaciones relevantes en tecnolog√≠as de datos y cloud.
Condiciones Oferta
Descripci√≥n proceso de selecci√≥n:
El proceso de selecci√≥n se realiza a trav√©s de Aira - plataforma de reclutamiento dise√±ado para mejorar tu experiencia de postulaci√≥n.
Para Postular Solo Necesitas
-  Postular a la oferta
-  Revisar tu email
-  Ingresar a Aira y contestar las preguntas y/o pruebas solicitadas
Luego, si vemos que tu perfil se ajusta a lo que estamos buscando, te contactaremos por email (a trav√©s de Aira) para seguir a la etapa presencial.
                
            
                            
            ",Mid-Senior level,Full-time,Information Technology,Retail,GCP
