[
    {
        "title": "Data Engineer Junior",
        "company": "LISIT",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205294902/",
        "job_description": "En Lisit, nos dedicamos a crear, desarrollar e implementar herramientas y servicios de software que automatizan y optimizan procesos, siempre con un fuerte enfoque en la innovaci\u00f3n y los desaf\u00edos que se presentan. Nuestro objetivo es fomentar la eficacia operativa de nuestros clientes, ayud\u00e1ndoles a alcanzar sus metas de transformaci\u00f3n mediante un acompa\u00f1amiento consultivo integral. Actualmente, estamos en b\u00fasqueda de un Data Engineer Junior que se una a nuestro equipo apasionado por la tecnolog\u00eda y el aprendizaje continuo.\n Funciones del Rol\nComo Data Engineer Junior, Ser\u00e1s Parte Esencial Del Equipo Encargado De Manejar y Optimizar El Flujo De Datos De La Organizaci\u00f3n. Tus Principales Responsabilidades Incluir\u00e1n\n- Colaborar en la recopilaci\u00f3n y procesamiento de datos relacionales y no relacionales.\n- Trabajar con lenguajes de programaci\u00f3n, especialmente Python, para crear soluciones de datos efectivas.\n- Implementar y mantener los procesos de integraci\u00f3n en ambientes cloud como GCP o Azure.\n- Realizar consultas y manipulaci\u00f3n de bases de datos utilizando SQL.\n- Aprender y adaptarte a nuevas tecnolog\u00edas y herramientas en el entorno de la nube.\n Descripci\u00f3n del Perfil\nBuscamos Un Perfil Proactivo, Con Conocimientos Intermedios En Python y Disposici\u00f3n Para Aprender Sobre Nuevas Tecnolog\u00edas. El Candidato Ideal Deber\u00e1 Tener\n- Experiencia b\u00e1sica a intermedia en programaci\u00f3n Python.\n- Habilidades en el uso y tratamiento de datos en ambientes tanto relacionales como no relacionales.\n- Conocimientos fundamentales en tecnolog\u00edas de nube, incluyendo GCP o Azure.\n- Experiencia en el uso del lenguaje SQL.\n- Bajo es requisito pero se valorar\u00e1 el conocimiento en Power BI.\n Habilidades Deseables\nSer\u00eda excelente contar con conocimientos adicionales en herramientas de visualizaci\u00f3n de datos como Power BI. Adem\u00e1s, habilidad para trabajar en equipo y una mentalidad orientada al aprendizaje continuo son altamente valoradas.\n Beneficios de Trabajar con Nosotros\nEn Lisit, Promovemos Un Ambiente De Trabajo Excepcional\n- Acceso a oportunidades de desarrollo profesional continuo en tecnolog\u00edas emergentes.\n- Un equipo apasionado por la innovaci\u00f3n y el aprendizaje, donde tu entusiasmo ser\u00e1 bienvenido.        \n            \n                            \n            ",
        "Seniority level": "Entry level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Data Analyst I",
        "company": "Principal Chile",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4187514059/",
        "job_description": ""
    },
    {
        "title": "Data Engineer",
        "company": "Xepelin",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-09",
        "job_url": "https://www.linkedin.com/jobs/view/4205474021/",
        "job_description": "Somos una FinTech que busca democratizar los servicios financieros para todo tipo de empresas. Nos apalancamos en la mejor tecnolog\u00eda para crear soluciones \u00e1giles, personalizadas y transparentes. Nuestro objetivo es ser la FinTech B2B m\u00e1s grande de Latam y convertirnos en el CFO digital de todas las empresas en la regi\u00f3n.\nXepelin nace en Chile en 2019 y, desde entonces, hemos levantado m\u00e1s de USD145 millones en equity y USD300 millones en asset-backed facilities para potenciar el crecimiento en toda la regi\u00f3n, especialmente en los pa\u00edses donde hoy operamos, Chile y M\u00e9xico. La \u00faltima ronda de equity fue de USD111 millones, record en Chile y una de las m\u00e1s grandes en Am\u00e9rica Latina para una FinTech.\n\u00bfPor qu\u00e9 trabajar en Xepelin?\n\ud83d\udcaa Desaf\u00edo\nEstamos sacudiendo una de las industrias m\u00e1s poderosas y competitivas, eliminando fricciones para darle a las Pymes acceso a capital y apalancado en la \u00faltima tecnolog\u00eda disponible. Todo esto poniendo siempre a nuestras Pymes en el centro.\nConstruir un banco digital desde cero es un gran proyecto; el producto es complejo y no se puede romper, existen regulaciones estrictas y tendremos que ser mejores que algunas de las corporaciones m\u00e1s grandes y consolidadas del mundo. Pero superar estos desaf\u00edos significa que habremos construido algo duradero.\n\ud83d\udca5 Impacto\nTrabajar en un equipo de clase mundial y automotivado significa autonom\u00eda, amplia experiencia en todos los proyectos y ver que tus contribuciones afectan directamente al producto e impactan a nuestras Pymes.\nTrabajar\u00e1s con todos nuestros productos, tendr\u00e1s que tomar decisiones fundamentales. El correcto posicionamiento de ellos marcar\u00e1 su futuro.\n\u2714\ufe0f Calidad\nNuestro posicionamiento de marca y productos es algo diferenciador frente al resto del mercado por lo que invertimos mucho en crear productos de calidad que nuestras Pymes respeten y valoren.\nNos damos el tiempo para pensar fuera de la caja y volver con propuestas innovadoras. Estamos aqu\u00ed para cambiar la industria!\n\u00bfQu\u00e9 estamos buscando? \nEn Xepelin estamos buscando personas creativas y visionarias que piensen fuera de la caja para sumarse a nuestro equipo. Si te apasiona resolver desaf\u00edos interesantes de alto impacto y quieres ser parte de un entorno din\u00e1mico que est\u00e1 transformando la industria financiera, \u00a1Esta oportunidad es para ti!\nEl rol se integrar\u00e1 a nuestro equipo de \nData Platform\n. Si te motiva el desaf\u00edo de construir soluciones innovadoras en un entorno de r\u00e1pido cambio, queremos conocerte.\nUnete a nosotros, crezcamos juntos!\nPrincipales responsabilidades...\n-  Dise\u00f1ar, crear y mantener pipelines de datos\n-  Mantener y optimizar la infraestructura de datos necesaria para una extracci\u00f3n precisa, transformaci\u00f3n y carga de datos de una amplia variedad de fuentes de datos\n-  Automatizar los flujos de trabajo de datos, como la ingesta de datos, la agregaci\u00f3n y el procesamiento de ETL o ELT\n-  Preparar datos sin procesar en almacenes de datos en un conjunto de datos consumibles para fines t\u00e9cnicos y partes interesadas no t\u00e9cnicas\n-  Crear, mantener e implementar productos de datos para equipos de an\u00e1lisis y ciencia de datos en Plataformas en la nube, preferentemente en GCP, y/o AWS\n-  Desarrollar sistemas y arquitectura que soporten las diferentes etapas del flujo de Machine Learning\n\u00bfQu\u00e9 necesitas para brillar?\n- Conocimientos en alguna Nube, preferentemente GCP o AWS (en ese orden de preferencia)\n- Conocimientos intermedio/avanzado en Python\n- Conocimiento intermedio/avanzado de SQL\n- Experiencia trabajando almacenamiento en la nube como GCS o AWS S3\n- Experiencia desplegando aplicaciones en ambientes serverless como Cloud Functions o AWS Lambda\n- Conocimientos administrando y desplegando alg\u00fan orquestador, por ejemplo: Dagster, Apache Airflow, Prefect, etc\n- Excelentes habilidades para trabajar en equipo. Ser humilde y saber colaborar, un Team Player!\n- Saber escuchar a tus stakeholders y poder traducir eso en requerimientos y ejecutarlos con tu equipo\n- Trabajo proactivo y responsable\n- Conocimientos en DBT\n- Conocimientos y manejo de lenguajes de programaci\u00f3n y/o frameworks, NodeJS, Golang, por ejemplo\n- Experiencia en MLOps\n- No tener miedo a tomar decisiones y liderar proyectos\n- Foco en impacto e historia consistente entregando resultados para usuarios y el negocio\n- Capacidad para pensar en grande y desarrollar iniciativas con impacto real y medible\n- Te sientes c\u00f3modo cuestionando el status-quo de los servicios financieros, adapt\u00e1ndose r\u00e1pidamente a los cambios, y presentando claramente tus ideas y conceptos para debatirlos en equipo\nNuestros Beneficios:\n\ud83c\udf34 Xepelin Balance\nVacaciones:\n 15 d\u00edas h\u00e1biles. Por cada a\u00f1o que cumplas en Xepelin, te damos un d\u00eda extra de vacaciones.\nBalance days:\n 10 d\u00edas libres adicionales al a\u00f1o, para disfrutar como quieras.\nTrabajo h\u00edbrido y flexibilidad horaria seg\u00fan el rol. Trabajamos por objetivos.\nBeneficios Flexibles: \nPuntos flexibles en tu moneda local al mes para gastar en lo que quieras.\nXepelin Fun:\n Actividades de encuentro financiadas por Xepelin para divertirnos juntos.\n\ud83d\ude80 Xepelin Performance & Career\nPlataformas de capacitaci\u00f3n:\n Convenios con las mejores plataformas, como Reforge, Udemy y DataCamp.\nKit de Bienvenida: \ntodo lo que necesitas para comenzar tu viaje en Xepelin \ud83d\ude0a\n\ud83e\udd1d Xepelin Cares\nCobertura de salud:\n contamos con convenios de salud con proveedores de calidad o reembolsos seg\u00fan el pa\u00eds donde te encuentres.\nPost Natal:\n te damos una semana extra de licencia post natal. \u00a1Nos interesa que est\u00e9s con tu familia y seres queridos!\nMatrimonio plus:\n Lleva tus planes al siguiente nivel, con una gift card y extendiendo tu permiso legal por matrimonio con dos d\u00edas de regalo por Xepelin.        \n            \n                            \n            ",
        "Seniority level": "Not Applicable",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Software Development, IT Services and IT Consulting, and Biotechnology Research"
    },
    {
        "title": "Data Engineer",
        "company": "BC Tecnolog\u00eda",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205297472/",
        "job_description": "Could not find Job Description"
    },
    {
        "title": "Data Engineer",
        "company": "2Brains",
        "location": "Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205294882/",
        "job_description": "2Brains es una empresa dedicada a construir y desarrollar el Futuro Digital de nuestros clientes, con una visi\u00f3n excepcional que radica en la integraci\u00f3n sin\u00e9rgica de estrategia, dise\u00f1o y tecnolog\u00eda, un tr\u00edptico poderoso que impulsa el crecimiento de empresas y disruptores tecnol\u00f3gicos.\nContamos con un nutrido equipo de m\u00e1s de 200 profesionales, verdaderos art\u00edfices de la innovaci\u00f3n digital. En el coraz\u00f3n de nuestra labor, destacamos como l\u00edderes indiscutibles, canalizando a\u00f1os de experiencia hacia la creaci\u00f3n de plataformas tecnol\u00f3gicas adaptables y productos digitales de clase mundial.\nEn 2Brains, no solo somos consultores, somos arquitectos de experiencias digitales. Aspiramos a ir m\u00e1s all\u00e1 de las expectativas, estableciendo nuevos est\u00e1ndares en la industria. Descubre c\u00f3mo damos vida a la innovaci\u00f3n, c\u00f3mo convertimos ideas en resultados tangibles y c\u00f3mo, junto a nosotros, puedes forjar un futuro digital brillante.\n El/la Data Engineer de 2Brains \nSe encarga de participar en el dise\u00f1o y desarrollo de los nuevos modelos de informaci\u00f3n de gesti\u00f3n y las mantenciones evolutivas de los existentes. Participar en las iniciativas de Anal\u00edtica avanzada del \u00e1rea, apoyando las exploraci\u00f3n de modelos de informaci\u00f3n internos y externos (Data Discovery). Obtener datos hist\u00f3ricos desde m\u00faltiples fuentes de informaci\u00f3n interna para apoyar las iniciativas de anal\u00edtica avanzada del equipo.\nEl/la Data Engineer de 2Brains debe\n- Construir y optimizar pipelines de datos para la ingesta, transformaci\u00f3n y carga eficiente de informaci\u00f3n.\n- Manejar infraestructuras en la nube (AWS, GCP, Azure), asegurando escalabilidad y eficiencia en costos.\n- Automatizar y monitorear procesos mediante herramientas de DevOps como Airflow, Terraform o Kubernetes.\n- Implementar controles de calidad y gobernanza para garantizar la integridad y disponibilidad de los datos.\n- Colaborar con equipos de Data Science, Producto y Desarrollo para dise\u00f1ar soluciones alineadas con las necesidades del negocio.\n Qu\u00e9 conocimientos buscamos en/la Data Engineer\n- Excluyente Experiencia trabajando con tecnolog\u00edas de BI\n- Experiencia en la construcci\u00f3n/operaci\u00f3n de sistemas distribuidos de extracci\u00f3n, ingesti\u00f3n y procesamiento de grandes conjuntos de datos de gran disponibilidad.\n- Capacidad demostrable en modelado de datos, desarrollo de ETL y almacenamiento de datos.\n- Experiencia en el uso de herramientas de informes de inteligencia empresarial (Power BI)\n- Excluyente conocimiento en consumo de microservicios de APIs Rest\n- Excluyente conocimiento en Git , Bitbucket, Docker,Jenkins,Webhooks\n- Programaci\u00f3n con Python y bases s\u00f3lidas de ingenier\u00eda de software.\n- Automatizaci\u00f3n y scripting.\n- Uso de librer\u00edas de Python para manipulaci\u00f3n y an\u00e1lisis de datos y Apache Spark.\n- Conocimientos en bases de datos SQL y NoSQL.\n- Conocimiento en CI/CD, Dataflow\n- Conocimiento en S3, Redshift y Glue AWS\n Que competencias buscamos en/la Data Engineer \n- Empat\u00eda\n- Buena capacidad de comunicaci\u00f3n.\n- Colaboraci\u00f3n y trabajo en equipo.\n- Proactividad.\n- Autonom\u00eda.\n- Foco en los objetivos de proyectos.\n Condiciones\nTrabajar con un equipo de alto rendimiento, aprendemos y nos desarrollamos juntos\nAcceso a grandes clientes y proyectos desafiantes\nAprendizaje y crecimiento permanente, organizamos meetups, capacitaciones y actividades culturales\nUn entorno de trabajo flexible y din\u00e1mico\nBeneficios especiales: d\u00eda libre para tu cumplea\u00f1os, d\u00edas de descanso a convenir.\n                \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Data Engineer",
        "company": "Falabella",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4207045620/",
        "job_description": "Descripci\u00f3n Empresa\nSomos m\u00e1s de 80 mil personas que cada d\u00eda trabajamos por el firme Prop\u00f3sito - Simplificar y Disfrutar m\u00e1s la Vida. Estamos presentes en 9 pa\u00edses y compuestos por grandes marcas posicionadas de diversas industrias. Falabella Retail, Sodimac, Banco Falabella, Tottus, Mallplaza, Falabella.com, Falabella Inmobiliario. Cada una de \u00e9stas nos hace ser quienes somos, y es entre todos, como Un Solo Equipo, que buscamos diariamente reinventarnos y superar las experiencias de nuestros clientes.\nSi eres trabajador de Falabella, revisa todos los cursos disponibles en la Academia Falabella, que te ayudar\u00e1n a seguir impulsando tu desarrollo y preparar tu pr\u00f3xima aventura con nosotros!\nSOMOS UNA EMPRESA QUE APOYA LA LEY 21015, APOYAMOS LA DIVERSIDAD Y LA INCLUSI\u00d3N EN TODAS SUS FORMAS, SIN IMPORTAR RELIGI\u00d3N, RAZA, G\u00c9NERO, SITUACI\u00d3N DE DISCAPACIDAD, NACIONALIDAD.\nFunciones Del Cargo\n\u00a1Si tienes una mente inquieta y te gusta so\u00f1ar en grande, este llamado es para ti!\nEn Falabella Retail buscamos a nuestro/a pr\u00f3ximo/a Data Engineer, con base en Santiago, Chile.\nSomos Falabella, UN equipo diverso con m\u00e1s de 100 mil colaboradores compuesto por grandes marcas: Falabella Retail, Sodimac, Banco Falabella, Seguros Falabella, Tottus, Mallplaza, Open Plaza y Linio. Hoy tenemos presencia en 7 pa\u00edses de Am\u00e9rica Latina, adem\u00e1s de oficinas en China e India.\n\u00bfCu\u00e1l es el principal objetivo del cargo?\nLiderar la construcci\u00f3n y mantenci\u00f3n de estructuras de datos, as\u00ed como la arquitectura tecnol\u00f3gica requerida para el procesamiento de apps.\n\u00bfQu\u00e9 har\u00e1s en el d\u00eda a d\u00eda?\n-  Desarrollo, implementaci\u00f3n de procesos ETL.\n-  Levantamiento de requerimientos funcionales y t\u00e9cnicos relacionados con los clientes internos.\n-  Implementar modelos de datos automatizados para transformar datos de acuerdo a los requisitos del negocio.\n-  Migraci\u00f3n de datos desde entornos on-premise a entornos Cloud.\n-  Trabajar con tecnolog\u00edas Google Cloud Platform (Big Query).\n\u00bfQu\u00e9 necesitas para postular?\n-  Profesional: Ingenier\u00eda Civil en Computaci\u00f3n, Inform\u00e1tica, Sistemas o carrera af\u00edn.\n-  Conocimiento en SQL (excluyente)\n-  S\u00f3lidos conocimientos en Google Cloud Platform (excluyente)\n-  Conocimiento avanzado en Python (excluyente)\n-  Conocimiento y experiencia trabajando en GIT (excluyente)\n-  Disponibilidad para ir a la oficina al menos 2 veces por semana (Las Condes) (excluyente)\nEn Nuestro Equipo Encontrar\u00e1s\n-  Espacios para crear e innovar.\n-  Ser\u00e1s parte de un lugar lleno de oportunidades de desarrollo.\n-  Tener un trabajo con sentido y donde se promueve la calidad de vida.\n-  Participar en voluntariados.\n-  \u00a1Pertenecer a una empresa llena de energ\u00eda!\nSi disfrutas nuevos desaf\u00edos con alta responsabilidad y exposici\u00f3n en el epicentro de la transformaci\u00f3n del retail en Latinoam\u00e9rica, \u00a1s\u00famate a trabajar con nosotros!\nSomos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusi\u00f3n en todas sus formas, sin importar religi\u00f3n, raza, g\u00e9nero, situaci\u00f3n de discapacidad, nacionalidad.\nRequisitos\n- Profesional: Ingenier\u00eda Civil en Computaci\u00f3n, Inform\u00e1tica, Sistemas o carrera af\u00edn.\n- Conocimiento en SQL (excluyente)\n- S\u00f3lidos conocimientos en Google Cloud Platform (excluyente)\n- Conocimiento avanzado en Python (excluyente)\n- Conocimiento y experiencia trabajando en GIT (excluyente)\n- Disponibilidad para ir a la oficina al menos 2 veces por semana (Las Condes) (excluyente)\nCondiciones Oferta\nDescripci\u00f3n proceso de selecci\u00f3n:\nEl proceso de selecci\u00f3n se realiza a trav\u00e9s de Aira - plataforma de reclutamiento dise\u00f1ado para mejorar tu experiencia de postulaci\u00f3n.\nPara Postular Solo Necesitas\n-  Postular a la oferta\n-  Revisar tu email\n-  Ingresar a Aira y contestar las preguntas y/o pruebas solicitadas\nLuego, si vemos que tu perfil se ajusta a lo que estamos buscando, te contactaremos por email (a trav\u00e9s de Aira) para seguir a la etapa presencial.\n                \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Retail"
    },
    {
        "title": "Data Engineer",
        "company": "NeuralWorks",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205500303/",
        "job_description": "NeuralWorks es una compa\u00f1\u00eda de alto crecimiento fundada hace 3 a\u00f1os. Estamos trabajando a toda m\u00e1quina en cosas que dar\u00e1n que hablar.\nSomos un equipo donde se unen la creatividad, curiosidad y la pasi\u00f3n por hacer las cosas bien. Nos arriesgamos a explorar fronteras donde otros no llegan: un modelo predictor basado en monte carlo, una red convolucional para detecci\u00f3n de caras, un sensor de posici\u00f3n bluetooth, la recreaci\u00f3n de un espacio ac\u00fastico usando finite impulse response.\nEstos son solo algunos de los desaf\u00edos, donde aprendemos, exploramos y nos complementamos como equipo para lograr cosas impensadas.\nTrabajamos en proyectos propios y apoyamos a corporaciones en partnerships donde codo a codo combinamos conocimiento con creatividad, donde imaginamos, dise\u00f1amos y creamos productos digitales capaces de cautivar y crear impacto.\n\ud83d\udc49 Conoce m\u00e1s sobre nosotros\n Descripci\u00f3n del trabajo\nEl equipo de Data y Analytics trabaja en diferentes proyectos que combinan vol\u00famenes de datos enormes e IA, como detectar y predecir fallas antes que ocurran, optimizar pricing, personalizar la experiencia del cliente, optimizar uso de combustible, detectar caras y objetos usando visi\u00f3n por computador.\nDentro del equipo multidisciplinario con Data Scientist, Translators, DevOps, Data Architect, tu rol ser\u00e1 clave en construir y proveer los sistemas e infraestructura que permiten el desarrollo de estos servicios, formando los cimientos sobre los cuales se construyen los modelos que permiten generar impacto, con servicios que deben escalar, con alt\u00edsima disponibilidad y tolerantes a fallas, en otras palabras, que funcionen. Adem\u00e1s, mantendr\u00e1s tu mirada en los indicadores de capacidad y performance de los sistemas.\nEn cualquier proyecto que trabajes, esperamos que tengas un gran esp\u00edritu de colaboraci\u00f3n, pasi\u00f3n por la innovaci\u00f3n y el c\u00f3digo y una mentalidad de automatizaci\u00f3n antes que procesos manuales.\nComo Data Engineer, Tu Trabajo Consistir\u00e1 En\n- Participar activamente durante el ciclo de vida del software, desde inception, dise\u00f1o, deploy, operaci\u00f3n y mejora.\n- Apoyar a los equipos de desarrollo en actividades de dise\u00f1o y consultor\u00eda, desarrollando software, frameworks y capacity planning.\n- Desarrollar y mantener arquitecturas de datos, pipelines, templates y est\u00e1ndares.\n- Conectarse a trav\u00e9s de API a otros sistemas (Python)\n- Manejar y monitorear el desempe\u00f1o de infraestructura y aplicaciones.\n- Asegurar la escalabilidad y resiliencia.\n Calificaciones clave\n- Estudios de Ingenier\u00eda Civil en Computaci\u00f3n o similar.\n- Experiencia pr\u00e1ctica de al menos 3 a\u00f1os en entornos de trabajo como Data Engineer, Software Engineer entre otros.\n- Experiencia con Python. Entendimiento de estructuras de datos con habilidades anal\u00edticas relacionadas con el trabajo con conjuntos de datos no estructurados, conocimiento avanzado de SQL, incluida optimizaci\u00f3n de consultas.\n- Pasi\u00f3n en problem\u00e1ticas de procesamiento de datos.\n- Experiencia con servidores cloud (GCP, AWS o Azure), especialmente el conjunto de servicios de procesamiento de datos.\n- Buen manejo de ingl\u00e9s, sobre todo en lectura donde debes ser capaz de leer un paper, art\u00edculos o documentaci\u00f3n de forma constante.\n- Habilidades de comunicaci\u00f3n y trabajo colaborativo.\n\u00a1En NeuralWorks nos importa la diversidad! Creemos firmemente en la creaci\u00f3n de un ambiente laboral inclusivo, diverso y equitativo. Reconocemos y celebramos la diversidad en todas sus formas y estamos comprometidos a ofrecer igualdad de oportunidades para todos los candidatos.\n\u201cLos hombres postulan a un cargo cuando cumplen el 60% de las calificaciones, pero las mujeres s\u00f3lo si cumplen el 100%.\u201d D. Gaucher , J. Friesen and A. C. Kay, Journal of Personality and Social Psychology, 2011.\nTe invitamos a postular aunque no cumplas con todos los requisitos.\n Nice to have\n- Agilidad para visualizar posibles mejoras, problemas y soluciones en Arquitecturas.\n- Experiencia en Infrastructure as code, observabilidad y monitoreo.\n- Experiencia en la construcci\u00f3n y optimizaci\u00f3n de data pipelines, colas de mensajes y arquitecturas big data altamente escalables.\n- Experiencia en procesamiento distribuido utilizando servicios cloud.\n Beneficios\n- MacBook Air M2 o similar (con opci\u00f3n de compra hiper conveniente)\n- Bono por desempe\u00f1o\n- Bono de almuerzo mensual y almuerzo de equipo los viernes\n- Seguro complementario de salud y dental\n- Horario flexible\n- Flexibilidad entre oficina y home office\n- Medio d\u00eda libre el d\u00eda de tu cumplea\u00f1os\n- Financiamiento de certificaciones\n- Inscripci\u00f3n en Coursera con plan de entrenamiento a medida\n- Estacionamiento de bicicletas\n- Vestimenta informal\n- Programa de referidos\n- Salida de \u201cteambuilding\u201d mensual        \n            \n                            \n            ",
        "Seniority level": "Not Applicable",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Ingeniero de Datos",
        "company": "Devaid",
        "location": "Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205299283/",
        "job_description": "En Devaid> nos apasionan los desaf\u00edos tecnol\u00f3gicos y nuestros clientes lo saben. Por lo anterior, nos plantean problem\u00e1ticas que nos obligan a estar constantemente probando e implementando nuevas tecnolog\u00edas.\nTrabajamos fuertemente en la nube ya que somos Partner Premier de Google Cloud en Chile, por lo que tendr\u00e1s la oportunidad de formarte como un profesional cloud.\nDependiendo de las necesidades del cliente, ofrece soluciones web, m\u00f3viles, integraci\u00f3n de sistemas, entre otros. Esto permite acceder a la herramienta sin importar el dispositivo ni el lugar d\u00f3nde se encuentra. Permitimos el trabajo colaborativo entre m\u00faltiples usuarios manteniendo una base centralizada de informaci\u00f3n.\n Funciones del cargo\nEsperamos Que Puedas Desempe\u00f1arte En Las Siguientes Actividades\n- Creaci\u00f3n de pipelines de carga y transformaci\u00f3n de datos.\n- Modelamiento de datos y creaci\u00f3n de Data Warehouse y Data Lakes.\n- Integraci\u00f3n de sistemas.\n- Creaci\u00f3n de modelos de machine learning con herramientas low code autoML.\nVas a participar como ingeniero de datos en equipos de consultores que prestan servicios a empresas importantes en Chile. En estos equipos participan distintos perfiles, tales como desarrolladores de software, arquitectos de datos y data scientists. Los servicios se prestan de forma remota y son prestados por proyecto (no es outsourcing de recursos), por lo que puedes trabajar desde tu casa sin problemas. Diariamente vas a tener reuniones con tu equipo para coordinar actividades y resolver temas complejos que vayan surgiendo.\n Requerimientos del cargo\nLos requisitos para un buen desempe\u00f1o de las funciones son:\n- 1 a\u00f1o de experiencia como Data Engineer. \n- Programaci\u00f3n en lenguaje Python, NodeJS o Java (al menos uno de los 3). \n- Conocimiento de soluciones de Data Warehouse y ETL. \n- Conocimiento de plataformas de procesamiento de datos como Apache Spark, Dataflow o similares. \n- Haber trabajado previamente con alguna nube p\u00fablica (AWS, Azure o GCP).\nSi no cumples alguno de estos puntos no te desanimes, queremos conocerte igualmente.\nEl trabajo es 100% remoto, pero es necesario que tengas RUT y/o papeles al d\u00eda en Chile.\n Deseables\nSuman puntos en tu postulaci\u00f3n si cumples alguna de las siguientes habilidades, ninguno de estos son excluyentes:\n- Conocimiento de herramientas Google Cloud, entre ellas Google BigQuery, Dataflow, Data Fusion y Pub Sub. \n- Experiencia en plataformas de deployment de infraestructura como Terraform. \n- Experiencia utilizando la herramienta de consola gcloud. \n Beneficios\nPrometemos un ambiente muy grato de trabajo, lleno de desaf\u00edos y donde podr\u00e1s ver los proyectos en los que estas involucrada/o siendo utilizados en un corto tiempo activamente por nuestros clientes, lo que siempre es muy gratificante.\nOtras Actividades\n- Actividades mensuales (Cupones de Food delivery, juegos en l\u00ednea, actividades grupales).\n- Actividad paseo anual: La empresa se junta por 2 d\u00edas en alg\u00fan lugar tur\u00edstico para realizar actividades grupales y unir al equipo.\n- D\u00eda libre flexible en tu cumplea\u00f1os.\n- Capacitaciones en lo que m\u00e1s te guste.\n- Certificaciones Google Cloud: Programa de certificaci\u00f3n en distintas ramas profesionales de GCP, gracias a que somos Partner Premier de Google Cloud en Chile.        \n            \n                            \n            ",
        "Seniority level": "Entry level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Data Engineer (GCP & DataFlow & Bigquery)",
        "company": "Option",
        "location": "Santiago Metropolitan Area",
        "date": "2025-04-12",
        "job_url": "https://www.linkedin.com/jobs/view/4208792219/",
        "job_description": "\u00bfQui\u00e9nes somos?\nEn \nOption\n, creemos en un mundo donde las soluciones tecnol\u00f3gicas no tienen l\u00edmites. Nuestra misi\u00f3n es transformar los desaf\u00edos en oportunidades mediante la creaci\u00f3n de soluciones innovadoras que potencien la Aceleraci\u00f3n Digital. Nuestro equipo es din\u00e1mico, colaborativo y apasionado por la tecnolog\u00eda. \u00danete a una organizaci\u00f3n que est\u00e1 redefiniendo c\u00f3mo el mundo utiliza los datos y la tecnolog\u00eda para resolver problemas complejos.\n\u00bfQu\u00e9 buscamos?\nEstamos en la b\u00fasqueda de un/a \nIngeniero/a de Datos\n para unirse al equipo de Data Services. Este rol ser\u00e1 clave en el levantamiento, an\u00e1lisis y migraci\u00f3n de procesos ETL desde un Data Lake mal gobernado hacia una arquitectura moderna sobre Google Cloud Platform (GCP). \u00a1Te estamos buscando!\n\u00bfQu\u00e9 te ofrece este puesto?\n- Participaci\u00f3n en un proceso estrat\u00e9gico de migraci\u00f3n a la nube.\n- Un entorno de trabajo colaborativo y con l\u00edderes t\u00e9cnicos accesibles.\n- Uso de tecnolog\u00edas modernas como GCP, Dataflow y BigQuery.\n- Trabajo conjunto con equipos de anal\u00edtica, desarrollo y operaci\u00f3n.\n\u00bfCu\u00e1les ser\u00e1n tus principales responsabilidades?\n- Levantar y documentar los ETLs actuales en Data Services.\n- Analizar el ambiente de datos y planificar su migraci\u00f3n a GCP.\n- Tomar iniciativa en la migraci\u00f3n de ETLs cr\u00edticos.\n- Resolver incidencias relacionadas a ETLs mediante la mesa de ayuda.\n- Participar en el dise\u00f1o del plan de migraci\u00f3n.\n- Colaborar con los l\u00edderes t\u00e9cnicos y equipos multidisciplinarios.\n\u00bfQu\u00e9 necesitas para ser nuestro pr\u00f3ximo Ingeniero de Datos?\nHabilidades T\u00e9cnicas Excluyentes\n- Oracle\n- Python\n- Dataflow (GCP)\n- Dataform (GCP)\n- GitLab\n- BigQuery (GCP)\n- Data Modeling\n- Composer (GCP)\nHabilidades T\u00e9cnicas Deseables\n- Oracle Data Integrator (ODI)\nUbicaci\u00f3n: LATAM\nModalidad de trabajo:\n 100% Remoto\n\u00a1\u00danete a nuestro equipo y transforma el futuro con nosotros!\nhttps://www.option.tech        \n            \n                            \n            ",
        "Seniority level": "Entry level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Information Technology & Services"
    },
    {
        "title": "Data Engineer",
        "company": "ICONSTRUYE",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205295718/",
        "job_description": "En ICONSTRUYE, hemos estado a la vanguardia de la tecnolog\u00eda en la construcci\u00f3n durante m\u00e1s de 20 a\u00f1os. Nuestra robusta plataforma tecnol\u00f3gica es un testimonio de nuestra experiencia y compromiso con la industria. Con m\u00e1s de 4,000 clientes en Chile, Colombia y Per\u00fa, nos enorgullecemos de proporcionar soluciones integrales que simplifican la cadena de abastecimiento. Buscamos un Ingeniero de Datos que se una a nosotros en la transformaci\u00f3n de la industria de la construcci\u00f3n, siendo el puente entre los datos brutos y aquellos que toman decisiones cr\u00edticas.\nTus Funciones Principales\nTu misi\u00f3n:\n Ser el puente entre los datos brutos y quienes necesitan realizar an\u00e1lisis y/o tomar decisiones con esos datos.\n- Garantizar la calidad, integridad y seguridad de los datos.\n- Colaborar con diversos stakeholders para comprender sus necesidades de datos.\n- Desarrollar procesos de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos para nuestro data lake, proporcionando informaci\u00f3n valiosa para el an\u00e1lisis y toma de decisiones.\n- Implementar nuevas bases de datos y/o data warehouses para satisfacer las necesidades de la empresa.\n- Contribuir a la definici\u00f3n de pol\u00edticas de gobernanza de datos.\n- Ser una autoridad en la creaci\u00f3n, implementaci\u00f3n y operaci\u00f3n de soluciones escalables y de bajo costo, facilitando el flujo de datos desde sistemas de producci\u00f3n hasta el data lake.\nRequerimientos T\u00e9cnicos\n- Dominio de Python o Go. \n- Dominio de SQL. \n- Conocimiento de base de datos relacionales y no relacionales (NoSQL). \n- Conocimiento de AirFlow, Luigi, Dagster. \n- Conocimientos de Kafka y/o RabbitMQ. \n- Conocimiento en Docker y Kubernetes. \nBeneficios Que Ofrecemos\n- \ud83c\udf34 5 d\u00edas extras de descanso al a\u00f1o.\n- \ud83c\udf54 Tarjeta amipass para utilizar en restaurantes, delivery y supermercados.\n- \ud83d\udc68\u200d\u2695\ufe0f Seguro complementario de salud, dental y de vida.\n- \ud83c\udfe0 Modalidad de trabajo h\u00edbrido.\n- \ud83d\udce0 Flexibilidad con permisos para tr\u00e1mites y asuntos familiares.\n- \ud83d\udc69\u200d\ud83d\udc66 Jornada reducida en d\u00edas de vacaciones escolares (viernes medio d\u00eda).\n- \ud83c\udf82 Tarde libre en tu cumplea\u00f1os.\n\u00a1\u00danete a nosotros y s\u00e9 parte de nuestra misi\u00f3n de transformar la industria de la construcci\u00f3n!\n                \n            \n                            \n            ",
        "Seniority level": "Not Applicable",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Ingeniero de Datos ($1.400.000 l\u00edquidos)",
        "company": "Vector",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-07",
        "job_url": "https://www.linkedin.com/jobs/view/4203857279/",
        "job_description": "Somos una empresa L\u00edder en el rubro TI. Nos encontramos en la b\u00fasqueda de Ingeniero de Datos, con experiencia en extracci\u00f3n de datos desde los sistemas fuente de est\u00e1ndares industriales y el\u00e9ctricos y su almacenaje en los destinos correspondientes, as\u00ed como tambi\u00e9n el asegurar la continuidad del funcionamiento de aplicaciones y redes OT que proporcionan datos a PMAC y ROCC.\nPrincipales Tareas\n- Sistematizar el traspaso de datos desde los distintos sistemas de la compa\u00f1\u00eda hacia los repositorios correspondientes para su consumo.\n- Participar en proyectos y entregar soluciones t\u00e9cnicas, procesos y requisitos.\n- Enfoque en la creaci\u00f3n de indicadores y KPI relevantes de las diferentes aplicaciones para reportar a nivel t\u00e9cnico y administrativo.\n- Realizar revisiones continuas de monitoreo para asegurarse de la continuidad del servicio.\n- Monitorear y controlar solicitudes y requerimientos de soporte (gesti\u00f3n de tickets).\n- Gestionar cualquier proceso de solicitud de cambio, asegur\u00e1ndose de que todas las solicitudes est\u00e9n debidamente documentadas y rastreadas. \n- Entregar soporte para que los servicios de OT se entreguen de acuerdo con los procedimientos operativos est\u00e1ndar y/o SLAs acordados; con enfoque en el servicio operativo, resoluci\u00f3n de problemas y respuesta \u00e1gil para el usuario final.\n- Escalar consultas complejas a la organizaci\u00f3n de soporte especializado correspondiente.\n- Identificar oportunidades de mejora del servicio a partir del an\u00e1lisis de tendencias de datos y las necesidades y aportes de los clientes/usuarios.\n- Involucrarse con stakeholders clave y para comprender sus requisitos y transmitir al \u00e1rea de resoluci\u00f3n correspondiente. \nConocimientos y experiencia \n- Estudios t\u00e9cnicos o profesionales en Telecomunicaciones, Instrumentaci\u00f3n, Sistemas, Computaci\u00f3n, Inform\u00e1tica, Electr\u00f3nica o carreras afines).\n- Instrumentista con conocimiento en programaci\u00f3n y transferencia de datos, o Ingeniero de Datos con conocimiento en protocolos industriales y sus est\u00e1ndares de comunicaci\u00f3n.\n- Conocimientos de redes de comunicaciones y soluciones de transporte de datos.\n- Gesti\u00f3n de datos y visualizaci\u00f3n usando herramientas cloud (Google, Microsoft).\n- Conocimientos de un lenguaje de scripting, preferiblemente Python.\n- Manejo b\u00e1sico de base de datos SQL.\n- Conocimientos b\u00e1sicos en gesti\u00f3n de accesos e identidades.\n- Conocimientos b\u00e1sicos en administraci\u00f3n de servidores.\n- Experiencia laboral de 5 a\u00f1os preferiblemente en empresas industriales.\n- Deseable manejo de ingles a nivel t\u00e9cnico intermedio.\nConocimientos espec\u00edficos\n- Conocimiento de protocolos industriales del sector el\u00e9ctrico (IEC-60870-5-104, Modbus, DNP 3.0).\n- Protocolos Industriales de comunicaci\u00f3n: Modbus TCP/IP, JSON, CSV, DNP3, SQL.\n- Conocimiento de sistemas SCADA.\n- Conocimientos de protocolos de transici\u00f3n con industria 4.0 (Modbus TCP, OPC UA, MQTT, HTTP, etc.).\nFundamentos de ciberseguridad.\nHorario\nLunes a viernes 08:00 a 18:00 / 08:30 a 18:30\nBeneficios\n-  Reajuste anual de sueldo de acuerdo a IPC\n-  Bonificaci\u00f3n anual por desempe\u00f1o laboral.\n-  Posibilidad de acceder a cursos de capacitaci\u00f3n en las diversas tem\u00e1ticas del cargo.\n-  Convenios de Salud, Dentales y \u00f3pticos, accesos a descuentos preferenciales y facilidades de pagos mediante descuentos por planilla sin inter\u00e9s.\n-  Posibilidad de entrega de aguinaldo de fiestas patrias y Navidad conforme a cumplimiento de antig\u00fcedad.\n-  Convenio seguro Oncol\u00f3gico a valor preferencial y con aporte de la organizaci\u00f3n y del colaborador.\n-  Regalo de gift card por nacimiento de hijo (a).\n-  Convenios bancarios (scotiabank y Banco de Chile) para planes de tarjetas de cuentas vista y corriente a valores preferenciales.        \n            \n                            \n            ",
        "Seniority level": "Not Applicable",
        "Employment type": "Contract",
        "Job function": "Information Technology",
        "Industries": "Information Technology & Services"
    },
    {
        "title": "Data Engineer Soluciones de Datos",
        "company": "LISIT",
        "location": "Biob\u00edo Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205294845/",
        "job_description": "En *Lisit*, nos dedicamos a crear, desarrollar e implementar servicios de software que ofrecen herramientas de automatizaci\u00f3n y optimizaci\u00f3n. Nuestra misi\u00f3n es promover la eficacia en la operatividad de nuestros clientes a trav\u00e9s de un soporte consultivo que integra diversas herramientas y pr\u00e1cticas. Buscamos contribuir al \u00e9xito de las transformaciones empresariales mediante estrategias integrales de acompa\u00f1amiento e implementaci\u00f3n.\n Que estamos buscando\n- Dise\u00f1ar, desarrollar y mantener infraestructuras y pipelines de datos escalables y confiables.\n- Optimizar el almacenamiento, procesamiento y recuperaci\u00f3n de datos para un funcionamiento eficiente e impecable.\n- Colaborar con equipos de diferentes departamentos para recopilar y analizar los requisitos de datos.\n- Garantizar la calidad, integridad y seguridad de los datos durante todo el ciclo de vida de estos.\n- Mantenerse actualizado sobre los \u00faltimos avances, desarrollos y enfoques en ingenier\u00eda de datos.\n \u00bfQu\u00e9 habilidades y experiencia necesitas?\n- Fuertes habilidades anal\u00edticas y de resoluci\u00f3n de problemas.\n- Al menos 3 a\u00f1os de experiencia en ingenier\u00eda de datos.\n- Experiencia comprobada en el dise\u00f1o y desarrollo de data pipelines y procesos ETL, preferiblemente con Azure Data Factory.\n- Amplia experiencia en SQL y dominio de al menos un lenguaje de ingenier\u00eda de datos, como Python o Scala.\n- Experiencia con Spark, Airflow y tecnolog\u00edas Big Data relacionadas.\n- Familiaridad con plataformas de datos basadas en la nube como AWS, Azure o GCP.\n- Excelentes habilidades de comunicaci\u00f3n y colaboraci\u00f3n.\n Deseable\nSe valorar\u00e1 la experiencia con herramientas de BI como Power BI y Microsoft Fabric. Tambi\u00e9n es deseable contar con alguna de las siguientes certificaciones: DP-203, PL-300, DP-600 y/o DP-700.\n \u00danete a nosotros\nEn *Lisit* ofrecemos un ambiente de trabajo innovador y colaborativo. Nos aseguramos de que nuestros empleados disfruten de un equilibrio entre trabajo y vida personal, con programas de capacitaci\u00f3n y desarrollo continuo. Valoramos tu entusiasmo y pasi\u00f3n por la ingenier\u00eda de datos.\nEstamos emocionados por conocer a personas con una mentalidad abierta y dispuestas a enfrentar nuevos desaf\u00edos. \u00a1Si est\u00e1s listo para innovar y crecer con nosotros, te queremos en nuestro equipo!\nEn el caso de residir en Santiago, debe tener disponibilidad para viajar una o dos semanas a Los Angeles, regi\u00f3n del BioB\u00edo\n                \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Data Engineer",
        "company": "Seeds",
        "location": "Santiago Metropolitan Region, Chile",
        "date": "2025-04-07",
        "job_url": "https://www.linkedin.com/jobs/view/4189755534/",
        "job_description": "\u00bfSos \nData Engineer\n? Entonces\u2026 \u00bfQu\u00e9 est\u00e1s esperando para sumarte a nuestra comunidad de Seeders? \u00a1Aplica a nuestra comunidad y accede a trabajo on-demand en las empresas l\u00edderes, sumate al Present of Work!\n\u00bfQui\u00e9nes somos?\nSomos una \ncomunidad\n que re\u00fane al mejor talento on-demand de Latinoam\u00e9rica, y lo conecta con las empresas l\u00edderes de la regi\u00f3n. Gestionamos el match perfecto entre las necesidades de las empresas y el talento con las competencias y la experiencia buscada, fomentando flexibilidad y el desarrollo profesional de nuestra comunidad.\nNo somos una plataforma m\u00e1s de freelancers, Seeds lidera un dream team de profesionales altamente calificados que eligen d\u00f3nde, c\u00f3mo y para qui\u00e9n trabajar, disfrutando as\u00ed de contribuir a una misi\u00f3n m\u00e1s grande, definiendo y moldeando la forma en que trabajamos.\nEstamos buscando sumar a nuestro Talent Pool roles de \nData Engineer\n para nuestra comunidad de Seeders.\nEstas son algunas de las responsabilidades usuales del rol:\n- Dise\u00f1ar, construir y mantener arquitecturas de datos robustas y escalables.\n- Desarrollar y optimizar pipelines de datos para recopilaci\u00f3n, almacenamiento, procesamiento y an\u00e1lisis de grandes vol\u00famenes de datos.\n- Implementar modelos de datos y algoritmos para resolver problemas de negocio y proveer insights accionables.\n- Trabajar en estrecha colaboraci\u00f3n con equipos de data scientists y analistas para apoyar sus requisitos de datos y facilitar el an\u00e1lisis de datos.\n- Asegurar la integridad, disponibilidad y confidencialidad de los datos a trav\u00e9s de las mejores pr\u00e1cticas de seguridad y gobernanza de datos.\n- Mantenerse al d\u00eda con las \u00faltimas tecnolog\u00edas y tendencias en el campo de la ingenier\u00eda de datos.\nRequisitos\n- Experiencia m\u00ednima de 3 a\u00f1os en roles de ingenier\u00eda de datos.\n- Fuerte dominio de lenguajes de programaci\u00f3n como Python, Java o Scala.\n- Experiencia trabajando con grandes vol\u00famenes de datos y herramientas de procesamiento de datos (como Hadoop, Spark).\n- Conocimientos en bases de datos SQL y NoSQL, as\u00ed como en soluciones de almacenamiento de datos en la nube (AWS, Google Cloud, Azure).\n- Capacidad para trabajar en entornos \u00e1giles y multidisciplinarios.\n- Ingl\u00e9s intermedio (deseable).\n\u00bfPor qu\u00e9 sumarte a nuestra comunidad de Seeders?\nEleg\u00ed tus proyectos.\nTrabaj\u00e1 desde donde vos quieras.\nEventos de networking.\nAsesoramiento personalizado.\nSeeds Academy: Potencia tu desarrollo profesional adquiriendo nuevas skills (upskilling & reskilling), participando de webinars, Bootcamps y otras acciones exclusivas para la comunidad.\nNo dejes de sumarte a nuestra comunidad de Seeds y aplicar a oportunidades de empresas lideres de la regi\u00f3n. \u00a1Te esperamos!        \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Consulting",
        "Industries": "Technology, Information and Media"
    },
    {
        "title": "Senior Data Engineer Python",
        "company": "23people",
        "location": "Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205294906/",
        "job_description": "\u00danete a Equifax Chile como Senior Data Engineer Python Somos l\u00edderes en soluciones de informaci\u00f3n y tecnolog\u00eda, operando globalmente para transformar el uso de la informaci\u00f3n con transparencia y seguridad. Estamos en un proyecto de migraci\u00f3n clave que requiere revisi\u00f3n de pipelines de datos, creaci\u00f3n de queries, dise\u00f1o de flujos de procesos, an\u00e1lisis de sistemas legados y documentaci\u00f3n t\u00e9cnica y de negocio. Valoramos la innovaci\u00f3n, la colaboraci\u00f3n y el conocimiento t\u00e9cnico. Si tienes habilidades anal\u00edticas excepcionales y pasi\u00f3n por la tecnolog\u00eda, \u00a1aplica hoy y s\u00e9 parte de nuestra transformaci\u00f3n digital!\n Funciones del cargo\n\u00bfQu\u00e9 har\u00e1s en tu d\u00eda a d\u00eda?\nEl profesional colaborar\u00e1 con un equipo multidisciplinario en un proyecto de expansi\u00f3n internacional, enfocado en la migraci\u00f3n estrat\u00e9gica de la plataforma hacia nuevos mercados. Su participaci\u00f3n ser\u00e1 fundamental para asegurar una implementaci\u00f3n eficiente que considere las particularidades de cada pa\u00eds destino, garantizando as\u00ed el \u00e9xito de esta iniciativa global.\nAlgunas De Sus Tareas Diarias Son Las Siguientes\n- Implementar mecanismos para verificar la integridad de los datos migrados\n- Implementar transformaciones espec\u00edficas para requisitos regionales\n- Dirigir el equipo t\u00e9cnico durante las fases cr\u00edticas de migraci\u00f3n\n- Gestionar el proceso integral de ETL entre diversos sistemas, desarrollando y optimizando los esquemas de mapeo necesarios para garantizar la compatibilidad entre las estructuras de datos de origen y destino.\n Requerimientos del cargo\nSkills\nT\u00e9cnicas\n- Python\n- BigQuery/SQL\n- GitHub\n- Apache Beam/Spark/Google Dataflow\nPersonales\n- Capacidad de autogesti\u00f3n\n- Buenos skills de comunicaci\u00f3n\n- Fortaleza en trabajo en equipo\n- Adaptaci\u00f3n al cambio (trabajar\u00e1n en distintas geos de Latam)\nContrato indefinido desde el inicio con 23people\nModalidad: Home Office, Con residencia en Chile (Deber\u00e1s ir a buscar el PC en primera instancia)\nExperiencia: Desde 5 a\u00f1os en adelante\nHorario: Lunes a Jueves de 8:30 a 6:30 y Viernes de 8:30 a 5:30 hrs.\n Deseables\n- Perfil Anal\u00edtico\n- UnitTest\n- AirFlow\n- PySpark\n- CI/CD\n- Postman\n- Jmeter\n Beneficios\nAlgunos de nuestros beneficios\n- Seguro complementario: Seguro de salud, vida y dental\n- Curso de ingl\u00e9s: En nuestro programa de formaci\u00f3n en idioma ingl\u00e9s, ofrecemos dos modalidades para adaptarnos a tus necesidades y objetivos.\n- Reembolso de certificaciones internacionales: Apoyamos el crecimiento profesional, por lo que te reembolsamos el costo de un examen de certificaci\u00f3n internacional que quieras realizar.\n- Bono de vacaciones: Por cada semana que te tomes de vacaciones te otorgamos una compensaci\u00f3n.\n- Aguinaldos en fiestas patrias y Navidad: Queremos que en fechas tan especiales la pases bien junto a tu familia, por lo que te entregamos un bono en septiembre y diciembre\n- D\u00eda libre de cumplea\u00f1os: Puedes optar por tomar tu d\u00eda libre, el d\u00eda previo a tu cumplea\u00f1os, el mismo d\u00eda de tu cumplea\u00f1os o el d\u00eda posterior.        \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Analista de datos",
        "company": "Ripley Chile",
        "location": "Las Condes, Santiago Metropolitan Region, Chile",
        "date": "2025-04-08",
        "job_url": "https://www.linkedin.com/jobs/view/4204266753/",
        "job_description": ""
    },
    {
        "title": "Graduate 2025 Software Engineer I Backend, Chile",
        "company": "Uber",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205853556/",
        "job_description": ""
    },
    {
        "title": "Ingeniero de Datos/ Dbt",
        "company": "BC Tecnolog\u00eda",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205500332/",
        "job_description": "En BC Tecnolog\u00eda, somos una consultora de TI con m\u00e1s de seis a\u00f1os de experiencia, especializada en ofrecer soluciones personalizadas para nuestros clientes en sectores como servicios financieros, seguros, retail y gobierno. Nos enfocamos en consultor\u00eda, outsourcing, desarrollo de proyectos y formaci\u00f3n de equipos, siempre con un claro compromiso hacia la satisfacci\u00f3n del cliente. Como parte de nuestro equipo, el ingeniero/a de datos jugar\u00e1 un papel clave en la creaci\u00f3n de soluciones basadas en tecnolog\u00edas de la nube, impulsando la innovaci\u00f3n y la colaboraci\u00f3n en un entorno de trabajo \u00e1gil.\n Responsabilidades Clave\nEl Ingeniero/a De Datos Ser\u00e1 Responsable De\n- Dise\u00f1ar y mantener pipelines de datos utilizando BigQuery y DBT.\n- Implementar tareas programadas en Google Cloud Platform (GCP) para la ingesta y procesamiento continuo de datos.\n- Construir y documentar modelos de datos optimizados para su an\u00e1lisis.\n- Validar y realizar pruebas para garantizar la precisi\u00f3n de los datos transformados.\n- Realizar seguimiento y documentaci\u00f3n de cambios en modelos y sus transformaciones.\n Requisitos T\u00e9cnicos\nBuscamos Un Ingeniero/a De Datos Con\n- Experiencia avanzada en BigQuery y DBT.\n- Conocimiento pr\u00e1ctico en Google Cloud Platform, incluyendo la programaci\u00f3n de tareas y almacenamiento.\n- S\u00f3lido manejo de SQL y experiencia en modelado de datos.\n- Capacidad para documentar procesos y realizar pruebas de calidad de datos de manera eficiente.\n Lo que ofrecemos\nBrindamos un contrato por proyecto de 12 meses en modalidad h\u00edbrida, lo que permite combinar trabajo remoto con visitas a la oficina 2 a 3 d\u00edas a la semana. Tambi\u00e9n garantizamos un enfoque en la inclusi\u00f3n, en cumplimiento con la Ley N\u00ba 21.015, promoviendo un entorno donde todos los empleados puedan prosperar.\n Beneficios        \n            \n                            \n            ",
        "Seniority level": "Not Applicable",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Data Analyst",
        "company": "Macal Remates",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205298423/",
        "job_description": ""
    },
    {
        "title": "Ingeniero de Datos Maestros (Proyecto Corporativo)",
        "company": "Agrosuper",
        "location": "Rancagua, O'Higgins Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205297494/",
        "job_description": "En Agrosuper, tenemos la misi\u00f3n de llevar alimentos de la m\u00e1s alta calidad a las familias de Chile y el mundo. Nos mueve el deseo de alimentar el talento y las ganas de crecer constantemente. Buscamos mejorar y fomentar un entorno donde todos disfruten lo bueno de la vida, por lo que valoramos a las personas, que son el alma de nuestra organizaci\u00f3n. Este cargo de Ingeniero de Datos Maestros (Corporativo) es fundamental para garantizar la calidad y disponibilidad de nuestros Datos Maestros a trav\u00e9s de la optimizaci\u00f3n de procesos y recursos en nuestras unidades de negocio.\n Principales Funciones\n- Gestionar los Datos Maestros en diversos Proyectos Corporativos.\n- Identificar y proponer mejoras, optimizando y eficientando nuestros procesos internos.\n- Gestionar la creaci\u00f3n de c\u00f3digos de distintos Datos Maestros considerados cr\u00edticos por la Organizaci\u00f3n.\n- Definir y configurar en SAP Estrategias de Liberaci\u00f3n (Compras).\n- Validar y autorizar \u00d3rdenes de Transportes Customizing en SAP.\n- Validar est\u00e1ndares de los Datos Maestros en SAP.\n- Evaluar y desarrollar parametrizaciones t\u00e9cnicas de Customizing alrededor de los Datos Maestros en SAP.\n- Asesorar al Equipo de Datos Maestros sobre dudas y buenas pr\u00e1cticas en el Gobierno de Datos Maestros.\n Requisitos\n- T\u00edtulo profesional en \u00e1reas como Ingenier\u00eda Civil Industrial, Comercial, Inform\u00e1tica o similar.\n- Experiencia laboral m\u00ednima de 2 a\u00f1os en roles similares.\n- Experiencia en SAP, espec\u00edficamente en Gobierno de Datos Maestros (certificado).\n- Conocimientos en herramientas de an\u00e1lisis y visualizaci\u00f3n, especialmente en Excel a nivel avanzado.\nDesirable Skills\nSi bien los requisitos mencionados son fundamentales, tambi\u00e9n valoramos habilidades adicionales que pueden enriquecer la experiencia en este rol. Esto incluye certificaciones adicionales en SAP, experiencia en gesti\u00f3n de proyectos y habilidades en liderazgo y trabajo en equipo. Adem\u00e1s, el deseo de mantenerse al d\u00eda con las tendencias en tecnolog\u00eda y an\u00e1lisis de datos ser\u00e1 considerado un gran plus.\n Beneficios\nAgrosuper ofrece un entorno de trabajo inspirador donde se valora el crecimiento tanto profesional como personal. Contamos con planes de crecimiento y desarrollo, capacitaci\u00f3n continua y becas de estudios, adem\u00e1s de convenios con distintas instituciones. Tambi\u00e9n ofrecemos bonos asociados al desempe\u00f1o para incentivar el trabajo de nuestros colaboradores. Adem\u00e1s, promovemos la inclusi\u00f3n de colaboradores con discapacidad, asegurando que todos tengan la oportunidad de contribuir a nuestro prop\u00f3sito de alimentar lo bueno de la vida.\n                \n            \n                            \n            ",
        "Seniority level": "Not Applicable",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Ingeniero de Datos",
        "company": "AyCA SpA",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4206696535/",
        "job_description": "Company Description: AyCA Spa\nJob Description: En AyCA SPA nos encontramos en b\u00fasqueda de un Ingeniero de Datos.\nProp\u00f3sito o Misi\u00f3n del Cargo\nEl Ingeniero de Datos en Mantenimiento de Planta es responsable de dise\u00f1ar, implementar y gestionar la infraestructura de datos y los sistemas de an\u00e1lisis necesarios para optimizar las estrategias y procesos de mantenimiento. Su rol principal es transformar los datos generados por los equipos, sistemas de monitoreo y actividades de mantenimiento en informaci\u00f3n valiosa y accionable que permita mejorar la confiabilidad de los activos, reducir costos, predecir fallas y optimizar la planificaci\u00f3n de las intervenciones.\nPrincipales Responsabilidades\n-  Dise\u00f1o e Implementaci\u00f3n de la Arquitectura de Datos\n-  Colaborar con el equipo de mantenimiento y TI para comprender las necesidades de datos y dise\u00f1ar una arquitectura robusta y escalable para la recopilaci\u00f3n, almacenamiento, procesamiento y an\u00e1lisis de datos de mantenimiento.\n-  Seleccionar e implementar las herramientas y tecnolog\u00edas adecuadas para la gesti\u00f3n de datos (bases de datos, data lakes, plataformas de procesamiento en la nube, etc.).\n-  Establecer y mantener los procesos de extracci\u00f3n, transformaci\u00f3n y carga (ETL/ELT) de datos desde diversas fuentes (CMMS, sensores IoT, registros manuales, etc.).\n-  Integraci\u00f3n de sistemas SCADA y PLCs con tecnolog\u00edas cloud (OPC UA, MQTT, REST APIs)\n-  Garantizar la calidad, integridad y seguridad de los datos de mantenimiento.\n-  Desarrollo de Soluciones de An\u00e1lisis y Reporte\n-  Desarrollar modelos de datos y esquemas que faciliten el an\u00e1lisis y la generaci\u00f3n de insights relevantes para el mantenimiento.\n-  Crear dashboards, informes y visualizaciones interactivas que permitan al equipo de mantenimiento monitorear KPIs, identificar tendencias, evaluar la efectividad de las estrategias y tomar decisiones informadas.\n-  Implementar t\u00e9cnicas de an\u00e1lisis predictivo (machine learning, inteligencia artificial) para predecir fallas de equipos, optimizar la planificaci\u00f3n de mantenimiento preventivo y proactivo.\n-  Automatizar la generaci\u00f3n de informes y alertas para facilitar la toma de decisiones en tiempo real.\n-  Dise\u00f1ar e implementar flujos de procesamiento de datos industriales.\n-  Construir y entrenar modelos de ML para detecci\u00f3n de fallas y patrones de operaci\u00f3n.\n-  Dise\u00f1ar estrategias para la optimizaci\u00f3n y escalabilidad del sistema de IA.\n-  Integrar modelos de IA con bases de datos y sistemas de control industriales.\n-  Asegurar la seguridad y confiabilidad del sistema en entornos industriales.\n-  Soporte y Optimizaci\u00f3n de Sistemas de Datos\n-  Monitorear y mantener el rendimiento y la disponibilidad de la infraestructura de datos de mantenimiento.\n-  Identificar y resolver problemas relacionados con la calidad, integridad y flujo de datos.\n-  Optimizar los procesos de ETL/ELT y las consultas de datos para mejorar la eficiencia del an\u00e1lisis.\n-  Mantener la documentaci\u00f3n t\u00e9cnica de la arquitectura de datos, los procesos y las soluciones implementadas.\n-  Colaboraci\u00f3n y Comunicaci\u00f3n\n-  Trabajar en estrecha colaboraci\u00f3n con el equipo de mantenimiento (planificadores, supervisores, t\u00e9cnicos), el departamento de TI y otros stakeholders para comprender sus necesidades de datos y ofrecer soluciones efectivas.\n-  Comunicar de manera clara y concisa los hallazgos del an\u00e1lisis de datos y las recomendaciones al equipo de mantenimiento y la gerencia.\n-  Participar en reuniones y proyectos relacionados con la mejora continua y la transformaci\u00f3n digital del \u00e1rea de mantenimiento.\n-  Capacitar al personal de mantenimiento en el uso de las herramientas y los informes de an\u00e1lisis de datos.\n-  Documentar procesos y modelos.\n-  Investigaci\u00f3n y Desarrollo\n-  Mantenerse actualizado sobre las \u00faltimas tendencias y tecnolog\u00edas en el campo del an\u00e1lisis de datos, la inteligencia artificial y el mantenimiento predictivo.\n-  Investigar y proponer nuevas herramientas y t\u00e9cnicas que puedan mejorar la eficiencia y efectividad del mantenimiento basado en datos.\n-  Participar en proyectos piloto para la implementaci\u00f3n de nuevas soluciones de an\u00e1lisis.\nRequisitos\n-  T\u00edtulo profesional en Ingenier\u00eda (Inform\u00e1tica, Industrial, Mec\u00e1nica, El\u00e9ctrica o carreras afines) con especializaci\u00f3n o experiencia en an\u00e1lisis de datos, ciencia de datos o gesti\u00f3n de informaci\u00f3n.\nExperiencia\n-  Plataformas de nube p\u00fablica: AWS (IoT Core, Lambda, S3), Azure (IoT Hub, Functions) o Google Cloud (Pub/Sub, Firestore).\n-  Dise\u00f1o o implementaci\u00f3n de dashboards para visualizaci\u00f3n de datos industriales (Power BI, Grafana, etc.).\n-  Haber desarrollado proyectos similares, ya sea como profesional o estudiante (tesis).\n-  Experiencia en el desarrollo de modelos de Machine Learning.\n-  Experiencia pr\u00e1ctica con Python, pandas, scikit-learn, TensorFlow, XGBoost o similares.\n-  Experiencia en arquitectura de datos: bases SQL, ETL, APIs.\n-  Conocimientos en integraci\u00f3n de sistemas industriales mediante APIs REST, OPC-UA o MQTT.\n-  Capacidad para dise\u00f1ar arquitecturas escalables y eficientes.\n-  Conocimiento en ciberseguridad industrial.\n-  Familiaridad con software industriales.\n-  Experiencia en desarrollo de aplicaciones para entornos industriales.\nSi crees que cumples con las competencias env\u00edanos tu CV indicando pretensiones de renta y disponibilidad.\nAy\u00fadanos a compartir para llegar a mas personas !!\n                \n            \n                            \n            ",
        "Seniority level": "Entry level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Mining"
    },
    {
        "title": "Data Engineer AWS \u2013 Contrato Indefinido.",
        "company": "BC Tecnolog\u00eda",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-09",
        "job_url": "https://www.linkedin.com/jobs/view/4204878459/",
        "job_description": "Company Description: BC Tecnolog\u00eda\nJob Description: Experiencia de 3 a\u00f1os en:\n-  Explotaci\u00f3n de datos (Tunnig)\n-  ETL\n-  SQL\n-  Python\n-  Apache Airflow (Deseable)\n-  AWS (Glue, Lambda, S3, Redshift, Dynamodb\n-  Trabajo Hibrido\nInteresados o referidos favor enviar cv actualizado a [email] indicando en asunto de e-mail cargo al cual postula (Data Engineer AWS)\n                \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Information Technology & Services"
    },
    {
        "title": "Data Engineer \u2013 Proyecto de 6 Meses",
        "company": "BC Tecnolog\u00eda",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205297473/",
        "job_description": "En BC Tecnolog\u00eda, somos una consultora de TI comprometida con ofrecer soluciones innovadoras y adaptadas a las necesidades de nuestros clientes. Con m\u00e1s de 6 a\u00f1os de experiencia en el sector, trabajamos con empresas en diferentes industrias, incluyendo servicios financieros, seguros, retail y gobierno. En este proyecto de Data Engineering, tendr\u00e1s la oportunidad de contribuir al dise\u00f1o y construcci\u00f3n de pipelines de datos para nuestros clientes, utilizando metodolog\u00edas \u00e1giles y colaborando con equipos altamente especializados.\n Responsabilidades del Rol\n- Dise\u00f1ar y construir pipelines de datos efectivos para cumplimentar las necesidades anal\u00edticas de nuestros clientes.\n- Programar usando lenguajes como Python, Scala o SQL para manipulaci\u00f3n y transformaci\u00f3n de datos.\n- Implementar y gestionar herramientas de orquestaci\u00f3n de pipelines, como Airflow, Mage, NiFi o similares.\n- Colaborar en pr\u00e1cticas de CI/CD, incluidos conocimientos b\u00e1sicos en Git y versionado de c\u00f3digo.\n- Integrar arquitecturas de datos, con un enfoque en Datalakes, Datawarehouses o Lakehouse.\n- Participar en modelado de datos utilizando t\u00e9cnicas dimensional, estrella y copo de nieve, si es requerido.\n Requisitos y Habilidades\nBuscamos candidatos que cuenten con al menos 2 a\u00f1os de experiencia en el \u00e1rea de Data Engineering. Deber\u00e1n tener competencias en dise\u00f1o y construcci\u00f3n de pipelines de datos, as\u00ed como experiencia con lenguajes de programaci\u00f3n pertinentes como Python, Scala o SQL.\nEs esencial dominar herramientas de orquestaci\u00f3n de datos, y tener un conocimiento b\u00e1sico sobre integraciones de CI/CD y flujos de trabajo de versionamiento de c\u00f3digo. Adicionalmente, es deseable contar con experiencia en arquitecturas de datos y modelado, incluidos Datalakes y t\u00e9cnicas de modelado espec\u00edficas.\nLa modalidad de trabajo es h\u00edbrida, lo que permitir\u00e1 equilibrar la colaboraci\u00f3n en persona con flexibilidad laboral.\n Habilidades Deseables\nSi bien no es un requisito, consideraremos positivamente la experiencia previa con Datalakes y Datawarehouses, as\u00ed como familiaridad con t\u00e9cnicas de modelado como dimensional, estrella o copo de nieve. Esto contribuir\u00e1 a un mejor entendimiento del contexto de las soluciones que desarrollaremos.\n Beneficios y Condiciones\nOfrecemos Un Contrato Por Proyecto De 6 Meses, Con Posibilidad De Extensi\u00f3n. Los Empleados Disfrutar\u00e1n De Un Sueldo a Convenir, Adem\u00e1s De Beneficios Adicionales Como\n- Seguro complementario.\n- Amipass de $4,500 por d\u00eda laborado.\n- Convenciones, actividades y bonos.\nEstamos ubicados en Alto Las Condes, permitiendo un ambiente de trabajo funcional y moderno. \u00a1Nos encantar\u00eda contar contigo en nuestro equipo! \ud83c\udf1f\n                \n            \n                            \n            ",
        "Seniority level": "Not Applicable",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Software Engineer",
        "company": "NeuralWorks",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205295705/",
        "job_description": ""
    },
    {
        "title": "Analista de Datos en GCP",
        "company": "BC Tecnolog\u00eda",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205294840/",
        "job_description": ""
    },
    {
        "title": "Analista de Datos",
        "company": "MindCo",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205553758/",
        "job_description": ""
    },
    {
        "title": "Analista de Datos",
        "company": "Outlier",
        "location": "Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4207881229/",
        "job_description": ""
    },
    {
        "title": "Senior Data Engineer",
        "company": "Grupo Falabella",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-09",
        "job_url": "https://www.linkedin.com/jobs/view/4205321119/",
        "job_description": "Somos m\u00e1s de 90 mil personas que, d\u00eda a d\u00eda, dedicamos nuestra pasi\u00f3n y energ\u00eda a cumplir nuestro Prop\u00f3sito de \u201cSimplificar y Disfrutar M\u00e1s la Vida\u201d. Prop\u00f3sito que hoy vive a trav\u00e9s de nuestro ecosistema f\u00edsico y digital en todas nuestras empresas (Falabella Retail, Sodimac, IKEA, Tottus, Mallplaza, Falabella Inmobiliario, Falabella.com, Linio, Falabella Financiero, Banco Falabella, Falabella Soriana, Seguros Falabella, Fazil, Fpay y Falabella Corporativo) y pa\u00edses (Argentina, Brasil, Chile, China, Colombia, India, M\u00e9xico, Per\u00fa y Uruguay).\nSi disfrutas nuevos desaf\u00edos con alta responsabilidad y exposici\u00f3n en el epicentro de la transformaci\u00f3n en Latinoam\u00e9rica, esta oportunidad es para ti. Buscamos un Senior Data Engineer\ud83d\udc68\u200d\ud83d\udcbb para sumarse a uno de nuestros equipo, quien sera el encargado de dise\u00f1ar, construir y mantener sistemas de datos escalables, para el an\u00e1lisis y la toma de decisiones en la organizaci\u00f3n.\nFunciones Del Cargo\nDise\u00f1ar y desarrollar canalizaciones de datos (ETL/ELT) robustas y eficientes. \nColaborar con equipos de ingenier\u00eda de datos.\nImplementar y gestionar bases de datos y data warehouses. \nOptimizar el rendimiento de las bases de datos y sistemas de almacenamiento de datos. \nGarantizar la calidad, integridad y seguridad de los datos. \nAutomatizar procesos de ingesti\u00f3n y transformaci\u00f3n de datos.\nMonitorizar y solucionar problemas relacionados con los sistemas de datos. \nDocumentar procesos, arquitecturas y mejores pr\u00e1cticas relacionadas con el manejo de datos.\nRequisitos\nProfesional titulado en Ingenier\u00eda Civil Computaci\u00f3n, Industrial, matem\u00e1tico u el\u00e9ctrico.\nExperiencia demostrable como Data Engineer\nExperiencia en lenguajes de programaci\u00f3n Python.\nExperiencia con Google Cloud Platform (Composer, Cloud Functions, Bigquery, Dataproc, etc)\nExperiencia utilizando git.\nConocimientos profundos en SQL y en bases de datos relacionales y no relacionales\nDeseable: Certificaci\u00f3n Associate Engineer\nDeseable: Nivel de Ingl\u00e9s intermedio (B1+)\nDeseable: Certificaciones relevantes en tecnolog\u00edas de datos y cloud.\nSi te apasionan los desafios numerico \ud83d\ude80\ud83d\udc68\u200d\ud83d\udcbby buscas ser parte de un gran team, ven y postula con nosotros!!\nSomos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusi\u00f3n en todas sus formas, sin importar religi\u00f3n, raza, g\u00e9nero, situaci\u00f3n de discapacidad, nacionalidad.\nConoce m\u00e1s oportunidades para vivir la #ExperienciaFalabella en https://muevete.falabella.com/        \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Financial Services"
    },
    {
        "title": "Data Engineer",
        "company": "Mediastream",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4206504298/",
        "job_description": "Description\nMediastream is a leading streaming technology company that has been in business for over 16 years. We collaborate with major companies and broadcasters around the world to offer a quality end-to-end solution for content administration, distribution, audiovisual production, and user experience. Our goal is to connect our customers with their audience in a simple and effective way, creating new revenue streams for their businesses.\nRole Description\nThis is a hibrid role for a Data Egineer. The Data Engineer will be responsible for proposing advanced applications of our data, reviewing patterns, deviations to detect trends to optimize dashboards and optimize advertising strategies. Promote new strategies and technologies to process, analyze and leverage customer data and improve user engagement. With the main objective of: Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights, which serve for product roadmap, Develop and manage efficient data pipelines and ETL workflows for the integration of diverse data sources and Use machine learning models and recommendation algorithms to personalize strategies.\nResponsibilities\n- Create, implement and maintain the company's data architecture.\n- Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights for product roadmap.\n- Develop and manage data pipelines and ETL workflows for the integration of diverse data sources.\n- Use machine learning models and recommendation algorithms to personalize strategies.\n- Create interactive visualizations and dashboards for studies to monitor performance and make data-driven decisions.\n- Collaborate closely with the development team to integrate, create features and roadmap proposals. \n- Have a product vision and work closely with the marketing and development teams to align strategies with business objectives.\n\">\nMediastream is a leading streaming technology company that has been in business for over 16 years. We collaborate with major companies and broadcasters around the world to offer a quality end-to-end solution for content administration, distribution, audiovisual production, and user experience. Our goal is to connect our customers with their audience in a simple and effective way, creating new revenue streams for their businesses.\nRole Description\nThis is a hibrid role for a Data Egineer. The Data Engineer will be responsible for proposing advanced applications of our data, reviewing patterns, deviations to detect trends to optimize dashboards and optimize advertising strategies. Promote new strategies and technologies to process, analyze and leverage customer data and improve user engagement. With the main objective of: Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights, which serve for product roadmap, Develop and manage efficient data pipelines and ETL workflows for the integration of diverse data sources and Use machine learning models and recommendation algorithms to personalize strategies.\nResponsibilities\n- Create, implement and maintain the company's data architecture.\n- Process, analyze and visualize audience, behavioral and engagement data to obtain valuable insights for product roadmap.\n- Develop and manage data pipelines and ETL workflows for the integration of diverse data sources.\n- Use machine learning models and recommendation algorithms to personalize strategies.\n- Create interactive visualizations and dashboards for studies to monitor performance and make data-driven decisions.\n- Collaborate closely with the development team to integrate, create features and roadmap proposals.\n- Have a product vision and work closely with the marketing and development teams to align strategies with business objectives.\nMinimum Requirements\n- At least 3 years of experience in Data Engineer roles.\n- Bachelor's degree in computer science or related field.\n- Knowledge in: SQL/No SQL: Advanced, Power BI, Looker, tableau or others: Intermediate, Python and development knowledge: Basic, machine learning, AI or similar technologies: Basic, Identification of cluster patterns, trends, deviations: Intermediate, cloud technologies: Intermediate.\nSoft Skills:\n- Teamwork\n- Decision-making\n- Attention to detail\n- Adaptability \n\">\n- At least 3 years of experience in Data Engineer roles.\n- Bachelor's degree in computer science or related field.\n- Knowledge in: SQL/No SQL: Advanced, Power BI, Looker, tableau or others: Intermediate, Python and development knowledge: Basic, machine learning, AI or similar technologies: Basic, Identification of cluster patterns, trends, deviations: Intermediate, cloud technologies: Intermediate.\nSoft Skills:\n- Teamwork\n- Decision-making\n- Attention to detail\n- Adaptability        \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "IT Services and IT Consulting"
    },
    {
        "title": "Data Engineer AWS",
        "company": "BC Tecnolog\u00eda",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205294910/",
        "job_description": "En \nBC Tecnolog\u00eda\n, nos especializamos en la consultor\u00eda de TI, ofreciendo un amplio rango de servicios para adaptarnos a las necesidades espec\u00edficas de nuestros clientes, principalmente en finanzas, seguros, retail y gobierno. Nuestro equipo trabaja mediante metodolog\u00edas \u00e1giles, lo que nos permite dise\u00f1ar e implementar soluciones tecnol\u00f3gicas efectivas y dirigidas al cliente. Actualmente, estamos buscando un Data Engineer con experiencia en AWS para sumarse a nuestro equipo y contribuir a proyectos innovadores en la gesti\u00f3n y explotaci\u00f3n de datos.\n Responsabilidades del Cargo\n- Desarrollar y gestionar procesos de ETL, asegurando la calidad y fiabilidad de los datos.\n- Optimizar la explotaci\u00f3n de datos a trav\u00e9s de t\u00e9cnicas de Tuning.\n- Implementar soluciones utilizando herramientas de AWS, incluyendo Glue, Lambda, S3, Redshift y DynamoDB.\n- Colaborar con los equipos de desarrollo de software para asegurar la integraci\u00f3n de datos eficiente.\n- Realizar an\u00e1lisis y visualizaci\u00f3n de datos para apoyar en la toma de decisiones.\n- Mantener un enfoque en la innovaci\u00f3n y la mejora continua de los procesos y herramientas utilizadas.\n Descripci\u00f3n del Cargo\nBuscamos Un Data Engineer AWS Con Un M\u00ednimo De 3 A\u00f1os De Experiencia En El Manejo De Datos. El Candidato Ideal Tendr\u00e1 Conocimientos S\u00f3lidos En\n- Explotaci\u00f3n de datos y Tuning.\n- Dise\u00f1o e implementaci\u00f3n de procesos ETL.\n- Desarrollo de consultas efectivas en SQL.\n- Programaci\u00f3n en Python.\n- Uso de herramientas de orquestaci\u00f3n como Apache Airflow (deseable).\nValoramos habilidades como el trabajo en equipo, la proactividad y la capacidad para adaptarse a nuevas tecnolog\u00edas. La combinaci\u00f3n de habilidades t\u00e9cnicas y soft skills es esencial para unirse a nuestro equipo din\u00e1mico.\n Habilidades Deseables\nAdem\u00e1s de los requisitos mencionados, ser\u00eda beneficioso contar con experiencia en:\n- Integraciones y gesti\u00f3n de datos en m\u00faltiples fuentes.\n- Implementaci\u00f3n de soluciones en la nube de AWS.\n- Conocimientos en herramientas de visualizaci\u00f3n de datos.\nEstas habilidades ayudar\u00e1n al candidato a integrarse de manera efectiva en nuestros equipos de trabajo y contribuir a proyectos futuros.\n Beneficios de Trabajar con Nosotros\nEn \nBC Tecnolog\u00eda\n, valoramos a nuestro equipo y ofrecemos un entorno flexible y beneficios atractivos:\n- Contrato indefinido.\n- Modalidad h\u00edbrida, combinando trabajo remoto y en oficina.\n- Paquete de beneficios corporativos que incluye salud prepaga de primer nivel para el empleado y su familia.\n- Un d\u00eda de home office a la semana, junto con desayunos y un comedor en la planta.\n- Acceso a un Sport Club y asistencia de un nutricionista.\n\u00a1\u00danete a nosotros y marca una diferencia en el mundo de la tecnolog\u00eda! \ud83c\udf89\n                \n            \n                            \n            ",
        "Seniority level": "Not Applicable",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Data Analyst",
        "company": "LISIT",
        "location": "Los \u00c1ngeles, Biob\u00edo Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205297449/",
        "job_description": ""
    },
    {
        "title": "Software Engineer Python",
        "company": "Equifax",
        "location": "Providencia, Santiago Metropolitan Region, Chile",
        "date": "2025-04-09",
        "job_url": "https://www.linkedin.com/jobs/view/4165780801/",
        "job_description": ""
    },
    {
        "title": "Data Engineer GCP",
        "company": "Soluciones - Data & Analytics Consulting",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4206574777/",
        "job_description": "\u2714\ufe0f\n\u00bfQui\u00e9nes Somos?\nSomos una consultora enfocada en Data & Analytics y contamos con m\u00e1s de 20 a\u00f1os de experiencia y exitosa participaci\u00f3n en implementaci\u00f3n de proyectos de peque\u00f1a, mediana y gran envergadura. Nuestro equipo, compuesto por consultores multidisciplinarios expertos y certificados, ha entregado soluciones tecnol\u00f3gicas de calidad que exceden las expectativas de cada cliente. A trav\u00e9s de una metodolog\u00eda flexible y adaptable, logramos entregar soluciones adecuadas a la realidad de cada organizaci\u00f3n, satisfaciendo los est\u00e1ndares de cada una de las empresas que conf\u00edan en nosotros.\n\u2714\ufe0f\n \u00bfQu\u00e9 har\u00e1s?\n- Integraci\u00f3n de productos de datos.\n- Se trabajar\u00e1 con informaci\u00f3n para conocer a clientes y segmentarlos, para innovar en productos.\n- Trabajar\u00e1 los procesos ETL de inicio a fin (ingesta, transformaci\u00f3n, disponibilizaci\u00f3n).\n- Conocimientos Full GCP (airflow, bigquery, cloudstorage como herramientas principales)\n- Deber\u00e1 generar el flujo completo del dato desde la ingesta, transformaci\u00f3n y disponibilizaci\u00f3n.\n\u2714\ufe0f\n \u00bfQu\u00e9 se requiere?\n- Experiencia en el rol o cargo de Ingeniero de Datos Google Cloud Platform (GCP)\n\u2714\ufe0f\nConocimientos t\u00e9cnicos excluyentes:\n- Experiencia en datos y modelo de datos\n- Metodolog\u00eda agile\n- Procesos ETL\n- Conocimientos en Suit GCP\n\u2714\ufe0f \u00bfQu\u00e9 Ofrecemos ?\n- Seguros complementario de salud\n- Rutas de estudios\n- D\u00eda libre cumplea\u00f1os\n- Reajuste salarial anual seg\u00fan variaci\u00f3n del IPC        \n            \n                            \n            ",
        "Seniority level": "Associate",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "IT Services and IT Consulting"
    },
    {
        "title": "Senior Data Engineer",
        "company": "23people",
        "location": "Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4207846989/",
        "job_description": "\u00a1Hola! Estamos buscando un Senior Data Engineer \n\ud83c\udf10\nRango salarial entre: $2.200.000 - $2.400.000 CLP\nPa\u00eds: Residentes en Chile \nSkills\nT\u00e9cnicas\n- Python\n- BigQuery/SQL\n- GitHub\n- Apache Beam/Spark/Google Dataflow\nPersonales\n- Capacidad de autogesti\u00f3n\n- Buenos skills de comunicaci\u00f3n\n- Fortaleza en trabajo en equipo\n- Adaptaci\u00f3n al cambio (trabajar\u00e1n en distintas geos de Latam)\nDeseable (NO excluyente)\n- Perfil Anal\u00edtico\n- UnitTest\n- AirFlow\n- PySpark\n- CI/CD\n- Postman\n- Jmeter\n\u00bfQu\u00e9 har\u00e1s en tu d\u00eda a d\u00eda?\nEl profesional colaborar\u00e1 con un equipo multidisciplinario en un proyecto de expansi\u00f3n internacional, enfocado en la migraci\u00f3n estrat\u00e9gica de la plataforma hacia nuevos mercados. Su participaci\u00f3n ser\u00e1 fundamental para asegurar una implementaci\u00f3n eficiente que considere las particularidades de cada pa\u00eds destino, garantizando as\u00ed el \u00e9xito de esta iniciativa global.\nAlgunas de sus tareas diarias son las siguientes:\n- Implementar mecanismos para verificar la integridad de los datos migrados\n- Implementar transformaciones espec\u00edficas para requisitos regionales\n- Dirigir el equipo t\u00e9cnico durante las fases cr\u00edticas de migraci\u00f3n\n- Gestionar el proceso integral de ETL entre diversos sistemas, desarrollando y optimizando los esquemas de mapeo necesarios para garantizar la compatibilidad entre las estructuras de datos de origen y destino.\nContrato indefinido desde el inicio con 23people\nModalidad: Home Office, Con residencia en Chile (Deber\u00e1s ir a buscar el PC en primera instancia)\nExperiencia: Desde 5 a\u00f1os en adelante\nHorario: Lunes a Jueves de 8:30 a 6:30 y Viernes de 8:30 a 5:30 hrs.\nAlgunos de nuestros beneficios:\n- Seguro complementario: Seguro de salud, vida y dental\n- Curso de ingl\u00e9s: En nuestro programa de formaci\u00f3n en idioma ingl\u00e9s, ofrecemos dos modalidades para adaptarnos a tus necesidades y objetivos.\n- Reembolso de certificaciones internacionales: Apoyamos el crecimiento profesional, por lo que te reembolsamos el costo de un examen de certificaci\u00f3n internacional que quieras realizar.\n- Bono de vacaciones: Por cada semana que te tomes de vacaciones te otorgamos una compensaci\u00f3n.\n- Aguinaldos en fiestas patrias y Navidad: Queremos que en fechas tan especiales la pases bien junto a tu familia, por lo que te entregamos un bono en septiembre y diciembre\n- D\u00eda libre de cumplea\u00f1os: Puedes optar por tomar tu d\u00eda libre, el d\u00eda previo a tu cumplea\u00f1os, el mismo d\u00eda de tu cumplea\u00f1os o el d\u00eda posterior.        \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "IT Services and IT Consulting"
    },
    {
        "title": "Data Engineer AWS",
        "company": "Soluciones - Data & Analytics Consulting",
        "location": "Santiago Metropolitan Region, Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4207848749/",
        "job_description": "\u2714\ufe0f\n\u00bfQui\u00e9nes Somos?\nSomos una consultora enfocada en Data & Analytics y contamos con m\u00e1s de 20 a\u00f1os de experiencia y exitosa participaci\u00f3n en implementaci\u00f3n de proyectos de peque\u00f1a, mediana y gran envergadura. Nuestro equipo, compuesto por consultores multidisciplinarios expertos y certificados, ha entregado soluciones tecnol\u00f3gicas de calidad que exceden las expectativas de cada cliente. A trav\u00e9s de una metodolog\u00eda flexible y adaptable, logramos entregar soluciones adecuadas a la realidad de cada organizaci\u00f3n, satisfaciendo los est\u00e1ndares de cada una de las empresas que conf\u00edan en nosotros.\n\u2714\ufe0f\n \u00bfQu\u00e9 har\u00e1s?\n- Responsabilidades del cargo: Dise\u00f1ar, construir y mantener procesos de ingesta de datos que permiten recolectar, almacenar, procesar y acceder a grandes vol\u00famenes de datos de manera eficiente y segura. Su trabajo asegura que los datos est\u00e9n disponibles, limpios y organizados para su an\u00e1lisis adhiri\u00e9ndose a los est\u00e1ndares definidos por el cliente.\n\u2714\ufe0f\n \u00bfQu\u00e9 se requiere?\n- Experiencia de al menos 3 a\u00f1os en el rol\n- Conocimientos t\u00e9cnicos excluyentes: S3, Lambdas, Glue Jobs, DynamoDB, Redshift, StepFunctions, Python, SQS.\n- Conocimientos t\u00e9cnicos deseables: API Gateway, Transfer Family.\n\u2714\ufe0f \u00bfQu\u00e9 Ofrecemos ?\n- Seguros complementario de salud\n- Rutas de estudios\n- D\u00eda libre cumplea\u00f1os\n- Reajuste salarial anual seg\u00fan variaci\u00f3n del IPC        \n            \n                            \n            ",
        "Seniority level": "Not Applicable",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "IT Services and IT Consulting"
    },
    {
        "title": "Data Engineer Senior",
        "company": "Equifax",
        "location": "Las Condes, Santiago Metropolitan Region, Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4144902157/",
        "job_description": "Como Data Engineer, estar\u00e1s a cargo de integrar, consolidar y estructurar los datos, apoy\u00e1ndote en un las mejores pr\u00e1cticas para manejar, mantener y mejorar nuestras soluciones.\n \n \n \u00bfQu\u00e9 vas a hacer? \n \n \n-  Evaluar, gestionar y resolver incidentes. \n-  Realizar c\u00e1lculos en linea utilizando Python. \n-  Ejecuci\u00f3n de pruebas. \n \n \n \u00bfQu\u00e9 experiencia necesita? \n \n \n-  + 4 a\u00f1os de experiencia trabajando en Python. \n-  + 4 a\u00f1os de experiencia BigQuery. \n-  + 4 a\u00f1os de experiencia trabajando con Apache Beam y GitHub. \n \n \n \u00bfQu\u00e9 podr\u00eda diferenciarte? \n \n \n-  Poseer alguna certificaci\u00f3n de Google en Data Engineer. \n-  Experiencia trabajando con Airflow. \n-  Experiencia Trabajando con Jmeter. \n-  Experiencia trabajando con Unit Test. \n-  Experiencia trabajando con PySpark. \n-  Experiencia trabajando con CI/DF. \n-  Experiencia trabajando con Postman.        \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Financial Services"
    },
    {
        "title": "Data Engineer Semisenior o Senior",
        "company": "LISIT",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205297492/",
        "job_description": "Lisit es una empresa comprometida con la creaci\u00f3n, desarrollo e implementaci\u00f3n de soluciones de software que faciliten la automatizaci\u00f3n y optimizaci\u00f3n para nuestros clientes. Nuestra visi\u00f3n se centra en brindar servicios que no solo cumplan con las necesidades del mercado, sino que tambi\u00e9n transformen la operatividad de las organizaciones. Tu funci\u00f3n como Ingeniero de Datos ser\u00e1 fundamental para lograr un acompa\u00f1amiento consultivo integral en sus procesos de transformaci\u00f3n.\n Responsabilidades del puesto\nComo Ingeniero De Datos Semi-senior o Senior En Lisit, Ser\u00e1s Una Pieza Clave En El Dise\u00f1o y Desarrollo De Soluciones De Datos Que Optimicen Nuestros Servicios y Herramientas. Tus Tareas Incluir\u00e1n\n- Generar pipelines de datos eficientes y resolver integraciones entre diversos sistemas.\n- Modelar datos para garantizar que nuestras plataformas sean \u00fatiles y escalables.\n- Colaborar en la implementaci\u00f3n de herramientas de infraestructura como c\u00f3digo (IaC) y gestionar el versionamiento a trav\u00e9s de GitHub o GitLab.\n- Desarrollar y ejecutar procesos ETL/ELT utilizando Azure Data Factory, asegurando la calidad y accesibilidad de los datos.\n Descripci\u00f3n del puesto\nBuscamos un Ingeniero de Datos altamente motivado, con un m\u00ednimo de 3 a\u00f1os de experiencia en el tratamiento de datos. Tu destreza con lenguajes de programaci\u00f3n como Python y Spark te permitir\u00e1 desempe\u00f1arte con solidez en el equipo. Se requiere un conocimiento intermedio-avanzado de herramientas de IaC (Terraform) y manejo de versionamiento de c\u00f3digo (GitHub/GitLab), as\u00ed como una s\u00f3lida comprensi\u00f3n del lenguaje SQL y bases de datos.\nEs esencial que tengas experiencia con plataformas en la nube como Google Cloud Platform (GCP) o Azure, y herramientas como Airflow, Cloud Run, Cloud Composer y BigQuery. Adem\u00e1s, el dominio de Azure Data Factory para procesos ETL-ELT es un requisito excluyente. Las certificaciones en Ingenier\u00eda de Datos son valoradas, tales como Azure DP-700, AZ-203, DP-600 y Google Cloud Digital Leader.\n Habilidades deseables\nSi cuentas con conocimientos en Microsoft Power BI o Fabric, ser\u00eda un gran plus para tu perfil. Queremos personas que no solo cumplan con los requisitos, sino que tambi\u00e9n aporten un enfoque innovador y colaborativo a nuestro equipo.\n Beneficios de trabajar con nosotros\nEn Lisit, Fomentamos Un Ambiente De Trabajo Excepcional, Donde La Innovaci\u00f3n y La Pasi\u00f3n Por El Aprendizaje Son Clave. Te Ofrecemos\n- Acceso a oportunidades continuas de desarrollo profesional en tecnolog\u00edas emergentes.\n- Un equipo motivado y apasionado que valora tu entusiasmo y contribuciones.\nAqu\u00ed, tendr\u00e1s la oportunidad de crecer y alcanzar tus objetivos profesionales mientras colaboras en proyectos desafiantes y de alto impacto.\n                \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Technology, Information and Internet and Information Technology & Services"
    },
    {
        "title": "Ingeniero de Datos",
        "company": "Amaris Consulting",
        "location": "Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4206597362/",
        "job_description": "Who are we?\nAmaris Consulting es una firma independiente de asesor\u00eda tecnol\u00f3gica que ofrece servicios de orientaci\u00f3n y soluciones para las empresas.\nRe\u00fane a m\u00e1s de 7 600 personas distribuidas en 5 continentes y m\u00e1s de 60 pa\u00edses. Con m\u00e1s de 1 000 clientes en todo el mundo, hemos implementado soluciones en proyectos importantes durante m\u00e1s de una d\u00e9cada.\nNuestros especialistas cubren sectores que abarcan desde servicios financieros y transporte hasta atenci\u00f3n sanitaria y tecnolog\u00eda.\nAmaris es su \u2018stepping stone\u2019 para atravesar r\u00edos de cambio, afrontar retos y realizar todos sus proyectos con \u00e9xito.\nJob Description\nBuscamos consultores din\u00e1micos para hacer crecer nuestro equipo de \nSistemas de Informaci\u00f3n y Digital\n en\n Chile\n. Tu experiencia, conocimiento y compromiso nos ayudar\u00e1n a enfrentar los desaf\u00edos de nuestros clientes.\nEstar\u00e1s apoyando diferentes proyectos a trav\u00e9s de tu experiencia como \nIngeniero de Datos.\nSus principales responsabilidades:\n- Asegurar que las soluciones de datos sean escalables, eficientes y alineadas con los objetivos de negocio.\n- Dise\u00f1ar, desarrollar e implementar soluciones de gesti\u00f3n y an\u00e1lisis de datos en la industria.\n- Utilizar herramientas como Python y SQL para extraer, transformar y cargar (ETL) datos.\n- Trabajar con bases de datos en la nube, utilizando alguna de las principales plataformas: Google Cloud Platform (GCP), Amazon Web Services (AWS) o Microsoft Azure.\n- Desarrollar y mantener pipelines de datos para la gesti\u00f3n y an\u00e1lisis eficiente.\n- Desarrollar APIs y plugins para integrar soluciones de datos con otras aplicaciones y sistemas.\n- Implementar y gestionar entornos de desarrollo y pruebas para soluciones de datos.\n- Mantenerse actualizado con las \u00faltimas tendencias y herramientas en el \u00e1mbito de la ingenier\u00eda de datos.\nRequisitos\n:\n- Al menos 2 a\u00f1os de experiencia como Ingeniero de Datos.\n- Al menos 2 a\u00f1os de experiencia con alguna de las principales nubes (GCP, AWS, Azure).\n- Dominio de Python.\n- Dominio de bases de datos SQL.\n- Experiencia con procesos ETL.\nAmaris Consulting se enorgullece de ser un lugar de trabajo con igualdad de oportunidades. Estamos comprometidos con la promoci\u00f3n de la diversidad dentro de la fuerza de trabajo y la creaci\u00f3n de un ambiente de trabajo inclusivo. Para ello, damos la bienvenida a las solicitudes de todos los candidatos cualificados, independientemente de su g\u00e9nero, orientaci\u00f3n sexual, raza, etnia, creencias, edad, estado civil, discapacidad u otras caracter\u00edsticas.        \n            \n                            \n            ",
        "Seniority level": "Entry level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "IT Services and IT Consulting"
    },
    {
        "title": "Analista de Datos",
        "company": "Outlier",
        "location": "La Serena, Coquimbo Region, Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4207883217/",
        "job_description": ""
    },
    {
        "title": "Data Engineer - GCP Ssr",
        "company": "axity",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-09",
        "job_url": "https://www.linkedin.com/jobs/view/4204875774/",
        "job_description": "Company Description: axity\nJob Description: Axity una compa\u00f1\u00eda con m\u00e1s de 35 a\u00f1os de trayectoria nuestro portafolio de servicios es uno de los m\u00e1s grandes en la industria: Estrategia Digital, Desarrollo de Software, Bussiness Intelligence, Big Data, Anal\u00edtica Avanzada, Seguridad, IOT.\nBuscamos Data Analyst / Data Engineer \u2013 Nivel Medio/Avanzado\n\u00bfTe apasiona convertir datos en informaci\u00f3n valiosa y accionable?\nEstamos en b\u00fasqueda de un profesional con experiencia en desarrollo de productos de complejidad media a avanzada, capaz de entregar soluciones de calidad dentro de los plazos establecidos.\nResponsabilidades\nDesarrollar productos anal\u00edticos cumpliendo con est\u00e1ndares de calidad y tiempos definidos.\nTraducir datos en informaci\u00f3n \u00fatil para la toma de decisiones.\nTrabajar en conjunto con equipos de anal\u00edtica para profundizar en el an\u00e1lisis y la s\u00edntesis de datos.\nSeleccionar y aplicar t\u00e9cnicas anal\u00edticas adecuadas a cada requerimiento.\nMantenerse actualizado sobre herramientas anal\u00edticas y productos de manipulaci\u00f3n de datos.\nRealizar procesos de recolecci\u00f3n, clasificaci\u00f3n, limpieza e interpretaci\u00f3n de grandes vol\u00famenes de datos.\nAplicar pr\u00e1cticas de gobernanza y seguridad de los datos.\nParticipar en iniciativas que involucren integraci\u00f3n de datos para procesos como planeaci\u00f3n de compras, demanda y gesti\u00f3n de inventarios.\nRequisitos\nExperiencia en GCP (Google Cloud Platform): BigQuery, Cloud Storage, Dataflow, Cloud Functions, Composer, Pub/Sub.\nConocimientos b\u00e1sicos en Kubernetes, contenedores y consumo de APIs.\nExperiencia en manejo de grandes vol\u00famenes de datos.\nConocimiento de sistemas legados, flujos de compras y demand forecasting.\nCapacidad de interacci\u00f3n continua con \u00e1reas de negocio.\nOfrecemos\nHorario: Lunes a viernes de 9:00 a 18:30\nContrato a plazo fijo luego a indefinido\nOportunidad de trabajar en proyectos desafiantes con impacto directo en el negocio\nAmbiente colaborativo e innovador\nSi te motiva trabajar con datos, impactar decisiones estrat\u00e9gicas y enfrentarte a desaf\u00edos t\u00e9cnicos, \u00a1postula con nosotros!\n                \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "IT Services and IT Consulting"
    },
    {
        "title": "Ingeniero de Gobierno de Datos - Subgerencia de Gobierno de Datos",
        "company": "Consorcio",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-08",
        "job_url": "https://www.linkedin.com/jobs/view/4204238135/",
        "job_description": ""
    },
    {
        "title": "Data Engineer - AWS Ssr",
        "company": "axity",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-09",
        "job_url": "https://www.linkedin.com/jobs/view/4204874848/",
        "job_description": "Company Description: axity\nJob Description: Axity una compa\u00f1\u00eda con m\u00e1s de 35 a\u00f1os de trayectoria nuestro portafolio de servicios es uno de los m\u00e1s grandes en la industria: Estrategia Digital, Desarrollo de Software, Bussiness Intelligence, Big Data, Anal\u00edtica Avanzada, Seguridad, IOT.\nResponsabilidades Principales\n-  Dise\u00f1o eficiente de almacenamiento de datos: utilizando servicios como Amazon S3, DynamoDB, RDS, entre otros, optimizando costos, rendimiento y accesibilidad.\n-  Optimizaci\u00f3n de consultas: aplicando \u00edndices, claves de partici\u00f3n y patrones de acceso eficientes (Query, GetItem, etc.).\n-  Integraci\u00f3n y procesamiento de datos: a trav\u00e9s de herramientas como AWS Glue, Amazon Kinesis y/o Firehose para ingesta, transformaci\u00f3n y orquestaci\u00f3n.\n-  Uso de formatos optimizados: como Parquet, ORC, entre otros, para mejorar la compresi\u00f3n y velocidad de lectura/escritura.\n-  Infraestructura como C\u00f3digo (IaC): despliegue de infraestructura en AWS mediante CloudFormation, AWS CDK o Terraform.\n________________________________________\n\ufe0f Conocimientos T\u00e9cnicos Clave\n-  Amplio manejo de servicios AWS: S3, DynamoDB, RDS, AWS Glue, Kinesis/Firehose.\n-  Dominio de bases de datos SQL/NoSQL: dise\u00f1o de esquemas, indexaci\u00f3n y tuning.\n-  Experiencia en optimizaci\u00f3n y particionamiento de grandes vol\u00famenes de datos.\n-  Familiaridad con automatizaci\u00f3n y orquestaci\u00f3n de pipelines: scripting, Jenkins, Shell, entre otros.\n-  Modalidad: H\u00edbrido\n-  \u00c1rea: Tecnolog\u00eda \u2013 Cloud\n-  Horario: Lunes a viernes de 9:00 a 18:00 hrs\n-  Tipo de Contrato: Plazo fijo, con posibilidad de pasar a indefinido\n________________________________________\n\u00bfPor qu\u00e9 postular?\n-  Ser\u00e1s parte de una empresa con enfoque en la innovaci\u00f3n y la transformaci\u00f3n digital.\n-  Trabajar\u00e1s con tecnolog\u00edas de vanguardia en un entorno colaborativo.\n-  Tendr\u00e1s oportunidades reales de crecimiento profesional.        \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "IT Services and IT Consulting"
    },
    {
        "title": "Ingeniero en Gesti\u00f3n de Datos",
        "company": "Genesys",
        "location": "Las Condes, Santiago Metropolitan Region, Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4206087107/",
        "job_description": ""
    },
    {
        "title": "Software Engineer",
        "company": "IGX",
        "location": "Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205299322/",
        "job_description": ""
    },
    {
        "title": "Consultor Data Analyst",
        "company": "LISIT",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4205297448/",
        "job_description": ""
    },
    {
        "title": "Software Engineer",
        "company": "Banco Falabella",
        "location": "Santiago Metropolitan Region, Chile",
        "date": "2025-04-09",
        "job_url": "https://www.linkedin.com/jobs/view/4205421235/",
        "job_description": ""
    },
    {
        "title": "Data Engineer Azure",
        "company": "",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4206654598/",
        "job_description": "Resumen del Cargo:\nBusco Ingeniero de Datos  para liderar y ejecutar proyectos de Data & Analytics. \nSer\u00e1 responsable del dise\u00f1o, desarrollo e implementaci\u00f3n de soluciones de datos usando Azure Databricks, Data Factory, Python  y otros servicios en la nube, asegurando que la infraestructura de datos sea escalable, segura y optimizada para la toma de decisiones. \nAdem\u00e1s, deber\u00e1 interactuar directamente con \u00e1reas de negocio para levantar requerimientos y traducirlos en soluciones t\u00e9cnicas eficientes.\n\u00a0\n\u00a0\nResponsabilidades:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Dise\u00f1ar y desarrollar soluciones de ingesti\u00f3n, transformaci\u00f3n y modelado de datos en Azure DataFactory, Databricks y otras tecnolog\u00edas relacionadas.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Optimizar procesos de ETL/ELT, asegurando calidad, integridad y eficiencia en el procesamiento de datos.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Colaborar con equipos de negocio para entender necesidades, identificar oportunidades y proponer soluciones basadas en datos.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Implementar arquitecturas de datos escalables que soporten anal\u00edtica avanzada, machine learning e inteligencia de negocio.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Garantizar la seguridad y el cumplimiento normativo en el manejo de datos, siguiendo est\u00e1ndares bancarios y regulatorios.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Desarrollar y optimizar pipelines de datos para la explotaci\u00f3n en entornos anal\u00edticos y de reportes.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Documentar procesos, arquitecturas y modelos de datos, asegurando buenas pr\u00e1cticas de gobernanza.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u2022\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Trabajar en conjunto con equipos de Data Science, BI y Tecnolog\u00eda para garantizar la disponibilidad y calidad de los datos.\n\u00a0        \n            \n                            \n            ",
        "Seniority level": "Entry level",
        "Employment type": "Full-time",
        "Job function": "Information Technology"
    },
    {
        "title": "Software Engineer",
        "company": "ZeroFox",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-07",
        "job_url": "https://www.linkedin.com/jobs/view/4203138895/",
        "job_description": ""
    },
    {
        "title": "Backoffice - Analista de datos",
        "company": "Infinity Ingenieria SPA",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-10",
        "job_url": "https://www.linkedin.com/jobs/view/4204075434/",
        "job_description": ""
    },
    {
        "title": "Analista de datos de Farmacia",
        "company": "IQVIA",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-12",
        "job_url": "https://www.linkedin.com/jobs/view/4208763580/",
        "job_description": ""
    },
    {
        "title": "Data Analyst Power BI- Bigquery",
        "company": "Soluciones - Data & Analytics Consulting",
        "location": "Santiago Metropolitan Region, Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4207890015/",
        "job_description": ""
    },
    {
        "title": "Data Analyst Senior Modelos y Datos Riesgo",
        "company": "Banco Bci",
        "location": "Las Condes, Santiago Metropolitan Region, Chile",
        "date": "2025-04-08",
        "job_url": "https://www.linkedin.com/jobs/view/4203767105/",
        "job_description": ""
    },
    {
        "title": "Data Insights Specialist",
        "company": "Nestl\u00e9",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-07",
        "job_url": "https://www.linkedin.com/jobs/view/4202697660/",
        "job_description": ""
    },
    {
        "title": "Data Analyst I - Operations",
        "company": "Signant Health",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-07",
        "job_url": "https://www.linkedin.com/jobs/view/4202554692/",
        "job_description": ""
    },
    {
        "title": "Software Engineer II, Gerencia Tecnolog\u00eda",
        "company": "Walmart Chile",
        "location": "Huechuraba, Santiago Metropolitan Region, Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4206684576/",
        "job_description": ""
    },
    {
        "title": "Software Engineer III, Gerencia Tecnolog\u00eda",
        "company": "Walmart Chile",
        "location": "Huechuraba, Santiago Metropolitan Region, Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4206686540/",
        "job_description": ""
    },
    {
        "title": "Salesforce Software Engineer",
        "company": "Banco Falabella",
        "location": "Santiago Metropolitan Area",
        "date": "2025-04-07",
        "job_url": "https://www.linkedin.com/jobs/view/4203137306/",
        "job_description": ""
    },
    {
        "title": "Analista BI",
        "company": "Chubb",
        "location": "Chile",
        "date": "2025-04-11",
        "job_url": "https://www.linkedin.com/jobs/view/4208212282/",
        "job_description": ""
    },
    {
        "title": "Software Engineer III",
        "company": "Mindbody",
        "location": "Chile",
        "date": "2025-04-13",
        "job_url": "https://www.linkedin.com/jobs/view/4169374324/",
        "job_description": ""
    },
    {
        "title": "Senior Software Engineer, Backend (Remote)",
        "company": "Mindbody",
        "location": "Chile",
        "date": "2025-04-12",
        "job_url": "https://www.linkedin.com/jobs/view/4170144703/",
        "job_description": ""
    },
    {
        "title": "Senior Data Engineer",
        "company": "Grupo Falabella",
        "location": "Santiago, Santiago Metropolitan Region, Chile",
        "date": "2025-04-09",
        "job_url": "https://www.linkedin.com/jobs/view/4205465977/",
        "job_description": "Descripci\u00f3n Empresa\nSomos m\u00e1s de 90 mil personas que, d\u00eda a d\u00eda, dedicamos nuestra pasi\u00f3n y energ\u00eda a cumplir nuestro Prop\u00f3sito de \u201cSimplificar y Disfrutar M\u00e1s la Vida\u201d. Prop\u00f3sito que hoy vive a trav\u00e9s de nuestro ecosistema f\u00edsico y digital en todas nuestras empresas (Falabella Retail, Sodimac, IKEA, Tottus, Mallplaza, Falabella Inmobiliario, Falabella.com, Linio, Falabella Financiero, Banco Falabella, Falabella Soriana, Seguros Falabella, Fazil, Fpay y Falabella Corporativo) y pa\u00edses (Argentina, Brasil, Chile, China, Colombia, India, M\u00e9xico, Per\u00fa y Uruguay).\nValoramos las distintas miradas porque entendemos que la diversidad es la clave de nuestra innovaci\u00f3n. Queremos ir m\u00e1s all\u00e1 de cualquier l\u00edmite, desafiarnos constantemente, divertirnos haciendo lo que nos gusta y dejar huella en lo que hacemos. Y sabemos que existe una forma de hacerlo: como UN SOLO EQUIPO.\nMisi\u00f3n Del Cargo\n\u00a1\u00danete a Falabella Retail y lleva tus habilidades de Ingenier\u00eda de Datos al pr\u00f3ximo nivel!\nFunciones Del Cargo\nFormar\u00e1s parte de un equipo de alto impacto que lidera la transformaci\u00f3n digital, trabajando en proyectos cr\u00edticos para optimizar y escalar nuestras operaciones en uno de los ecosistemas m\u00e1s din\u00e1micos de la regi\u00f3n.\nMision: Responsable de dise\u00f1ar, construir y mantener sistemas de datos escalables para el an\u00e1lisis y la toma de decisiones en la organizaci\u00f3n.\nResponsabilidades\nDise\u00f1ar y desarrollar canalizaciones de datos (ETL/ELT) robustas y eficientes.\nColaborar con equipos de ingenier\u00eda de datos.\nImplementar y gestionar bases de datos y data warehouses.\nOptimizar el rendimiento de las bases de datos y sistemas de almacenamiento de datos.\nGarantizar la calidad, integridad y seguridad de los datos.\nAutomatizar procesos de ingesti\u00f3n y transformaci\u00f3n de datos.\nMonitorizar y solucionar problemas relacionados con los sistemas de datos.\nDocumentar procesos, arquitecturas y mejores pr\u00e1cticas relacionadas con el manejo de datos.\nSi disfrutas nuevos desaf\u00edos con alta responsabilidad y exposici\u00f3n en el epicentro de la transformaci\u00f3n del retail en Latinoam\u00e9rica, \u00a1s\u00famate a trabajar con nosotros! Somos una empresa que apoya la Ley 21015, apoyamos la diversidad y la inclusi\u00f3n en todas sus formas, sin importar religi\u00f3n, raza, g\u00e9nero, situaci\u00f3n de discapacidad, nacionalidad.\nConoce m\u00e1s oportunidades para vivir la #ExperienciaFalabella en https://muevete.falabella.com/\nRequisitos\n- Profesional Titulado en Ingenier\u00eda Civil Computaci\u00f3n, Industrial, matem\u00e1tico u el\u00e9ctrico.\n- Experiencia demostrable como Data Engineer por mas de 04 a\u00f1os\n- Conocimientos en lenguajes de programaci\u00f3n Python.\n- Experiencia con Google Cloud Platform (Composer, Cloud Functions, Bigquery, Dataproc, etc)\n- Experiencia utilizando git\n- Deseable: Conocimientos profundos en SQL y en bases de datos relacionales y no relacionales\n- Deseable: Certificaciones relevantes en tecnolog\u00edas de datos y cloud.\nCondiciones Oferta\nDescripci\u00f3n proceso de selecci\u00f3n:\nEl proceso de selecci\u00f3n se realiza a trav\u00e9s de Aira - plataforma de reclutamiento dise\u00f1ado para mejorar tu experiencia de postulaci\u00f3n.\nPara Postular Solo Necesitas\n-  Postular a la oferta\n-  Revisar tu email\n-  Ingresar a Aira y contestar las preguntas y/o pruebas solicitadas\nLuego, si vemos que tu perfil se ajusta a lo que estamos buscando, te contactaremos por email (a trav\u00e9s de Aira) para seguir a la etapa presencial.\n                \n            \n                            \n            ",
        "Seniority level": "Mid-Senior level",
        "Employment type": "Full-time",
        "Job function": "Information Technology",
        "Industries": "Retail"
    }
]